<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Intention Recognition on K7288</title>
    <link>https://K7288.github.io/categories/intention-recognition/</link>
    <description>Recent content in Intention Recognition on K7288</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 07 Jul 2021 17:00:00 +0800</lastBuildDate><atom:link href="https://K7288.github.io/categories/intention-recognition/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
      <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
      <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
      <description>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach
intention定义: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).
Research question to propose an automatic, user-independent recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.</description>
    </item>
    
    <item>
      <title>Motion control for a walking companion robot with a novel human–robot interface</title>
      <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
      <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
      <description>Motion control for a walking companion robot with a novel human–robot interface
Research question A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.
A new human– robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.
mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states</description>
    </item>
    
    <item>
      <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
      <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
      <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
      <description>A lower limb exoskeleton based on recognition of lower limb walking intention
intention定义: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination
Introduction   Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driver’s intention, and human–robot interface.
  three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.</description>
    </item>
    
  </channel>
</rss>
