<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Literature Notes on K7288</title>
    <link>https://K7288.github.io/categories/literature-notes/</link>
    <description>Recent content in Literature Notes on K7288</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 17 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://K7288.github.io/categories/literature-notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>外骨骼综述</title>
      <link>https://K7288.github.io/posts/%E5%A4%96%E9%AA%A8%E9%AA%BC%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%A4%96%E9%AA%A8%E9%AA%BC%E7%BB%BC%E8%BF%B0/</guid>
      <description>Lower limb exoskeleton systems-overview1    Category Control(mostly) Actuator(mostly) Wearer     Assistive High precision; Predefined trajectories triggered by the user’s moving intention
($\Rightarrow$ Intention Estimation + Trajectories Generating) DC motor patients permanently lose the ability to walk   Rehabilitation Predefined; Impedance control; Adjusting itself based on patient feedback. high-power density rehabilitating patients to regain mobility   Augmentation admittance/impedance control; positive feedback sensitivity amplification control, Inaccurate but high power/weight ratio actuators (series elastic actuators (SEA) and pneumatic actuators) healthy individuals    Assistive Intention Estimation ​   Direct</description>
    </item>
    
    <item>
      <title>(Origami) Pneumatic Exoskeleton</title>
      <link>https://K7288.github.io/posts/origami-pnumatic-exoskeleton/</link>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/origami-pnumatic-exoskeleton/</guid>
      <description>(Origami) Pneumatic Exoskeleton
Summary of previous work    Author Origami pattern Joint Prototype 研究阶段     Bio-Robotics and Control (BiRC) Laboratory，UNIST, Korea Yoshimura pattern shoulder  1.设计 2.建模（输出力关于弯曲角度等的表达式）3. 实验验证对支撑能力/输出力矩的仿真结果   南方科技大学 刘思聪 王峥 Variated Yoshimura with trapezoid facets. wrist  1. 设计 2. 运动学建模 3. 级联控制（未详细阐述，使用之前合作的工作） 4. 实验验证控制性能以及不同负载下的运动范围   西北工业大学 Jing Fang*2 #1 #2 / (Accordion/Fan) knee  1. 设计 2. 建模（输出力矩的闭式表达式）3. 实验验证机械性能及辅助效果 4. 控制（满足对特定动作的支持）   Yang, Hee Doo / (Artificial muscle) elbow</description>
    </item>
    
    <item>
      <title>IPS for Validation</title>
      <link>https://K7288.github.io/posts/ips-for-validation/</link>
      <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/ips-for-validation/</guid>
      <description>Detection of gait events using an F-Scan in-shoe pressure measurement system 比较了force-based detection (FD，软件自带)和area-based method (AD) ；kinetic detection(KT，使用force platforms的数据)作为validation
对F-Scan® system准确性的讨论 Several studies have evaluated the accuracy and reliability of force and pressure measurements using the F-Scan® system and reached different conclusions. While some authors concluded that F-Scan demonstrated good to excellent reliability in measuring plantar pressures [11], others concluded that the system was not entirely suitable for accurate and repeatable absolute pressure measurements [12], [13], [14] or that the system could be used only in a sample large enough as to allow the detection of the real effect of the treatment [15].</description>
    </item>
    
    <item>
      <title>Reviews of Gait Event/Phase Detection Methods</title>
      <link>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</link>
      <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</guid>
      <description>Strategy1 &amp;amp; Yield  Search Strategy
  Scopus, Google Scholar, and PubMed databases were used to perform a literature search on the topic of gait phase partitioning.
  The electronic search was conducted in September 2015.
  Keywords included: gait events, gait phases, and their combinations with the words: partitioning, detection, classification, and recognition. In addition, wildcard symbols, such as hyphens or inverted commas, were used to consider all possible variations of root words.</description>
    </item>
    
    <item>
      <title>Phase Portraits</title>
      <link>https://K7288.github.io/posts/phase-portrait/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/phase-portrait/</guid>
      <description>Studies using phase portraits    Authors and year Axes Task     Holgate et al. 2009 Tibia angle &amp;amp; tibia scaled angular velocity Continuous gait phase estimation   Villarreal et al.,2017 Thigh angle &amp;amp; its derivative(estimated thigh velocity) Continuous gait phase estimation   Quintero et al.,2017 Thigh angle &amp;amp; its derivative(estimated thigh velocity) Continuous gait phase estimation; gait speed estimation(as a byproduct)   Quintero et al.</description>
    </item>
    
    <item>
      <title>Sensors for Gait Analysis</title>
      <link>https://K7288.github.io/posts/sensors-for-gait-analysis/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/sensors-for-gait-analysis/</guid>
      <description>Sensors for Gait Analysis  Sensors for Gait Analysis  Sensors  Inertial Measurement Units  Sensor placement  Preference in literature (inter- and intra=) Segments to choose   Filter Application   Insole pressure sensors      Sensors    Distribution of studies based on the type of wearable sensors used Distribution of studies based on the type of sensors used for ground-truth validation of IMU-based gait analysis.</description>
    </item>
    
    <item>
      <title>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons</title>
      <link>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</link>
      <pubDate>Thu, 08 Jul 2021 14:29:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</guid>
      <description>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons
intention定义: walk/stride across/stop state
Research question  analysis of gait planning based on a human kinematics model and real-time motion stability based on the zero-moment point (ZMP). a neural interface based on sEMG to achieve motion intention recognition and muscle fatigue estimation. to verify the stability of human–exoskeleton system and ergonomic effects of the proposed gait switching method by organized experiments.</description>
    </item>
    
    <item>
      <title>A novel motion intention recognition approach for soft exoskeleton via IMU</title>
      <link>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</link>
      <pubDate>Thu, 08 Jul 2021 09:05:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</guid>
      <description>A novel motion intention recognition approach for soft exoskeleton via IMU
intention定义: the classic five kinds of terrains(including walking on flat ground, going up and downstairs, and up and down slopes) &amp;amp; transformed terrains
   Abbreviation Definition Abbreviation Definition     IMU Inertial measurement unit SA Stair ascent   DDLMI DNN-based deep locomotion mode identification SD Stair decent   ISR Identification success rate RA Ramp ascent   LW Level-ground walking RD Ramp decent    Research question to propose a recognition method with historical information based on neural network to recognize different terrain and add the pattern transformation recognition, trying to predict the next motion mode in advance.</description>
    </item>
    
    <item>
      <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
      <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
      <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
      <description>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach
intention定义: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).
Research question to propose an automatic, user-independent recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.</description>
    </item>
    
    <item>
      <title>Motion control for a walking companion robot with a novel human–robot interface</title>
      <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
      <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
      <description>Motion control for a walking companion robot with a novel human–robot interface
Research question A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.
A new human– robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.
mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states</description>
    </item>
    
    <item>
      <title>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study</title>
      <link>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</link>
      <pubDate>Tue, 06 Jul 2021 22:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</guid>
      <description>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study
intention定义: standing still(stationary), walking or ascending the stairs
Hardware sensors: ADXL345 (an accelerometer; in pelvis unit) and four FSRs (two in each foot for heel and toe respectively)
Algorithm   gait adaptation: detect in which phase of the gait cycle the subject is
  adaptive frequency oscillators (AFO) $\Leftarrow$ Since the human gait cycle is periodic, the acceleration signals obtained from the pelvis unit is also periodic in nature.</description>
    </item>
    
    <item>
      <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
      <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
      <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
      <description>A lower limb exoskeleton based on recognition of lower limb walking intention
intention定义: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination
Introduction   Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driver’s intention, and human–robot interface.
  three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.</description>
    </item>
    
    <item>
      <title>Intention Recgonition for Exoskeleton</title>
      <link>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</link>
      <pubDate>Tue, 06 Jul 2021 13:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</guid>
      <description>Intention Recgonition for Exoskeleton
intention定义: walk/stand
assistance exoskeleton system   支持4种state: L swing, R swing, Double stance(L), Double stance(R)
  control
  Methods online SVM; features: ZMP(Zero Moment Point), IMU
  ZMP
  concept: The distributed floor reaction force can be replaced by a single force R acts on ZMP.
  ZMP can be obtained from ground reaction force (GRF) measurement or inverse dynamics of system.</description>
    </item>
    
    <item>
      <title>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses</title>
      <link>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</guid>
      <description>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses
intention定义—locomotion modes: level walking, ramp ascent, ramp descent, stair ascent, and stair descent
Research question to develop a user-independent intent recognition system capable of recognizing level-ground walking, slopes, and stairs and to compare this system with a user-dependent intent recognition system.
Introduction  Prior studies in which pattern recognition algorithms: current methods to initiate transitions between modes, such as visual, audio, or compensatory movement commands, are unintuitive and impose a cognitive burden.</description>
    </item>
    
    <item>
      <title>Multi-sensor based human motion intention recognition algorithm for walking-aid robot</title>
      <link>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</guid>
      <description>Multi-sensor based human motion intention recognition algorithm for walking-aid robot
intention定义：velocity; 这里表征为一个自定概念IM
Research question A multi-sensor(force sensors and LRF; for both lower and upper limbs) based human motion intention recognition algorithm for walking-aid robot.
Introduction  assistive rehabilitation robots: PAMM, Walking Helper, HAL, Omni RT Walker-II (ORTW-II) 简略说了一些human motion estimation methods  Methods  Sensors: push-pull force sensors and LRF(Laser Range Finder)    LRF: Range Segmentation, Identification of Circle, Leg detection, Intention detection</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://K7288.github.io/posts/terms/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/terms/</guid>
      <description>Terms Definition     inertia matrix    damping matrix    stiffness matrix    centripetal and Coriolis matrix    Cartesian coordinate    mass-damper-spring model    impedance control    admittance control 导纳控制    push-off impulse time    transition function    adaptive frequency oscillators    one-way ANOVA    two-way ANOVA    a neural interface    linear discriminant analysis    drift(signal/integral/zero/integral/temperature drift)    a rigid body 刚体    time-varying, adaptive compensation term, manifold, coarse/fine-grained level granularity, an inertial frame, oscillator, denominator,</description>
    </item>
    
    <item>
      <title>行文常见说法</title>
      <link>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</guid>
      <description>prior studies/research
Experimental Protocol
Representative diagram
the integrated design
cognitive effort
methodology
prototype
Sensory Information</description>
    </item>
    
    <item>
      <title>A review of human activity recognition methods</title>
      <link>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</link>
      <pubDate>Thu, 01 Jul 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</guid>
      <description>A review of human activity recognition methods
Recognizing human activities from video sequences or still images
intention定义: activity; 一个描述性词
Usually, the terms “activity” and “behavior” are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term “activity” is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term “behavior” is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.</description>
    </item>
    
    <item>
      <title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>
      <link>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</link>
      <pubDate>Tue, 29 Jun 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</guid>
      <description>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intention定义：velocity+trajectory; 只涉及到一个接触点
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.</description>
    </item>
    
    <item>
      <title>Froude Numbers</title>
      <link>https://K7288.github.io/posts/froude-numbers/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/froude-numbers/</guid>
      <description>The Gaits of Bipedal and Quadrupedal Animals Alexander R. The gaits of bipedal and quadrupedal animals. The International Journal of Robotics Research. 1984;
mammals of different sizes tend to move in dynamically similar fashion whenever their Froude numbers $u^2 /gh$ are equal: here u is speed, g is the acceleration of free fall, and h is the height of the hip joint from the ground.
Research Problem description of the gaits of two- and four-legged animals and some of the important optimization criteria(e.</description>
    </item>
    
    <item>
      <title>The effect of stride length on lower extremity joint kinetics at various gait speeds</title>
      <link>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</link>
      <pubDate>Sun, 16 May 2021 10:44:02 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</guid>
      <description>The effect of stride length on lower extremity joint kinetics at various gait speeds
 Research question Concepts Notations Background Materials and Methods  Data analysis  1. 数据处理 2. Protocol validation 3. Continuum analysis  main effect analysis SL   4. Torque pulse approximation     Results  Protocol validation Continuum analysis Torque pulse approximation   Conclusion Limits/Further Work Thoughts/Comments  Research question In this study, we investigated how sagittal plane joint moments are affected by a factorial modulation of two important gait parameters: gait speed and stride length.</description>
    </item>
    
    <item>
      <title>步速估计综述整理</title>
      <link>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</link>
      <pubDate>Wed, 12 May 2021 22:17:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</guid>
      <description>Toward Pervasive Gait Analysis With Wearable Sensors: A Systematic Review Abstract 对当前的定量步态分析技术进行系统的综述，并提出关键指标，来评估现有的通过可穿戴传感器提取步态特征的方法。它旨在突出这一快速发展的研究领域中的关键进展，并概述研究和临床应用的潜在未来方向。
SECTION III. Methods for Extracting Relevant Gait Features From Wearable Sensors A.文献检索
B. Kinematics
Kinematic information is a well-established set of gait measures in biomechanical analysis.
从惯性传感器获取运动学信息似乎很直观，但是要获得关于人体运动学的准确空间信息仍然很困难：全局失准和integration drift
C.时序特征
D.利用惯性传感器的步速提取
Laudanski et al. [104] reviewed the current research (16 papers in total) on gait speed estimation using inertial sensors, classifying the current gait speed estimation model into three categories: abstraction model (i.</description>
    </item>
    
    <item>
      <title>基于几何与物理特征融合的智能下肢假肢运动意图识别</title>
      <link>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</link>
      <pubDate>Wed, 12 May 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</guid>
      <description>基于几何与物理特征融合的智能下肢假肢运动意图识别Movement intention recognition of intelligent lower limb prosthesis based on the fusion of geometric and physical features
intention定义—locomotion modes 5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡，8类转换模式
Research question 将关节角表示的几何特征与加速度、角速度表示的物理特征有机融合并应用于智能下肢假肢的运动意图识别
Introduction 传统的意图识别方法所用传感器数量及种类较多, 特征向量维数偏高, 统计特征对短时样本具有不稳定性（在1.3 特征选择与提取有公式证明）。related work没有结合几何和物理。
Methods   采样：健侧大腿、小腿惯性测量单元于摆动相前期所产生的运动时序数据作为样本；
  数据处理：移动平均滤波器滤波去噪
  特征提取：
 几何特征：根据两个传感器的加速度、角速度计算一维的膝关节角，FDA方法提取最值斜率 物理特征：加速度、角速度的均值、方差  均值、方差、最值斜率融合构成25维的特征基构建特征向量
  SVM分类
  Results 13种日常行为进行分类。实验结果：对5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡的识别率达到96.9%, 对8类转换模式的识别率达到97.1%, 对13 种模式的识别率为94.3%。
Highlights 减少了传感器的数量及种类, 降低 了特征向量的维数降低了算法复杂度且避免了滞后性问题, 用加速度、 角速度及膝关节角三个参数共同对人体下肢运动的运动学特点进行表征。
在特征的提取上, 将FDA方法与统计方法相结合, 弥补了仅提取统计特征的不稳定性问题。
Limits/Further Work 对于13种动作的识别率有待提高, 后期工作会集中于对类间相似性相对较强较难区分的动作进行分类, 如: 下楼与下坡, 走到下楼 与走到下坡等.</description>
    </item>
    
  </channel>
</rss>
