<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Intention Recognition on K7288</title>
    <link>https://K7288.github.io/tags/intention-recognition/</link>
    <description>Recent content in Intention Recognition on K7288</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 02 Aug 2021 00:52:44 +0800</lastBuildDate><atom:link href="https://K7288.github.io/tags/intention-recognition/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>IPS for Validation</title>
      <link>https://K7288.github.io/posts/ips-for-validation/</link>
      <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/ips-for-validation/</guid>
      <description>Detection of gait events using an F-Scan in-shoe pressure measurement system  对F-Scan® system准确性的讨论 Methods &amp;amp; Results   KT的阈值选取 一些验证指标  Detection of gait events using an F-Scan in-shoe pressure measurement system 比较了force-based detection (FD，软件自带)和area-based method (AD) ；kinetic detection(KT，使用force platforms的数据)作为validation
对F-Scan® system准确性的讨论 Several studies have evaluated the accuracy and reliability of force and pressure measurements using the F-Scan® system and reached different conclusions. While some authors concluded that F-Scan demonstrated good to excellent reliability in measuring plantar pressures [11], others concluded that the system was not entirely suitable for accurate and repeatable absolute pressure measurements [12], [13], [14] or that the system could be used only in a sample large enough as to allow the detection of the real effect of the treatment [15].</description>
    </item>
    
    <item>
      <title>Reviews of Gait Event/Phase Detection Methods</title>
      <link>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</link>
      <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</guid>
      <description>Strategy1 &amp;amp; Yield  Search Strategy
  Scopus, Google Scholar, and PubMed databases were used to perform a literature search on the topic of gait phase partitioning.
  The electronic search was conducted in September 2015.
  Keywords included: gait events, gait phases, and their combinations with the words: partitioning, detection, classification, and recognition. In addition, wildcard symbols, such as hyphens or inverted commas, were used to consider all possible variations of root words.</description>
    </item>
    
    <item>
      <title>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons</title>
      <link>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</link>
      <pubDate>Thu, 08 Jul 2021 14:29:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</guid>
      <description>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons
intention定义: walk/stride across/stop state
Research question  analysis of gait planning based on a human kinematics model and real-time motion stability based on the zero-moment point (ZMP). a neural interface based on sEMG to achieve motion intention recognition and muscle fatigue estimation. to verify the stability of human–exoskeleton system and ergonomic effects of the proposed gait switching method by organized experiments.</description>
    </item>
    
    <item>
      <title>A novel motion intention recognition approach for soft exoskeleton via IMU</title>
      <link>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</link>
      <pubDate>Thu, 08 Jul 2021 09:05:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</guid>
      <description>A novel motion intention recognition approach for soft exoskeleton via IMU
intention定义: the classic five kinds of terrains(including walking on flat ground, going up and downstairs, and up and down slopes) &amp;amp; transformed terrains
   Abbreviation Definition Abbreviation Definition     IMU Inertial measurement unit SA Stair ascent   DDLMI DNN-based deep locomotion mode identification SD Stair decent   ISR Identification success rate RA Ramp ascent   LW Level-ground walking RD Ramp decent    Research question to propose a recognition method with historical information based on neural network to recognize different terrain and add the pattern transformation recognition, trying to predict the next motion mode in advance.</description>
    </item>
    
    <item>
      <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
      <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
      <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
      <description>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach
intention定义: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).
Research question to propose an automatic, user-independent recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.</description>
    </item>
    
    <item>
      <title>Motion control for a walking companion robot with a novel human–robot interface</title>
      <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
      <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
      <description>Motion control for a walking companion robot with a novel human–robot interface
Research question A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.
A new human– robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.
mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states</description>
    </item>
    
    <item>
      <title>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study</title>
      <link>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</link>
      <pubDate>Tue, 06 Jul 2021 22:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</guid>
      <description>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study
intention定义: standing still(stationary), walking or ascending the stairs
Hardware sensors: ADXL345 (an accelerometer; in pelvis unit) and four FSRs (two in each foot for heel and toe respectively)
Algorithm   gait adaptation: detect in which phase of the gait cycle the subject is
  adaptive frequency oscillators (AFO) $\Leftarrow$ Since the human gait cycle is periodic, the acceleration signals obtained from the pelvis unit is also periodic in nature.</description>
    </item>
    
    <item>
      <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
      <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
      <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
      <description>A lower limb exoskeleton based on recognition of lower limb walking intention
intention定义: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination
Introduction   Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driver’s intention, and human–robot interface.
  three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.</description>
    </item>
    
    <item>
      <title>Intention Recgonition for Exoskeleton</title>
      <link>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</link>
      <pubDate>Tue, 06 Jul 2021 13:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</guid>
      <description>Intention Recgonition for Exoskeleton
intention定义: walk/stand
assistance exoskeleton system   支持4种state: L swing, R swing, Double stance(L), Double stance(R)
  control
  Methods online SVM; features: ZMP(Zero Moment Point), IMU
  ZMP
  concept: The distributed floor reaction force can be replaced by a single force R acts on ZMP.
  ZMP can be obtained from ground reaction force (GRF) measurement or inverse dynamics of system.</description>
    </item>
    
    <item>
      <title>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses</title>
      <link>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</guid>
      <description>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses
intention定义—locomotion modes: level walking, ramp ascent, ramp descent, stair ascent, and stair descent
Research question to develop a user-independent intent recognition system capable of recognizing level-ground walking, slopes, and stairs and to compare this system with a user-dependent intent recognition system.
Introduction  Prior studies in which pattern recognition algorithms: current methods to initiate transitions between modes, such as visual, audio, or compensatory movement commands, are unintuitive and impose a cognitive burden.</description>
    </item>
    
    <item>
      <title>Multi-sensor based human motion intention recognition algorithm for walking-aid robot</title>
      <link>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</guid>
      <description>Multi-sensor based human motion intention recognition algorithm for walking-aid robot
intention定义：velocity; 这里表征为一个自定概念IM
Research question A multi-sensor(force sensors and LRF; for both lower and upper limbs) based human motion intention recognition algorithm for walking-aid robot.
Introduction  assistive rehabilitation robots: PAMM, Walking Helper, HAL, Omni RT Walker-II (ORTW-II) 简略说了一些human motion estimation methods  Methods  Sensors: push-pull force sensors and LRF(Laser Range Finder)    LRF: Range Segmentation, Identification of Circle, Leg detection, Intention detection</description>
    </item>
    
    <item>
      <title>A review of human activity recognition methods</title>
      <link>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</link>
      <pubDate>Thu, 01 Jul 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</guid>
      <description>A review of human activity recognition methods
Recognizing human activities from video sequences or still images
intention定义: activity; 一个描述性词
Usually, the terms “activity” and “behavior” are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term “activity” is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term “behavior” is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.</description>
    </item>
    
    <item>
      <title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>
      <link>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</link>
      <pubDate>Tue, 29 Jun 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</guid>
      <description>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intention定义：velocity+trajectory; 只涉及到一个接触点
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.</description>
    </item>
    
    <item>
      <title>基于几何与物理特征融合的智能下肢假肢运动意图识别</title>
      <link>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</link>
      <pubDate>Wed, 12 May 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</guid>
      <description>基于几何与物理特征融合的智能下肢假肢运动意图识别Movement intention recognition of intelligent lower limb prosthesis based on the fusion of geometric and physical features
intention定义—locomotion modes 5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡，8类转换模式
Research question 将关节角表示的几何特征与加速度、角速度表示的物理特征有机融合并应用于智能下肢假肢的运动意图识别
Introduction 传统的意图识别方法所用传感器数量及种类较多, 特征向量维数偏高, 统计特征对短时样本具有不稳定性（在1.3 特征选择与提取有公式证明）。related work没有结合几何和物理。
Methods   采样：健侧大腿、小腿惯性测量单元于摆动相前期所产生的运动时序数据作为样本；
  数据处理：移动平均滤波器滤波去噪
  特征提取：
 几何特征：根据两个传感器的加速度、角速度计算一维的膝关节角，FDA方法提取最值斜率 物理特征：加速度、角速度的均值、方差  均值、方差、最值斜率融合构成25维的特征基构建特征向量
  SVM分类
  Results 13种日常行为进行分类。实验结果：对5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡的识别率达到96.9%, 对8类转换模式的识别率达到97.1%, 对13 种模式的识别率为94.3%。
Highlights 减少了传感器的数量及种类, 降低 了特征向量的维数降低了算法复杂度且避免了滞后性问题, 用加速度、 角速度及膝关节角三个参数共同对人体下肢运动的运动学特点进行表征。
在特征的提取上, 将FDA方法与统计方法相结合, 弥补了仅提取统计特征的不稳定性问题。
Limits/Further Work 对于13种动作的识别率有待提高, 后期工作会集中于对类间相似性相对较强较难区分的动作进行分类, 如: 下楼与下坡, 走到下楼 与走到下坡等.</description>
    </item>
    
  </channel>
</rss>
