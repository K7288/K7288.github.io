<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>K7288</title>
        <link>https://K7288.github.io/</link>
        <description>Recent content on K7288</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Fri, 06 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://K7288.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Origami patterns</title>
        <link>https://K7288.github.io/posts/origami-patterns/</link>
        <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/origami-patterns/</guid>
        <description>&lt;p&gt;Yoshimura&lt;/p&gt;
&lt;p&gt;Miura-ori&lt;/p&gt;
&lt;p&gt;diagnoal&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Origami Pneumatic Exoskeleton</title>
        <link>https://K7288.github.io/posts/origami-pnumatic-exoskeleton/</link>
        <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/origami-pnumatic-exoskeleton/</guid>
        <description>&lt;p&gt;Origami Pneumatic Exoskeleton&lt;/p&gt;
&lt;h2 id=&#34;previous-work&#34;&gt;Previous work&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;西北工业大学 Jing Fang*2 &lt;a class=&#34;link&#34; href=&#34;#an-inflatable-and-foldable-knee-exosuit-based-on-intelligent-management-of-biomechanical-energy&#34; &gt;#1&lt;/a&gt; &lt;a class=&#34;link&#34; href=&#34;#novel-accordion-inspired-foldable-pneumatic-actuators-for-knee-assistive-devices&#34; &gt;#2&lt;/a&gt; the knee joint&lt;/li&gt;
&lt;li&gt;南方科技大学 刘思聪 王峥 wrist&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;an-inflatable-and-foldable-knee-exosuit-based-on-intelligent-management-of-biomechanical-energy&#34;&gt;An Inflatable and Foldable Knee Exosuit Based on Intelligent Management of Biomechanical Energy&lt;/h2&gt;
&lt;h3 id=&#34;research-object&#34;&gt;Research object&lt;/h3&gt;
&lt;p&gt;An inflatable, foldable and variable stiffness knee exosuit and an intelligent control profile for it&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Biomechanical energy harvesting: Humans are a rich source of energy. An average-sized person
stores as much energy in fat as a 1000-kg battery&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;methods&#34;&gt;Methods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;a large amount of negative power that is marked by K1, K2 and K3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;assets/image-20210806140539308.png&#34; alt=&#34;image-20210806140539308&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Intelligent Energy Management Profile&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;quasi-stiffness to characterize the spring-like behavior of knee joint.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;assets/image-20210806140817591.png&#34; alt=&#34;image-20210806140817591&#34; style=&#34;zoom:53%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过与膝关节平行增加一个变刚度弹簧，并根据图3这六个点上（根据步态周期划分）调整其刚度，可以收集和再利用人体的生物机械能，节省行走过程中消耗的体力。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DESIGN AND FABRICATION&lt;/p&gt;
&lt;p&gt;热塑性聚氨酯(TPU)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;assets/image-20210806105450817.png&#34; alt=&#34;image-20210806105450817&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;novel-accordion-inspired-foldable-pneumatic-actuators-for-knee-assistive-devices&#34;&gt;Novel Accordion-Inspired Foldable Pneumatic Actuators for Knee Assistive Devices&lt;/h2&gt;
&lt;h3 id=&#34;methods-1&#34;&gt;Methods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Biomechanics and design requirements&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210806151335187.png&#34; alt=&#34;image-20210806151335187&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;​	能推出膝关节外骨骼需要提供的角度以及力矩（康复型的需要小一点）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;设计 （同上篇）the geometry of FPBAs also ensures that their &lt;strong&gt;internal&lt;/strong&gt;
&lt;strong&gt;airflow is always unobstructed at any angle&lt;/strong&gt;, which avoids the
airflow restriction problem for single-chamber actuators at extreme bending angles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;虚功原理推出输出力矩（volume/angle relationships和内部压强的函数） $\tau=\left(\frac{P_{0} \cdot V_{0}\left(\theta_{0}\right)}{V(\theta)}-P_{a t m}\right) \cdot \frac{\mathrm{d} V(\theta)}{\mathrm{d}  \theta}$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;assets/image-20210806153740685.png&#34; alt=&#34;image-20210806153740685&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;控制：不同的辅助动作给不同的恒压&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;assets/image-20210806155605797.png&#34; alt=&#34;image-20210806155605797&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;img src=&#34;assets/image-20210806170617002.png&#34; alt=&#34;image-20210806170617002&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;origami-structured-actuating-modules-for-upper-limb-support&#34;&gt;Origami-Structured Actuating Modules for Upper Limb Support&lt;/h2&gt;
&lt;p&gt;题目 关键词 摘要 结论 图表 引言 结果和讨论 实验&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;p&gt;a layered manufacturing process for a durable pattern-embedded sheet, which is applicable to the construction of any origami-structured SPAs, 2) an analytical model of the exerted force and bending angle, as well as a design optimization, and 3) experimental verification of the exerted force and upper limb motion assistance offered by the actuating module when used as a wearable system.&lt;/p&gt;
&lt;h3 id=&#34;research-question&#34;&gt;Research question&lt;/h3&gt;
&lt;h3 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h3&gt;
&lt;h3 id=&#34;methods-2&#34;&gt;Methods&lt;/h3&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;h3 id=&#34;highlights&#34;&gt;Highlights&lt;/h3&gt;
&lt;h3 id=&#34;limitsfurther-work&#34;&gt;Limits/Further Work&lt;/h3&gt;
&lt;h3 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;怎么用充气实现弯曲？&lt;/p&gt;
&lt;p&gt;好像是结构自身的特点？是未充满气就是弯曲吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以实现twist吗？看实验图片是有的（手向斜前侧伸出），但是介绍Yoshimura的时候没说twist这样会不会有问题？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;a-compact-soft-robotic-wrist-brace-with-origami-actuators&#34;&gt;A Compact Soft Robotic Wrist Brace With Origami Actuators&lt;/h2&gt;
&lt;p&gt;SOA(soft origami actuator)&lt;/p&gt;
&lt;h3 id=&#34;materials&#34;&gt;Materials&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;synergistic actuation approach 协同驱动&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210810143810899.png&#34; alt=&#34;image-20210810143810899&#34;  /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;soft-on-soft&lt;/p&gt;
&lt;p&gt;锚点使得soft actuator的output linear deformation and force in axial direction重整为consecutive bending&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Yoshimura pattern&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;small elastic constant in the axial direction;&lt;/li&gt;
&lt;li&gt;simplicity of elementary facets&lt;/li&gt;
&lt;li&gt;intrinsically high circumferential bending rigidity&lt;/li&gt;
&lt;li&gt;The hexagon facets effectively eliminate the extruding vertices formed by the triangular facets of the standard Yoshimura pattern; thus, the potential stress concentration at the vertices was avoided.六边形切面有效地消除了标准Yoshimura三角形切面所形成的挤压顶点;从而避免了顶点处潜在的应力集中。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;methods-3&#34;&gt;Methods&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;整体简化成一个并联机构(a parallel mechanism with four soft actuators) 2-DOF的运动简化成绕x/y轴的转动，通过D-H方法可以得到末端位置&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;assets/image-20210810152312429.png&#34; alt=&#34;image-20210810152312429&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;不同load下的位移-压强关系可测定&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A cascaded control strategy (a motion-control outer loop and multichannel pressure-control inner loops for each SOA)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210810142215509.png&#34; alt=&#34;a cascaded control strategy&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The outer loop, controlled by the high-level controller, used pressure feedback information from each actuator to obtain the overall device motion estimation and then compared with the desired motion mapped from the different control commands (flexion/extension, ulnar/radial deviation, and engagement signal). The resultant pressure commands from the high-level controller were then relayed to the low-level controllers, each regulating one soft origami actuator accordingly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;del&gt;没有讲是怎么配合人的&lt;/del&gt; 其实讲了，因为是康复型不是增强型所以只要输入上层指令&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;According to Flores et al. (2014), the average maximal torque generated by the wrist of a healthy individual in radial/ulnar deviation is 1.3 Nm. As shown in Figure 7F, the force generated from proposed SR brace in radial/ulnar deviation was around 6 N; thus, considering the length of the 2-actuator unit of 128 mm, the torque generated by the SR brace reached up to 0.76 Nm, which is about &lt;strong&gt;58% of the max torque of human wrist&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;题目 关键词 摘要 结论 图表 引言 结果和讨论 实验&lt;/p&gt;
&lt;h3 id=&#34;research-question-1&#34;&gt;Research question&lt;/h3&gt;
&lt;h3 id=&#34;introduction-2&#34;&gt;Introduction&lt;/h3&gt;
&lt;h3 id=&#34;methods-4&#34;&gt;Methods&lt;/h3&gt;
&lt;h3 id=&#34;results-1&#34;&gt;Results&lt;/h3&gt;
&lt;h3 id=&#34;highlights-1&#34;&gt;Highlights&lt;/h3&gt;
&lt;h3 id=&#34;limitsfurther-work-1&#34;&gt;Limits/Further Work&lt;/h3&gt;
&lt;h3 id=&#34;thoughtscomments-1&#34;&gt;Thoughts/Comments&lt;/h3&gt;
&lt;p&gt;题目 关键词 摘要 结论 图表 引言 结果和讨论 实验&lt;/p&gt;
&lt;h3 id=&#34;research-question-2&#34;&gt;Research question&lt;/h3&gt;
&lt;h3 id=&#34;introduction-3&#34;&gt;Introduction&lt;/h3&gt;
&lt;h3 id=&#34;methods-5&#34;&gt;Methods&lt;/h3&gt;
&lt;h3 id=&#34;results-2&#34;&gt;Results&lt;/h3&gt;
&lt;h3 id=&#34;highlights-2&#34;&gt;Highlights&lt;/h3&gt;
&lt;h3 id=&#34;limitsfurther-work-2&#34;&gt;Limits/Further Work&lt;/h3&gt;
&lt;h3 id=&#34;thoughtscomments-2&#34;&gt;Thoughts/Comments&lt;/h3&gt;
</description>
        </item>
        <item>
        <title>IPS for Validation</title>
        <link>https://K7288.github.io/posts/ips-for-validation/</link>
        <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/ips-for-validation/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#detection-of-gait-events-using-an-f-scan-in-shoe-pressure-measurement-system&#34; &gt;Detection of gait events using an F-Scan in-shoe pressure measurement system&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e5%af%b9f-scan-system%e5%87%86%e7%a1%ae%e6%80%a7%e7%9a%84%e8%ae%a8%e8%ae%ba&#34; &gt;对F-Scan® system准确性的讨论&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#methods--results&#34; &gt;Methods &amp;amp; Results&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#kt%e7%9a%84%e9%98%88%e5%80%bc%e9%80%89%e5%8f%96&#34; &gt;KT的阈值选取&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e4%b8%80%e4%ba%9b%e9%aa%8c%e8%af%81%e6%8c%87%e6%a0%87&#34; &gt;一些验证指标&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;detection-of-gait-events-using-an-f-scan-in-shoe-pressure-measurement-system&#34;&gt;Detection of gait events using an F-Scan in-shoe pressure measurement system&lt;/h2&gt;
&lt;p&gt;比较了force-based detection (FD，软件自带)和area-based method (AD) ；kinetic detection(KT，&lt;strong&gt;使用force platforms的数据&lt;/strong&gt;)作为validation&lt;/p&gt;
&lt;h3 id=&#34;对f-scan-system准确性的讨论&#34;&gt;对F-Scan® system准确性的讨论&lt;/h3&gt;
&lt;p&gt;Several studies have evaluated the accuracy and reliability of force and pressure measurements using the F-Scan® system and reached different conclusions. While some authors concluded that F-Scan demonstrated good to excellent reliability in measuring plantar pressures [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib11&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;11]&lt;/a&gt;, others concluded that the system was not entirely suitable for accurate and repeatable absolute pressure measurements [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib12&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;12]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib13&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;13]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib14&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;14]&lt;/a&gt; or that the system could be used only in a sample large enough as to allow the detection of the real effect of the treatment [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib15&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;15]&lt;/a&gt;. Other studies suggested that errors could be greatly minimized by adequate preparation and use of the system [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib16&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;16]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib17&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;17]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib18&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;18]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib19&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;19]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib20&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;20]&lt;/a&gt;. These and similar studies show that the system could provide valuable information but care should be taken when measuring absolute values of force or pressure.&lt;/p&gt;
&lt;p&gt;[&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib16&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;16]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib17&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;17]&lt;/a&gt;建议subject先走10min保证温度+适应，所以可以先穿上鞋再贴IMU&lt;/p&gt;
&lt;h3 id=&#34;methods--results&#34;&gt;Methods &amp;amp; Results&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;#kt%e7%9a%84%e9%98%88%e5%80%bc%e9%80%89%e5%8f%96&#34; &gt;KT&lt;/a&gt;&lt;/strong&gt; 10N threshold&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FD&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$\text{force threshold}= \text{minimum}+(\text{maximum}-\text{minimum})\times \frac{10}{100}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;​AD&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$\text {area threshold}=\mathrm{ALS} \mathrm{w}+(\mathrm{ALSt}-\mathrm{ALSw}) \times \frac{5}{100}$​​&lt;/p&gt;
&lt;p&gt;统计load area，出现频率最高的小面积($&amp;lt; 2000 \text{mm}^2$​)就是$\text{area loaded during swing (ALSw)}$​，($&amp;gt;2000 \text{mm}^2$​​) 的up to the maximum area (b) was used to find the $\text{area loaded during stance (ALSt)}$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/1-s2.0-S096663620800043X-gr1.jpg&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;5 set by visually inspecting&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;statistical analysis&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A 2 (insoles sets: 1 and 2) × 2 (time differences with respect to the gold standard for methods FD and AD) mixed design analysis of variance (ANOVA) was used for the analysis, with time differences serving as the within subjects factor.&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;The results of the statistical test for IC showed that there was a significant effect for the methods factor, &lt;em&gt;F&lt;/em&gt; (1, 8) = 348.5, &lt;em&gt;p&lt;/em&gt; &amp;lt; 0.01. The effect of the insoles sets was not significant, &lt;em&gt;F&lt;/em&gt; (1, 8) = 0.35, &lt;em&gt;p&lt;/em&gt; &amp;gt; 0.05, and the interaction of insoles sets and methods was also not significant, &lt;em&gt;F&lt;/em&gt; (1, 8) = 5.1, &lt;em&gt;p&lt;/em&gt; &amp;gt; 0.05.&lt;/p&gt;
&lt;p&gt;For FO, the statistical test also showed a significant effect for the detection methods, &lt;em&gt;F&lt;/em&gt; (1, 8) = 600.2, &lt;em&gt;p&lt;/em&gt; &amp;lt; 0.01. The effect of the insoles sets was not significant, &lt;em&gt;F&lt;/em&gt; (1, 8) = 0.77, &lt;em&gt;p&lt;/em&gt; &amp;gt; 0.05, and the interaction of insoles sets and methods was also not significant, &lt;em&gt;F&lt;/em&gt; (1, 8) = 11.1, &lt;em&gt;p&lt;/em&gt; &amp;gt; 0.05.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/1-s2.0-S096663620800043X-gr2.jpg&#34; style=&#34;zoom: 67%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/1-s2.0-S096663620800043X-gr3.jpg&#34; style=&#34;zoom: 67%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;kt的阈值选取&#34;&gt;KT的阈值选取&lt;/h2&gt;
&lt;p&gt;直接用阈值最好是使用测力板&amp;quot;gold standards&amp;quot;，但也可以用insole pressure sensor&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;IPSs are often considered as an alternative to force plates in validation studies due to several advantages including cost factor, wearability, and unconstrained movement that allows natural gait in both indoor and outdoor environments.&lt;/p&gt;
&lt;p&gt;Despite these advantages, there are some constraints to consider. IPSs are typically placed inside the shoe and are thus subject to pressure between it and the foot, which can lead to non-zero pressure readings even when the foot is in swing phase. Although IPSs are comparable to force plates when it comes to estimation of temporal features, using them for real-time ground reaction force estimation is not recommended since it takes a considerably longer time to reach the set value compared to a force plate.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Different thresholds algorithms proposed: a fixed threshold for both events of zero [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib24&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;24]&lt;/a&gt;, 2.5 N [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib25&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;25]&lt;/a&gt; and 10 N [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib8&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;8]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib9&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;9]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib26&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;26]&lt;/a&gt;, a combination of 10 N for IC and 5 N for FO [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib10&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;10]&lt;/a&gt;, [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib27&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;27]&lt;/a&gt;, a proportion of body weight [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib28&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;28]&lt;/a&gt; or a threshold equal to two standard deviations above the mean unloaded baseline [&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S096663620800043X?via%3Dihub#bib7&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;7]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;GRF thresholds of 10 N, 15 N, and 2% of the maximum vertical GRF(high agreement between the different force thresholds (R2 value &amp;gt;0.99))&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;three different thresholds, i.e., 5 N, 10 N, and 50 N 不同阈值之间有差别&lt;/li&gt;
&lt;li&gt;IC and TO events were the 10 N and 25 N thresholds&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;HO and TO: 30% of the maximum; &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;39% of the maximum FSR value (on a rising edge)&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;一些验证指标&#34;&gt;一些验证指标&lt;/h2&gt;
&lt;p&gt;误差，误差分布 accuracy (precision, recall, F1-score) and timing agreement (Bland-Altman method)&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Prasanth, H., Caban, M., Keller, U., Courtine, G., Ijspeert, A., Vallery, H., &amp;amp; von Zitzewitz, J. (2021). Wearable sensor-based real-time gait detection: A systematic review. Sensors, 21(8)&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Rosa M.S. Visscher, Sailee Sansgiri, Marie Freslier, Jaap Harlaar, Reinald Brunner, William R. Taylor, Navrag B. Singh, Towards validation and standardization of automatic gait event identification algorithms for use in paediatric pathological populations, Gait &amp;amp; Posture, Volume 86, 2021, Pages 64-69, ISSN 0966-6362, &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2021.02.031&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.gaitpost.2021.02.031&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J.P. Hunter, R.N. Marshall, P.J. McNair &lt;strong&gt;Relationships between ground reaction force impulse and kinematics of sprint-running acceleration&lt;/strong&gt; Journal of Applied Biomechanics, 21 (1) (2005), pp. 31-43&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;E. Bergamini, P. Picerno, H. Pillet, F. Natta, P. Thoreux &lt;strong&gt;Estimation of temporal parameters during sprint running using a trunk-mounted inertial measurement unit&lt;/strong&gt; J. Biomech., 45 (2012), pp. 1123-1126&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Mo, S.; Chow, D.H.K. Accuracy of Three Methods in Gait Event Detection during Overground Running. &lt;em&gt;Gait Posture&lt;/em&gt; &lt;strong&gt;2018&lt;/strong&gt;, &lt;em&gt;59&lt;/em&gt;, 93–98.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Figueiredo, P. Félix, L. Costa, J. C. Moreno and C. P. Santos, &amp;ldquo;Gait Event Detection in Controlled and Real-Life Situations: Repeated Measures From Healthy Subjects,&amp;rdquo; in IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 26, no. 10, pp. 1945-1956, Oct. 2018, doi: 10.1109/TNSRE.2018.2868094.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Hanlon M and Anderson R 2009 Real-time gait event detection using wearable sensors &lt;em&gt;Gait Posture&lt;/em&gt; &lt;strong&gt;30&lt;/strong&gt; 523–7&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Reviews of Gait Event/Phase Detection Methods</title>
        <link>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</link>
        <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</guid>
        <description>&lt;h2 id=&#34;strategy1--yield&#34;&gt;Strategy&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; &amp;amp; Yield&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Search Strategy&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Scopus, Google Scholar, and PubMed databases were used to perform a literature search on the topic of gait phase partitioning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The electronic search was conducted in September 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keywords included: &lt;em&gt;gait events, gait phases&lt;/em&gt;, and their combinations with the words: &lt;em&gt;partitioning, detection, classification&lt;/em&gt;, &lt;em&gt;and recognition&lt;/em&gt;. In addition, wildcard symbols, such as hyphens or inverted commas, were used to consider all possible variations of root words.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To avoid missing some important studies, a cross referencing was applied from each article found during electronic search. A literature search was performed by Taborri.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Inclusion Criteria&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Articles obtained thorough these searches were evaluated using the title and abstract. The articles were included in this systematic review when they met the following criteria: (i) they were written in English; (ii) they were published from January 2000 to September 2015. We excluded conference proceedings when a journal article published by the same authors with the same contents was already included.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Extraction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Publications included in this systematic review were downloaded into Mendeley for screening. In order to make the review readable and focused on the authors’ intention, as claimed in the Introduction section, a data extraction was conducted based on major themes: (i) the granularity of the gait cycle ; (ii) sensor placement; and, (iii) method and performance of gait phase classifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Quality Assessment&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A quality assessment of the found articles was provided in addition to the systematic review; in particular, publications were subject to seven criteria, as shown in &lt;a class=&#34;link&#34; href=&#34;https://www.mdpi.com/1424-8220/16/1/66/htm#table_body_display_sensors-16-00066-t001&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Table 1&lt;/a&gt;, in accordance to Campos and colleagues [&lt;a class=&#34;link&#34; href=&#34;https://www.mdpi.com/1424-8220/16/1/66/htm#B84-sensors-16-00066&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;84&lt;/a&gt;]. Independently, Taborri, Palermo and Rossi used the seven criteria to assess the quality of the publications. Any discrepancy among two reports was adjudicated by the third one.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;gait-event-detection&#34;&gt;gait event detection&lt;/h3&gt;
&lt;p&gt;检索关键词: gait event detection，限定2015及以后&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;wearable-sensor-based-real-time-gait-detection-a-systematic-review&#34;&gt;Wearable sensor-based real-time gait detection: A systematic review&lt;/h4&gt;
&lt;p&gt;Rueterbories et al. [26] Review of sensor configurations and placements, and a brief review of gait detection methods&lt;/p&gt;
&lt;p&gt;Perez-Ibarra et al. [27] Brief review comparing gait event detection methods, sensors used, placement of sensors and subjects involved&lt;/p&gt;
&lt;p&gt;Panebianco et al. [18] Rule-based methods&lt;/p&gt;
&lt;h3 id=&#34;gait-phase-detection&#34;&gt;gait phase detection&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.webofscience.com/wos/alldb/summary/57226eff-c2ae-4eb3-91bd-e96594eab295-02dc6d49/date-descending/1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;检索Author Keywords &amp;ldquo;gait phase detection&amp;rdquo;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;event-detection&#34;&gt;event detection&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.webofscience.com/wos/alldb/summary/da435c9d-241f-46b7-be7b-4230ef82c979-02dc6d7b/date-descending/1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;检索Author Keywords &amp;ldquo;event detection&amp;rdquo;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;gait-event-detection-1&#34;&gt;gait event detection&lt;/h3&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.webofscience.com/wos/alldb/summary/11caf6e3-d842-4474-a033-08c1df7ab6c6-02e490df/date-descending/1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;检索Author Keywords &amp;ldquo;gait event detection&amp;rdquo;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;gait-events--phases&#34;&gt;Gait events &amp;amp; phases&lt;/h2&gt;
&lt;p&gt;见&amp;quot;J. Perry, J.M. Burnfield, Gait Analysis: Normal and Pathological Function(2nd ed.), SLACK Incorporated (2010)&amp;quot;（&lt;a class=&#34;link&#34; href=&#34;https://K7288.github.io/posts/gait-analysis-fundamentals/#gait-analysis-three-basic-approaches3&#34; &gt;笔记&lt;/a&gt;）以及&amp;quot;Michael W. Whittle, An Introduction to Gait Analysis, 4th Ed. (2007)&amp;quot;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/1-s2.0-S0966636217302424-gr1.jpg&#34; alt=&#34;image-20210813200345964&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210813202148021.png&#34; alt=&#34;image-20210813202148021&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;此外，一些工作里有不同的划分方式&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210813200345964.png&#34; alt=&#34;image-20210813200345964&#34;  /&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Taborri, J., Palermo, E., Rossi, S., &amp;amp; Cappa, P. (2016). Gait partitioning methods: A systematic review. Sensors (Switzerland), 16(1). &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.3390/s16010066&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.3390/s16010066&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Caldas, R., Mundt, M., Potthast, W., Buarque de Lima Neto, F., &amp;amp; Markert, B. (2017). A systematic review of gait analysis methods based on inertial sensors and adaptive algorithms. Gait and Posture, 57, 204–210. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2017.06.019&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.gaitpost.2017.06.019&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Pacini Panebianco, G., Bisi, M. C., Stagni, R., &amp;amp; Fantozzi, S. (2018). Analysis of the performance of 17 algorithms from a systematic review: Influence of sensor position, analysed variable and computational approach in gait timing estimation from IMU measurements. Gait and Posture, 66, 76–82. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2018.08.025B&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.gaitpost.2018.08.025B&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;enson, L. C., Clermont, C. A., Bošnjak, E., &amp;amp; Ferber, R. (2018). The use of wearable devices for walking and running gait analysis outside of the lab: A systematic review. Gait &amp;amp; Posture, 63, 124–138. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/J.GAITPOST.2018.04.047P&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/J.GAITPOST.2018.04.047P&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;rasanth, H., Caban, M., Keller, U., Courtine, G., Ijspeert, A., Vallery, H., &amp;amp; von Zitzewitz, J. (2021). Wearable sensor-based real-time gait detection: A systematic review. Sensors, 21(8). &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.3390/s21082727&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.3390/s21082727&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Celik, Y., Stuart, S., Woo, W. L., &amp;amp; Godfrey, A. (2021). Gait analysis in neurological populations: Progression in the use of wearables. Medical Engineering &amp;amp; Physics, 87, 9–29. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/J.MEDENGPHY.2020.11.005&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/J.MEDENGPHY.2020.11.005&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Phase Portraits</title>
        <link>https://K7288.github.io/posts/phase-portrait/</link>
        <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/phase-portrait/</guid>
        <description>&lt;h2 id=&#34;studies-using-phase-portraits&#34;&gt;Studies using phase portraits&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Authors and year&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Axes&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Task&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;#holgate-et-al2009&#34; &gt;Holgate et al. 2009&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Tibia angle &amp;amp; tibia scaled angular velocity&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Continuous gait phase estimation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;#villarreal-et-al2017&#34; &gt;Villarreal et al.,2017&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Thigh angle &amp;amp; its derivative(estimated thigh velocity)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Continuous gait phase estimation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;#quintero-et-al2017&#34; &gt;Quintero et al.,2017&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Thigh angle &amp;amp; its derivative(estimated thigh velocity)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Continuous gait phase estimation; gait speed estimation(as a byproduct)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;a class=&#34;link&#34; href=&#34;#quintero-et-al2018&#34; &gt;Quintero et al. 2018&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Thigh angle &amp;amp; its integral&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Continuous gait phase estimation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;holgate-et-al2009&#34;&gt;Holgate et al.,2009&lt;/h2&gt;
&lt;p&gt;Holgate et al.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;: The polar angle between the &lt;strong&gt;tibia angle&lt;/strong&gt; and its &lt;strong&gt;scaled angular velocity&lt;/strong&gt; has an invertible relationship with the gait phase and is not subject-dependent.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/5152565-fig-4-source-large.gif&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Tibia angular velocity multiplied by a scaling factor versus tibia angle. The closer the curve is to the origin, the shorter the stride length. Polar angle $\Phi$ represents the progression around the curve based on gait percent. $r$ is the polar radius and is related to the stride length of the particular curve.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/5152565-fig-3-source-large.gif&#34; alt=&#34;img&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Tibia angle profile for able bodied human gait. Each curve represents a different stride length. The closer the curve is to the zero degree axis, the shorter the stride length.&lt;/p&gt;
&lt;h2 id=&#34;villarreal-et-al2017&#34;&gt;Villarreal et al.,2017&lt;/h2&gt;
&lt;p&gt;The phase portrait was scaled by a factor estimated by the ratio of difference in maximum phase angle and minimum phase angle to the difference in the first derivative of the same, so as to improve the monotonicity and linearity. These properties were further improved by filtering, at the expense of some delay. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/gregg2-2569019-large.gif&#34; alt=&#34;&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;quintero-et-al2017&#34;&gt;Quintero et al.,2017&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The raw thigh orbit (raw) compared to the interpolated filtered, shifted/scaled thigh orbit (interp + shift/scale) in the phase plane for 20 continuous strides at 3 mph. Applying the shift and scale algorithm produces a circular orbit shape, in contrast to the raw non-circular orbit.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/8062565-fig-4-source-large.gif&#34; style=&#34;zoom:120%; &#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The phase portrait of $\dot\theta_y(t)$ vs. $θ_x(t)$ across various treadmill speeds (1–9 mph) each having 20 consecutive gait strides. The polar radius $r$ can be correlated to the subject&amp;rsquo;s gait speed. speeds &amp;lt; 4mph produced a circular orbit from 0 to 2$\pi$ (i.e., 0% to 100% gait cycle). At 5 mph, the subject transitioned from fast walking to running, where more forceful ground impacts can be observed in the IMU measurements due to the flight phase. this produced a non-circular form after impact with intersection of other orbits at different speeds, as shown in the first quadrant for 5–6 mph.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/8062565-fig-6-source-small.gif&#34; alt=&#34;&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;quintero-et-al2018&#34;&gt;Quintero et al.,2018&lt;/h2&gt;
&lt;p&gt;Quintero et al.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;: &lt;strong&gt;thigh angular position&lt;/strong&gt; and its corresponding &lt;strong&gt;integral&lt;/strong&gt; to form a well-defined thigh orbit.&lt;/p&gt;
&lt;p&gt;A phase angle $ \vartheta (t) $ is computed by utilizing thigh angular position $\phi(t)$ and its integral $\Phi(t)=\int ^t_0\phi(τ)dτ $in the following way:
$$
\vartheta (t) =\mathrm{atan2}((\Phi (t) + \Gamma)z, (\phi (t) +\gamma)) 
$$
where the scale factor z, the thigh angle shift γ, and the thigh integral shift Γ are given by
$$
z= \frac{|\phi _{\rm max} - \phi _{\rm min}|}{|\Phi _{\rm max} - \Phi _{\rm min}|}, \gamma = -(\frac{\phi _{\rm max} + \phi _{\rm min}}{2}), \ \ \Gamma = -(\frac{\Phi _{\rm max} + \Phi _{\rm min}}{2}).
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Phase plane of the thigh angle ϕ(t) vs. its integral Φ(t) during prosthetic leg experiments (see Section IV). The phase plane has been scaled by z and shifted by (γ,Γ) to achieve a circular orbit across the stride, which improves the linearity of the phase variable ϑ(t).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/gregg3-2794536-large.gif&#34; alt=&#34;img&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;M. A. Holgate, T. G. Sugar, and A. W. Bohler, “A novel control algorithm for wearable robotics using phase plane invariants,” in 2009 IEEE International Conference on Robotics and Automation, pp. 3845–3850, Kobe, Japan, 2009.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. J. Villarreal, H. A. Poonawala and R. D. Gregg, &amp;ldquo;A Robust Parameterization of Human Gait Patterns Across Phase-Shifting Perturbations,&amp;rdquo; in &lt;em&gt;IEEE Transactions on Neural Systems and Rehabilitation Engineering&lt;/em&gt;, vol. 25, no. 3, pp. 265-278, March 2017, doi: 10.1109/TNSRE.2016.2569019.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Quintero, D. J. Lambert, D. J. Villarreal and R. D. Gregg, &amp;ldquo;Real-Time continuous gait phase and speed estimation from a single sensor,&amp;rdquo; &lt;em&gt;2017 IEEE Conference on Control Technology and Applications (CCTA)&lt;/em&gt;, 2017, pp. 847-852, doi: 10.1109/CCTA.2017.8062565.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Quintero, D. J. Villarreal, D. J. Lambert, S. Kapp, and R. D. Gregg, “Continuous-phase control of a powered knee-ankle prosthesis: amputee experiments across speeds and inclines,” IEEE Transactions on Robotics, vol. 34, no. 3, pp. 686–701, 2018.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Sensors for Gait Analysis</title>
        <link>https://K7288.github.io/posts/sensors-for-gait-analysis/</link>
        <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/sensors-for-gait-analysis/</guid>
        <description>&lt;h1 id=&#34;sensors-for-gait-analysis&#34;&gt;Sensors for Gait Analysis&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#sensors-for-gait-analysis&#34; &gt;Sensors for Gait Analysis&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#sensors&#34; &gt;Sensors&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#inertial-measurement-units&#34; &gt;Inertial Measurement Units&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#sensor-placement&#34; &gt;Sensor placement&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#preference-in-literature&#34; &gt;Preference in literature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#inter--and-intra-segments-to-choose&#34; &gt;(inter- and intra=) Segments to choose&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#filter&#34; &gt;Filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#application&#34; &gt;Application&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#insole-pressure-sensors&#34; &gt;Insole pressure sensors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sensors&#34;&gt;Sensors&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:30 0px&#34;&gt;Distribution of studies based on the type of wearable sensors used&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:300px&#34;&gt;Distribution of studies based on the type of sensors used for &lt;code&gt;ground-truth validation of IMU&lt;/code&gt;-based gait analysis. Absolute number of studies in each category is listed within parentheses.&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;https://K7288.github.io/assets/sensors-21-02727-g005_2.jpg&#34; style=&#34;zoom:30%;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;https://K7288.github.io/assets/sensors-21-02727-g005_3.jpg&#34; style=&#34;zoom:30%;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;IMU—inertial measurement unit, IPS—insole pressure sensor, EMG—electromyography sensor.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Only 11% of studies using a rule-based method required the placement of more than one IMU per leg, in contrast to 53% of machine learning approaches. This means applications using the rule-based methods typically require a less complex sensor setup, which would be preferable to the end-user. Furthermore, in 84% of studies using rule-based methods, the approach could be used independently for one leg or the other, compared to 47% for machine learning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h3 id=&#34;inertial-measurement-units&#34;&gt;Inertial Measurement Units&lt;/h3&gt;
&lt;h4 id=&#34;sensor-placement&#34;&gt;Sensor placement&lt;/h4&gt;
&lt;h5 id=&#34;preference-in-literature&#34;&gt;Preference in literature&lt;/h5&gt;
&lt;blockquote&gt;
&lt;p&gt;Number of studies using inertial measurement units (IMUs) that placed the sensor(s) on specific anatomical locations. Single placement contains studies where sensor(s) were placed only in one anatomical location. Placement combinations’ columns indicate studies where sensor(s) were placed in more than one location. Each relevant location is marked by a shaded cell and the number of studies using this combination is indicated at the bottom of the column. The total indicates the sum of studies where the sensor(s) were placed on that given anatomical location.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mdpi.com/sensors/sensors-21-02727/article_deploy/html/images/sensors-21-02727-g006.png&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;inter--and-intra-segments-to-choose&#34;&gt;(inter- and intra=) Segments to choose&lt;/h5&gt;
&lt;p&gt;Foot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Li et al., 2016&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;: compared IMU signals from the thigh, the shank and the foot, based on the &lt;u&gt;stability of “energy of acceleration”&lt;/u&gt; which is the norm of raw acceleration minus gravity&lt;/li&gt;
&lt;li&gt;Jasiewicz et al., 2006&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;: significantly more accuracy in &lt;u&gt;gait event detection&lt;/u&gt; methods&lt;/li&gt;
&lt;li&gt;Taborri et al., 2014&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;: better accuracy of a HMM-based classifier for &lt;u&gt;gait event detection&lt;/u&gt; when using data of the foot.&lt;/li&gt;
&lt;li&gt;Wenger, N. et al., 2015&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;: &lt;u&gt;neuro-behavioral experiments&lt;/u&gt; suggesting that limb endpoints are the primary variables used to coordinate locomotion in animals and humans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shank&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bejarano et al., 2013&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;: the root mean square error between each cycle (as well as the average)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Irrelevant (in some tasks)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mazilu et al., 2012&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;: in the context of freezing of gait&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Intra-segment&lt;/p&gt;
&lt;p&gt;​	mount/socket; Anwary et al.&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;: the medial arch followed by the Achilles tendon(also the centre point of foot length; location 1 🔽); based on accuracy of extracted features: Number of Strides, Distance, Speed, Stride Length, Stride Period, Stance Length, Stance Period, Swing Length, Swing Period and ratio of stance and swing&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/7361/8299495/8246577/yu2-2786587-large.gif&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;filter&#34;&gt;Filter&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;39 out of 69 studies at least used a preprocessing filter, 31 of which used a low-pass filter among which 15 used the Butterworth low-pass filter. Note that preprocessing filters add to the latency in data processing, which is undesirable in a real-time system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;application&#34;&gt;Application&lt;/h4&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://k7288.github.io/assets/image-20210716105523059.png&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210716105523059.png&#34; alt=&#34;image-20210716105523059&#34;  /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;insole-pressure-sensors&#34;&gt;Insole pressure sensors&lt;/h3&gt;
&lt;p&gt;Only six out of 28 studies related to IPS used any sort of preprocessing/filtering. Instead, these studies relied directly on the raw signal from the IPS, likely contributing to shorter latency, an advantage when it comes to real-time systems.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Li, F.; Liu, G.; Liu, J.; Chen, X.; Ma, X. 3D Tracking via Shoe Sensing. &lt;em&gt;Sensors&lt;/em&gt; &lt;strong&gt;2016&lt;/strong&gt;, &lt;em&gt;16&lt;/em&gt;, 1809. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=3D&amp;#43;Tracking&amp;#43;via&amp;#43;Shoe&amp;#43;Sensing&amp;amp;author=Li,&amp;#43;F.&amp;amp;author=Liu,&amp;#43;G.&amp;amp;author=Liu,&amp;#43;J.&amp;amp;author=Chen,&amp;#43;X.&amp;amp;author=Ma,&amp;#43;X.&amp;amp;publication_year=2016&amp;amp;journal=Sensors&amp;amp;volume=16&amp;amp;pages=1809&amp;amp;doi=10.3390/s16111809&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;] [&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.3390/s16111809&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CrossRef&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Jasiewicz, J.M.; Allum, J.H.; Middleton, J.W.; Barriskill, A.; Condie, P.; Purcell, B.; Li, R.C.T. Gait event detection using linear accelerometers or angular velocity transducers in able-bodied and spinal-cord injured individuals. &lt;em&gt;Gait Posture&lt;/em&gt; &lt;strong&gt;2006&lt;/strong&gt;, &lt;em&gt;24&lt;/em&gt;, 502–509. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=Gait&amp;#43;event&amp;#43;detection&amp;#43;using&amp;#43;linear&amp;#43;accelerometers&amp;#43;or&amp;#43;angular&amp;#43;velocity&amp;#43;transducers&amp;#43;in&amp;#43;able-bodied&amp;#43;and&amp;#43;spinal-cord&amp;#43;injured&amp;#43;individuals&amp;amp;author=Jasiewicz,&amp;#43;J.M.&amp;amp;author=Allum,&amp;#43;J.H.&amp;amp;author=Middleton,&amp;#43;J.W.&amp;amp;author=Barriskill,&amp;#43;A.&amp;amp;author=Condie,&amp;#43;P.&amp;amp;author=Purcell,&amp;#43;B.&amp;amp;author=Li,&amp;#43;R.C.T.&amp;amp;publication_year=2006&amp;amp;journal=Gait&amp;#43;Posture&amp;amp;volume=24&amp;amp;pages=502%e2%80%93509&amp;amp;doi=10.1016/j.gaitpost.2005.12.017&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;] [&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2005.12.017&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CrossRef&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Taborri, J.; Rossi, S.; Palermo, E.; Patanè, F.; Cappa, P. A novel HMM distributed classifier for the detection of gait phases by means of a wearable inertial sensor network. &lt;em&gt;Sensors&lt;/em&gt; &lt;strong&gt;2014&lt;/strong&gt;, &lt;em&gt;14&lt;/em&gt;, 16212–16234. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=A&amp;#43;novel&amp;#43;HMM&amp;#43;distributed&amp;#43;classifier&amp;#43;for&amp;#43;the&amp;#43;detection&amp;#43;of&amp;#43;gait&amp;#43;phases&amp;#43;by&amp;#43;means&amp;#43;of&amp;#43;a&amp;#43;wearable&amp;#43;inertial&amp;#43;sensor&amp;#43;network&amp;amp;author=Taborri,&amp;#43;J.&amp;amp;author=Rossi,&amp;#43;S.&amp;amp;author=Palermo,&amp;#43;E.&amp;amp;author=Patan%c3%a8,&amp;#43;F.&amp;amp;author=Cappa,&amp;#43;P.&amp;amp;publication_year=2014&amp;amp;journal=Sensors&amp;amp;volume=14&amp;amp;pages=16212%e2%80%9316234&amp;amp;doi=10.3390/s140916212&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;] [&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.3390/s140916212&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CrossRef&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Wenger, N.; Moraud, E.M.; Raspopovic, S.; Bonizzato, M.; DiGiovanna, J.; Musienko, P.; Morari, M.; Micera, S.; Courtine, G. Closed-loop neuromodulation of spinal sensorimotor circuits controls refined locomotion after complete spinal cord injury. &lt;em&gt;Sci. Transl. Med.&lt;/em&gt; &lt;strong&gt;2014&lt;/strong&gt;, &lt;em&gt;6&lt;/em&gt;, 255ra133. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=Closed-loop&amp;#43;neuromodulation&amp;#43;of&amp;#43;spinal&amp;#43;sensorimotor&amp;#43;circuits&amp;#43;controls&amp;#43;refined&amp;#43;locomotion&amp;#43;after&amp;#43;complete&amp;#43;spinal&amp;#43;cord&amp;#43;injury&amp;amp;author=Wenger,&amp;#43;N.&amp;amp;author=Moraud,&amp;#43;E.M.&amp;amp;author=Raspopovic,&amp;#43;S.&amp;amp;author=Bonizzato,&amp;#43;M.&amp;amp;author=DiGiovanna,&amp;#43;J.&amp;amp;author=Musienko,&amp;#43;P.&amp;amp;author=Morari,&amp;#43;M.&amp;amp;author=Micera,&amp;#43;S.&amp;amp;author=Courtine,&amp;#43;G.&amp;amp;publication_year=2014&amp;amp;journal=Sci.&amp;#43;Transl.&amp;#43;Med.&amp;amp;volume=6&amp;amp;pages=255ra133&amp;amp;doi=10.1126/scitranslmed.3008325&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;] [&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1126/scitranslmed.3008325&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CrossRef&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Bejarano, N.C.; Ambrosini, E.; Pedrocchi, A.; Ferrigno, G.; Monticone, M.; Ferrante, S. An adaptive real-time algorithm to detect gait events using inertial sensors. In Proceedings of the XIII Mediterranean Conference on Medical and Biological Engineering and Computing 2013, Seville, Spain, 25–28 September 2013; pp. 1799–1802. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=An&amp;#43;adaptive&amp;#43;real-time&amp;#43;algorithm&amp;#43;to&amp;#43;detect&amp;#43;gait&amp;#43;events&amp;#43;using&amp;#43;inertial&amp;#43;sensors&amp;amp;conference=Proceedings&amp;#43;of&amp;#43;the&amp;#43;XIII&amp;#43;Mediterranean&amp;#43;Conference&amp;#43;on&amp;#43;Medical&amp;#43;and&amp;#43;Biological&amp;#43;Engineering&amp;#43;and&amp;#43;Computing&amp;#43;2013&amp;amp;author=Bejarano,&amp;#43;N.C.&amp;amp;author=Ambrosini,&amp;#43;E.&amp;amp;author=Pedrocchi,&amp;#43;A.&amp;amp;author=Ferrigno,&amp;#43;G.&amp;amp;author=Monticone,&amp;#43;M.&amp;amp;author=Ferrante,&amp;#43;S.&amp;amp;publication_year=2013&amp;amp;pages=1799%e2%80%931802&amp;amp;doi=10.1007/978-3-319-00846-2_444&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;] [&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1007/978-3-319-00846-2_444&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CrossRef&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Mazilu, S.; Hardegger, M.; Zhu, Z.; Roggen, D.; Troster, G.; Plotnik, M.; Hausdorff, J.M. Online detection of freezing of gait with smartphones and machine learning techniques. In Proceedings of the 2012 6th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth), San Diego, CA, USA, 21–24 May 2012; pp. 123–130. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=Online&amp;#43;detection&amp;#43;of&amp;#43;freezing&amp;#43;of&amp;#43;gait&amp;#43;with&amp;#43;smartphones&amp;#43;and&amp;#43;machine&amp;#43;learning&amp;#43;techniques&amp;amp;conference=Proceedings&amp;#43;of&amp;#43;the&amp;#43;2012&amp;#43;6th&amp;#43;International&amp;#43;Conference&amp;#43;on&amp;#43;Pervasive&amp;#43;Computing&amp;#43;Technologies&amp;#43;for&amp;#43;Healthcare&amp;#43;%28PervasiveHealth%29&amp;amp;author=Mazilu,&amp;#43;S.&amp;amp;author=Hardegger,&amp;#43;M.&amp;amp;author=Zhu,&amp;#43;Z.&amp;amp;author=Roggen,&amp;#43;D.&amp;amp;author=Troster,&amp;#43;G.&amp;amp;author=Plotnik,&amp;#43;M.&amp;amp;author=Hausdorff,&amp;#43;J.M.&amp;amp;publication_year=2012&amp;amp;pages=123%e2%80%93130&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Anwary, A.R.; Yu, H.; Vassallo, M. Optimal foot location for placing wearable IMU sensors and automatic feature extraction for gait analysis. &lt;em&gt;IEEE Sens. J.&lt;/em&gt; &lt;strong&gt;2017&lt;/strong&gt;, &lt;em&gt;18&lt;/em&gt;, 2555–2567. [&lt;a class=&#34;link&#34; href=&#34;https://scholar.google.com/scholar_lookup?title=Optimal&amp;#43;foot&amp;#43;location&amp;#43;for&amp;#43;placing&amp;#43;wearable&amp;#43;IMU&amp;#43;sensors&amp;#43;and&amp;#43;automatic&amp;#43;feature&amp;#43;extraction&amp;#43;for&amp;#43;gait&amp;#43;analysis&amp;amp;author=Anwary,&amp;#43;A.R.&amp;amp;author=Yu,&amp;#43;H.&amp;amp;author=Vassallo,&amp;#43;M.&amp;amp;publication_year=2017&amp;amp;journal=IEEE&amp;#43;Sens.&amp;#43;J.&amp;amp;volume=18&amp;amp;pages=2555%e2%80%932567&amp;amp;doi=10.1109/JSEN.2017.2786587&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Scholar&lt;/a&gt;] [&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1109/JSEN.2017.2786587&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CrossRef&lt;/a&gt;]&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Before Taking A Recording</title>
        <link>https://K7288.github.io/posts/before-taking-a-recording/</link>
        <pubDate>Fri, 09 Jul 2021 22:00:09 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/before-taking-a-recording/</guid>
        <description>&lt;h1 id=&#34;before-taking-a-recording&#34;&gt;Before Taking A Recording&lt;/h1&gt;
&lt;p&gt;* means &amp;ldquo;optinal&amp;rdquo;; 此处的定义和步骤均参考Tekscan的F-Scan User Manual&lt;/p&gt;
&lt;h2 id=&#34;preparing-the-patient&#34;&gt;Preparing the Patient&lt;/h2&gt;
&lt;p&gt;trim the sensor; set up the testing area; set up the system hardware; weigh the patient; outfit the patient.&lt;/p&gt;
&lt;h2 id=&#34;zeroing-the-sensor&#34;&gt;*Zeroing the Sensor&lt;/h2&gt;
&lt;p&gt;当整个实验过程中鞋垫上始终有额外压力时使用；类似称重的去皮；&lt;/p&gt;
&lt;h2 id=&#34;equilibration&#34;&gt;*Equilibration&lt;/h2&gt;
&lt;p&gt;在鞋垫上放置均匀重物；&lt;/p&gt;
&lt;h2 id=&#34;calibration&#34;&gt;Calibration&lt;/h2&gt;
&lt;h3 id=&#34;point-calibration&#34;&gt;Point Calibration&lt;/h3&gt;
&lt;p&gt;校准时间取决于实际行走过程，快的人1s，慢的2s&lt;/p&gt;
&lt;p&gt;先抬起待校准脚，放下同时重量全部集中在该脚上，放下后很快（间隔1s）实验人员点击校准（实测这样不行，还是要稍微稳定一下再开始标定。）&lt;/p&gt;
&lt;p&gt;可以用手指在竖直墙面上轻点辅助稳定。（实测+官方文档）&lt;/p&gt;
&lt;p&gt;稳定后传感器压力持续上升，可以只看前n秒来判断标定是否正确。(n=5~10)&lt;/p&gt;
&lt;h3 id=&#34;extended-calibration&#34;&gt;Extended Calibration&lt;/h3&gt;
&lt;p&gt;是点校准的延伸；默认开启；在两个均采用点校准的sensor测量完成后基于体重调整两sensor的校准（by an equal amount）to correct for the differing &amp;ldquo;drift&amp;rdquo; times that occur between your calibration and the actual test.&lt;/p&gt;
&lt;p&gt;进行此校准要求两脚均必须满3steps $\Rightarrow$ 不然会提示“步态扩展不足”&lt;img src=&#34;https://K7288.github.io/assets/image-20210712093930692.png&#34; alt=&#34;image-20210712093930692&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;打✔️开启&lt;img src=&#34;https://K7288.github.io/assets/image-20210712093802855.png&#34; alt=&#34;image-20210712093802855&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-calibration&#34;&gt;Step Calibration&lt;/h3&gt;
&lt;p&gt;To initiate Step calibration, initially, the subject stands entirely &lt;strong&gt;on the foot to be off-loaded&lt;/strong&gt;. The user clicks the Start button, and a timer appears in the calibration window. After a second or two, the computer directs the subject to rapidly shift their weight onto the foot to be calibrated and keep their weight applied for five to ten seconds.&lt;/p&gt;
&lt;p&gt;It is important that the subject be “steady” during the calibration process. For example, the subject should be encouraged to touch a vertical surface at about the height of their ear with a finger or two. In many labs there is a wall or pillar that provides a good vertical surface. This steadies the subject without changing the vertical force. If the subject wobbles or shifts their weight on the calibration foot, the computer will reject the trial and provide a message to the user.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210710095637119.png&#34; alt=&#34;image-20210710095637119&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For most research, Step calibration is expected to be the most accurate technique.&lt;/strong&gt; Step calibration has both a factor for rapid dynamic changes and compensates for time related changes in sensor output.&lt;/p&gt;
&lt;h3 id=&#34;verify-your-calibrationpointstep&#34;&gt;Verify your calibration(Point/Step)&lt;/h3&gt;
&lt;p&gt;Have your subject walk in place for a few steps while you take a recording. Select &lt;strong&gt;Show Panes&lt;/strong&gt; and select &lt;strong&gt;New Graph&lt;/strong&gt;. The force curves for each window should be roughly the same amplitude and duration. Additionally, output numbers of the calibrated window should be +/- 10% of the patient’s body weight. Note: You may have to rotate the Real-time Window to see the &amp;ldquo;Force&amp;rdquo; display.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210709222807276.png&#34; alt=&#34;image-20210709222807276&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;walk-calibration&#34;&gt;Walk Calibration&lt;/h3&gt;
&lt;p&gt;Walk calibration functions automatically, without the requirement for an additional maneuver by the subject. Walk calibration is accomplished for the left and right foot together. Walk calibration is &lt;strong&gt;done automatically after the trial of interest is recorded.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每一次movie都生成一个相应的校准&lt;/p&gt;
&lt;p&gt;要求subject步行，不能慢跑或跳跃；也需要在摆动相全部体重集中在一只脚上&lt;/p&gt;
&lt;p&gt;Walk calibration is expected to be most effective clinically, where most subjects are walking at a normal pace. Because the calibration is automatic, Walk calibration is quicker, increasing the number of subjects that can be seen in an hour, or increasing the number of trials that can be performed. Walk calibration can be used with subjects who cannot stand on one foot for ten seconds. It is not expected to be as accurate as step calibration.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons</title>
        <link>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</link>
        <pubDate>Thu, 08 Jul 2021 14:29:01 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</guid>
        <description>&lt;p&gt;A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons&lt;/p&gt;
&lt;p&gt;intention定义: walk/stride across/stop state&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;analysis of gait planning based on a human kinematics model and real-time motion stability based on the zero-moment point (ZMP).&lt;/li&gt;
&lt;li&gt;a neural interface based on sEMG to achieve motion intention recognition and muscle fatigue estimation.&lt;/li&gt;
&lt;li&gt;to verify the stability of human–exoskeleton system and ergonomic effects of the proposed gait switching method by organized experiments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210710143319290-1625899646300.png&#34; alt=&#34;image-20210710143319290&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一些商用外骨骼&lt;/p&gt;
&lt;p&gt;Exoskeleton robots require the human interface to provide walking stability so that it may function as a flexible assistant. Such robots have been developed by commercial companies including Rewalk (Talaty et al., 2013), Ekso Bionics (Baunsgaard et al., 2018), Ailegs (Chen et al., 2018), and MaiBu BEAR H1. Exoskeleton robots especially require the walking stability as far as possible so as to provide flexible assistant. The Hybrid Assistive Limb (HAL) (Shimizu et al., 2019), which takes advantage of sEMG in control strategy, was designed by the robotics company Cyberdyne (Yilmaz et al., 2018).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;研究机构和大学的外骨骼&lt;/p&gt;
&lt;p&gt;Sogang University in Korea developed a exoskeleton namely SUBAR (Chen et al., 2013; Hwang and Jeon, 2018), which could &lt;strong&gt;estimate the muscular torque of its wearer&lt;/strong&gt;. Singapore’s Nanyang Technological University (Mertz, 2012) and Harvard University (Abe et al., 2018) have also made solid progress in the development of assisted exoskeletons. The Chinese University of Science and Technology designed an exoskeleton robot driven by a servo motor (Li et al., 2019) and developed a fuzzy algorithm for lower extremity exoskeleton (Huang et al., 2016a). The exoskeleton team of H. C. from University of Electronic Science and Technology of China have developed exoskeletons for paraplegia (Huang et al., 2018), hemiplegia patients (Peng et al., 2020), and human-power augmentation (Huang et al., 2016b, 2019). The exoskeleton group at the Shenzhen Institutes of Advanced Technology of the Chinese Academy of Sciences has developed the fourth generation of the SIAT exoskeleton robot. With four degrees of freedom (DoFs), this exoskeleton robot has successfully enabled persons with disabilities to stand up and walk independently (Liu et al., 2017; Wang et al., 2018a).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;While investigating the existing exoskeleton control methods, we found very few studies that have examined the minimum force requirements into the control scheme by the wearer. We also found scarce consideration for the state of the wearer while operating a lower limb exoskeleton.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;h3 id=&#34;gait-planning&#34;&gt;Gait Planning&lt;/h3&gt;
&lt;p&gt;We initially treat these two joints as two points and draw the trajectories of these points during the walking process to determine the trajectory approximating the sine function (Chen et al., 2019)&lt;/p&gt;
&lt;h3 id=&#34;motion-intention-recognition&#34;&gt;Motion Intention Recognition&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210710163446929.png&#34; alt=&#34;image-20210710163446929&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;muscle-fatigue-estimation&#34;&gt;Muscle Fatigue Estimation&lt;/h3&gt;
&lt;p&gt;the wavelet packet energy entropy (WPEE)&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210710165904286.png&#34; alt=&#34;image-20210710165904286&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210710170024701.png&#34; alt=&#34;image-20210710170024701&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;p&gt;这个虽然用到了COP/ZMP，但是因为是康复外骨骼有俩拐杖应该不能直接用它这个公式，但是计算方法可以看一下&lt;/p&gt;
&lt;p&gt;这通篇读下来也没看出来哪里control了啊，就三个模式检测出来直接上对应的机器状态，不愧是康复型&lt;/p&gt;
</description>
        </item>
        <item>
        <title>A novel motion intention recognition approach for soft exoskeleton via IMU</title>
        <link>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</link>
        <pubDate>Thu, 08 Jul 2021 09:05:01 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</guid>
        <description>&lt;p&gt;A novel motion intention recognition approach for soft exoskeleton via IMU&lt;/p&gt;
&lt;p&gt;intention定义: the classic five kinds of terrains(including walking on flat ground, going up and downstairs, and up and down slopes) &amp;amp; transformed terrains&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Abbreviation&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Definition&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Abbreviation&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Definition&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;IMU&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Inertial measurement unit&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;SA&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stair ascent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;DDLMI&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;DNN-based deep locomotion mode identification&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;SD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stair decent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ISR&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Identification success rate&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;RA&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Ramp ascent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;LW&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Level-ground walking&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;RD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Ramp decent&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;to propose a recognition method with historical information based on neural network to recognize different terrain and add the pattern transformation recognition, trying to predict the next motion mode in advance.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;前人的一些工作&lt;/p&gt;
&lt;p&gt;The recognition of locomotion patterns in different terrains is a base for soft exoskeleton to achieve precise control. Several motion recognition methods have been proposed for different types of signals [6]. Electromyography (EMG) is one of the most important signals in motor pattern recognition [6,7]. Based on the EMG signal controller, Michael et al. [8] proposed a recognition method for walking on flat ground, ramps up and downhill. Joshi et al. [6] present a classification method to recognize walking on ground, ascending stairs and the transition between these motions using the spectrogram of EMG signal. Another accessible signal is ground reaction force (GRF), usually collected by a plantar pressure sensor on insole [9–11]. Duc Nguyen et al. [12] extracted plantar pressure data as input features, and proposed five classical motion pattern recognition methods by using the K-nearest neighbor (KNN) classification method. Chen et al. [13] identified different motion patterns through wearable capacitance sensors without requiring real-time gait conversion. Li et al. [14] used the threshold method based on inertial measurement unit (IMU) to identify horizontal ground, staircase rise/fall and slope rise/fall, which required only a few sensors and low computation. However, there is a phase delay in the transition to identification. Multi-sensor fusion, which is able to enhance system performance and robustness, has been widely used in recent years [15–17]. In [18], a neural muscle mechanical fusion motion pattern recognition algorithm combining EMG and GRF is proposed, which involves installing seven or more electrodes in the extremities and an insole with a pressure sensor at the foot of a healthy limb. Ma et al. [19] proposed a kernel recursive least-squares method (KRLS) to show the model generalization abilities. &amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其他sensor的缺点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;EMG is often used to recognize biological signals of motion patterns. However, the electrode of the EMG signal must stick to the surface of the human skin. Once the human body perspires, the wire will fall off, which brings a lot of trouble to practical application [22].&lt;/li&gt;
&lt;li&gt;GRF is ineffective on uneven ground where the swing phase and the pressure sensor are not in full contact, even though it is readily available.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-structure-of-exoskeleton-and-analysis-of-motion-characteristics&#34;&gt;The Structure of Exoskeleton and Analysis of Motion Characteristics&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708095757790.png&#34; alt=&#34;image-20210708095757790&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708100858161.png&#34; alt=&#34;image-20210708100858161&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708103300498.png&#34; alt=&#34;image-20210708103300498&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;h3 id=&#34;gait-data-process&#34;&gt;Gait Data Process&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;mean filter with a window length of three
$$
\begin{cases}\begin{array}{l}
\theta_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} \theta_{i}(t-j),\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\{r h,l h, r k, l k\}\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases}
$$
where $ \theta $ is the joint angle at time  t  before filtering and $ \theta^{\prime} $ is the corresponding joint angle after filtering. In the same way, $ a, a^{\prime}, w, w^{\prime} $.  Here, $ i $ denotes one of the six joints, and $ j $ is the tag of a window.&lt;/p&gt;
&lt;p&gt;Therefore, the characteristics of the DDLMI model are characterized according to Equation (2):&lt;/p&gt;
&lt;p&gt;$x=[\theta_{i}, a_{i}, w_{i}]^{T}, i=\{r h,  l h,  r k,  l k\}\Rightarrow$ input: joint angle, angular acceleration and angular velocity(an axis angle (x), two axes (XY) acceleration and two axes (YZ) angular velocity)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;max-min normalization&lt;/p&gt;
&lt;p&gt;standardize the input vector elements to the range of [−1, 1]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a sliding window&lt;/p&gt;
&lt;p&gt;Each window sequence is a training sample. In this paper, the window size is set to 100, and the step size is 50. 单位是啥❓&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;locomotion-mode-identification&#34;&gt;Locomotion Mode Identification&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708140622072.png&#34; alt=&#34;image-20210708140622072&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;performance-evaluation&#34;&gt;Performance Evaluation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Steady Locomotion Period&lt;/strong&gt;: the identification success rate $\text{ISR}=\frac{N_{\text{correct}}}{N_{\text{total}}}$; the confusion matrix&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Locomotion Transition Period&lt;/strong&gt;: to judge whether the conversion pattern recognition is timely; $D_{I}=\frac{T_{i}-T_{c}}{T} * 100 \%$ where $ T_{i} $ is the moment when locomotion transition is identified, $ T_{c} $ is the critical moment, the moment when the user starts to change the current locomotion mode, and $ T $ is the average time of a gait cycle.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708142419934.png&#34; alt=&#34;image-20210708142419934&#34; style=&#34;zoom:23%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708142441984.png&#34; alt=&#34;image-20210708142441984&#34; style=&#34;zoom:23%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708142508314.png&#34; alt=&#34;image-20210708142508314&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708142524704.png&#34; alt=&#34;image-20210708142524704&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210708142633949.png&#34; alt=&#34;image-20210708142633949&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;highlights&#34;&gt;Highlights&lt;/h2&gt;
&lt;p&gt;sensors用得少；识别及预测transition&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TODO这个intro部分涉及的还挺全面的，之后看一下&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TODO 回头看一下基于interaction force具体是怎么做的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TODO 对IMU数据的处理&amp;amp;可靠性验证&lt;/p&gt;
&lt;p&gt;The angle information used in this paper is directly output by IMU, and there is a 90-degree difference with the actual hip posture angle. Therefore, 90 degrees should be subtracted from the original angle information when compared with the attitude angle obtained by Vicon system dynamic capture in [25]. One-way &lt;strong&gt;ANOVA&lt;/strong&gt; showed that there was no significant difference in F value at the level of a = 0.01. Therefore, the inertial measurement system used in this paper is reliable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;也用到了滑窗法增强数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
        <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
        <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
        <description>&lt;p&gt;Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach&lt;/p&gt;
&lt;p&gt;intention定义: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;to propose an automatic, &lt;strong&gt;user-independent&lt;/strong&gt; recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;EMG的一些drawback&lt;/li&gt;
&lt;li&gt;之前的一些人的分类工作&lt;/li&gt;
&lt;li&gt;它说预测的少，而且很少有达到“预”测&lt;/li&gt;
&lt;li&gt;一些工作规定被试用a predefined limb进行transition&lt;/li&gt;
&lt;li&gt;a set of challenges&lt;/li&gt;
&lt;li&gt;总之就是说这个工作前面做的人少而且有challenges并且没人只用kinematic data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;Sensors: 7 IMUs&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707192136762.png&#34; alt=&#34;image-20210707192136762&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707194610843.png&#34; alt=&#34;image-20210707194610843&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707193002245.png&#34; alt=&#34;image-20210707193002245&#34; style=&#34;zoom:45%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据滤波: 1st order low- pass filter (exponential smoothing) with 0.5 as the smoothing factor and a cut-off of 10 Hz [13]. 一阶低通滤波器(指数平滑)，平滑因子为0.5，截止频率为10hz&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;feature-calculation&#34;&gt;feature calculation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;feature是一个窗口的；也探究window size的影响&lt;/li&gt;
&lt;li&gt;feature两腿都有；两种方式：左腿右腿；前腿后腿the leading and opposite legs&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pre-processing&#34;&gt;pre-processing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;normalization: compared different normalization techniques, namely centering, z-score standardization, and min-max scaling&lt;/li&gt;
&lt;li&gt;filter feature selection: minimum-redundancy maximum-relevancy (mRMR) algorithm to rank features in descending order according to their relevance [19]. Then, we used the ANOVA, starting on the highest-ranked feature, to assess which classes are distinguishable for the feature considering the feature’s mean and variance per class. This procedure was done until there are a set of features that distinguish between all classes. mRMR找强关联项; ANOVA去除冗余特征&lt;/li&gt;
&lt;li&gt;feature extraction: principal component analysis (PCA) considering the Horn’s Parallel Analysis as a cut-off criterium&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-labeling&#34;&gt;data labeling&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707202933670.png&#34; alt=&#34;image-20210707202933670&#34; style=&#34;zoom:47%;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;model-building&#34;&gt;model building&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;wrapper methods: mRMR排序，由高到低依次检验，如果有提升则加到feature set里; ‘‘forward selection plus backward selection’’,类似剪枝&lt;/li&gt;
&lt;li&gt;hyperparameter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707210012031.png&#34; alt=&#34;image-20210707210012031&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;实验&#34;&gt;实验&lt;/h3&gt;
&lt;p&gt;Mathew’s correlation coefficient (MCC) for both comparison and reporting of model’s performances due to its good representative properties of &lt;strong&gt;unbalanced classes&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707210104931.png&#34; alt=&#34;image-20210707210104931&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The most effective machine learning configuration includes min-max scaling in [−1;1] interval and ‘‘mRMR plus forward selection algorithm’’ for feature normalization and dimensionality reduction, respectively, and Gaussian SVM classifier.&lt;/p&gt;
&lt;h3 id=&#34;feature-calculation-analysis&#34;&gt;FEATURE CALCULATION ANALYSIS&lt;/h3&gt;
&lt;p&gt;识别: 使用左/右方法的全步幅最优；预测: leading/opposite approach and 1/4 fraction of gait stride
yielded the best results&lt;/p&gt;
&lt;p&gt;the interval from 1/4 stride’s fraction to the toe-off event (likely from terminal stance phase to preswing phase) contains relevant information for the user’s motion prediction.&lt;/p&gt;
&lt;h3 id=&#34;feature-normalization-analysis&#34;&gt;FEATURE NORMALIZATION ANALYSIS&lt;/h3&gt;
&lt;p&gt;min-max scaling with the interval [−1;1] yielded the best results for recognition and
prediction.&lt;/p&gt;
&lt;h3 id=&#34;feature-selection-and-extraction-analysis&#34;&gt;FEATURE SELECTION AND EXTRACTION ANALYSIS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;performed better in recognition than in the prediction&lt;/li&gt;
&lt;li&gt;an adequate dimensionality reduction method improved the effectiveness of the classifier com-
pared to the inclusion of the entire dataset.&lt;/li&gt;
&lt;li&gt;mRMR was faster and more effective than the ‘‘forward selection’’ and ‘‘backward selection’’ methods&lt;/li&gt;
&lt;li&gt;the ANOVA was less effective due to the low number of selected features (2 to 3 features) to discern between the classes&lt;/li&gt;
&lt;li&gt;dimensionality reduction methods that depend on the built model outperformed the ones (as ANOV A and PCA) that consider neither the classification model nor the classification goal.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-building-analysis&#34;&gt;model building analysis&lt;/h3&gt;
&lt;p&gt;SVM classifier with a Gaussian kernel is an effective classifier to yield a benchmark tool for both recognition and prediction purposes, despite the higher computational burden than other classifiers.&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;EMG sensors present some drawbacks when compared to kinematic sensors, such as the lengthy and expert-based installation, difficulty for keeping them attached during the user’s daily locomotion, and the shifting electrodes may change EMG patterns and degrade the classification over time [2], [4], [6].&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;确实！👎&lt;/p&gt;
&lt;p&gt;这种控制变量的形式应该之后也要用&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Motion control for a walking companion robot with a novel human–robot interface</title>
        <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
        <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
        <description>&lt;p&gt;Motion control for a walking companion robot with a novel human–robot interface&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.&lt;/p&gt;
&lt;p&gt;A new human– robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.&lt;/p&gt;
&lt;p&gt;mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;sensors&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;cost&#34;&gt;&lt;/a&gt;The design of human–robot interface involves two difficulties: &lt;strong&gt;the selected variables of body should fully reflect the motion state of the user&lt;/strong&gt; and the sensors adopt to effectively measure the selected variables.&lt;/p&gt;
&lt;p&gt;介绍了信息充分性和成本之间的trade-off&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;control&lt;/p&gt;
&lt;p&gt;Admittance control algorithm and variant of admittance-based control algorithm are widely used in the walker robot. $ { }^{4,7,8,10,11,13} $ Fuzzy control is also widely used. $ ^{12,15,18,22}  $Other control algorithms such as learning algorithm,$  ^{23}  $ smooth control,$  { }^{24} $ and Bayesian Networks mode$ { }^{16} $ are also adopted to the walker robot.&lt;/p&gt;
&lt;p&gt;The precise motion control highly depends on the design of HRI.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;h3 id=&#34;recognition-of-elemental-motion-state&#34;&gt;Recognition of elemental motion state&lt;/h3&gt;
&lt;p&gt;因为是辅助病人的，所以涉及的运动模式很有限，这篇文章只针对直行和转体两种。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707154707714.png&#34; alt=&#34;image-20210707154707714&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A rule-based method with fuzzy threshold rules&lt;/p&gt;
&lt;p&gt;Rule set (rule-based method)
If $ \Delta F_{Y F}&amp;gt;0 $ and $ \Delta F_{Y F} \leq 0 $ and $ F_{Y B}&amp;gt;F_{Y F} $, then $ \Delta d y_{\text {user }}&amp;gt;0, \Delta  angle  _{\text {user }}=0 $&lt;/p&gt;
&lt;p&gt;If $ \Delta F_{Y B}&amp;gt;0 $ and $ \Delta F_{Y F}&amp;gt;0 $ and $ F_{Y B} \approx F_{Y F} $ and $ P_{F}&amp;gt;   P_{M_{F}} $ and $ P_{B}&amp;gt;P_{M_{B}} $, then $ \Delta d y_{\text {user }}&amp;gt;0, \Delta  angle  _{\text {user }}&amp;gt;0 $&lt;/p&gt;
&lt;p&gt;If $ \Delta F_{Y B}&amp;gt;0 $ and $ \Delta F_{Y F}&amp;gt;0 $ and $ F_{Y B} \approx F_{Y F} $ and $ P_{F}&amp;lt;P_{M_{F}} $ and $ P_{B}&amp;lt;P_{M_{B}} $, then $ \Delta d y_{\text {user }}&amp;gt;0, \Delta  angle  _{\text {user }}&amp;lt;0 $&lt;/p&gt;
&lt;h3 id=&#34;mathematical-model-based-control-method&#34;&gt;Mathematical model-based control method&lt;/h3&gt;
&lt;p&gt;Motion Ⅰ&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707161517517.png&#34; alt=&#34;image-20210707161517517&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Motion Ⅱ 类似&lt;/p&gt;
&lt;h3 id=&#34;fc-method&#34;&gt;FC method&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707161722146.png&#34; alt=&#34;image-20210707161722146&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The force sensor data serve as the feedback of the control system rather than the input of control system.&lt;/p&gt;
&lt;p&gt;The FC basic concept is: when the real-time force sensor data equals to the initial state force sensor data, it indicates that robot moves at the same pace or rotate at the same angle with user. The robot is seen as a stable system and the motion of user is seen as the disturbance, the initial output of the force sensor is seen as the reference input. The control objective is to make the real- time output of force sensors equal to the initial one-axis force sensor data by adjust the motion of robot.&lt;/p&gt;
&lt;h3 id=&#34;stability-analysis&#34;&gt;Stability analysis&lt;/h3&gt;
&lt;p&gt;MMBC: close- loop transfer function; the characteristic equation of the system; roots of characteristic equation&lt;/p&gt;
&lt;p&gt;FC: the open-loop transfer function; the characteristic polynomial; poles of the system&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TODO 项目相关：所以从&lt;a class=&#34;link&#34; href=&#34;#cost&#34;&gt;这方面&lt;/a&gt;来看也能体现我这个工作的意义，选择显著相关的variable就可能降低对传感器的要求&lt;/li&gt;
&lt;li&gt;TODO 数据处理相关 the six- axis force/torque sensors or 3-D force sensors are required to remove noise (Kalman filters and G-h filters)&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study</title>
        <link>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</link>
        <pubDate>Tue, 06 Jul 2021 22:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</guid>
        <description>&lt;p&gt;Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study&lt;/p&gt;
&lt;p&gt;intention定义: standing still(stationary), walking or ascending the stairs&lt;/p&gt;
&lt;h2 id=&#34;hardware&#34;&gt;Hardware&lt;/h2&gt;
&lt;p&gt;sensors: ADXL345 (an accelerometer; in pelvis unit) and four FSRs (two in each foot for heel and toe respectively)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707085802763.png&#34; alt=&#34;image-20210707085802763&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;gait adaptation: detect in which phase of the gait cycle the subject is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;adaptive frequency oscillators (AFO) $\Leftarrow$ Since the human gait cycle is periodic, the &lt;strong&gt;acceleration&lt;/strong&gt; signals obtained from the pelvis unit is also &lt;strong&gt;periodic&lt;/strong&gt; in nature.&lt;/p&gt;
&lt;img src=&#34;https://K7288.github.io/assets/image-20210707090629072.png&#34; alt=&#34;image-20210707090629072&#34; style=&#34;zoom:35%;&#34; align=&#34;right&#34;/&gt;
&lt;ul&gt;
&lt;li&gt;$\epsilon$: the coupling strength&lt;/li&gt;
&lt;li&gt;$\nu$: amplitude-learning factor&lt;/li&gt;
&lt;li&gt;$f_{\min }$: initial frequency value&lt;/li&gt;
&lt;li&gt;a set of three oscillators  ($\mathrm{M}=3$)  to generate a learning signal,  $\hat{\theta} $, with the vertical acceleration of ADXL345 as the teaching signal,  $\theta_{d}$ .&lt;/li&gt;
&lt;li&gt;The Y matrix of order ($2 \mathrm{M}+2 \times 1$)  describes the state of the oscillator at any given instant of time.&lt;/li&gt;
&lt;li&gt;$ \phi_{i}$ and $\alpha_{i}  $ are the phase and amplitude of the  $i^{t h}$  oscillator, respectively.&lt;/li&gt;
&lt;li&gt;$ \omega$  is the fundamental angular frequency of the oscillator&lt;/li&gt;
&lt;li&gt;$ \beta $ sets the offset of the learned signal.&lt;/li&gt;
&lt;li&gt;$ \dot{\theta} $: estimated rate of change of learning signal, which plays a significant role in the classification of gait patterns.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;gait_detection&#34;&gt;&lt;/a&gt;gait event detection (GED): detect the heel strike (HS) and toe-offs (TO) of each foot.&lt;/p&gt;
&lt;p&gt;1️⃣ calibration(store maximum &amp;amp; minimum);2️⃣ max-min normalization;3️⃣ the previous normalized value of the heel FSR less than a specified upper limit (UL) and the current normalized value is greater than UL $\Rightarrow$ a heel strike (normalized value of the toe FSR greater than a specified lower limit (LL) and the current normalized value is less than LL $\Rightarrow$ a toe off)&lt;/p&gt;
&lt;p&gt;A good estimate for gait event detection is obtained when the UL and LL is taken to be 80% and 20%.&lt;/p&gt;
&lt;p&gt;With the knowledge of HS, TO and $\phi_{1}$ of the first oscillator, we calculate the phase,  $\phi_{G C}$, of the gait cycle of each foot **in percentage**. When $ \phi_{G C} $ is plotted with other temporal data of the gait cycle, it gives us the information about the subject&amp;rsquo;s state at each gait phase. The **stance time** of the gait cycle is calculated as the time duration from the HS of one foot to the TO of the same foot whereas the **swing time** is the time between the TO of one foot to the HS of the same foot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;gait pattern classification: without machine learning techniques: rule-based&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707105303376.png&#34; alt=&#34;image-20210707105303376&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;$a c c_{c a l i b}$和 $diff_{\text {calib }}$通过1分钟的校准得到&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707111045296.png&#34; alt=&#34;image-20210707111045296&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210707111756100.png&#34; alt=&#34;image-20210707111756100&#34; style=&#34;zoom:57%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is an offset between the heel strikes detected by the IDGR and VICON system which is carried forward throughout the plot, see fig. 4. This offset occurs because the gait events detected in IDGR and the motion capture system is due to the kinetics at the FSR and kinematics of the heel and toe trajectories with respect to the sacrum, respectively. Therefore, the heel strike detected by the VICON system occurs before those of the IDGR system.&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#gait_detection&#34;&gt;校准，通过力传感器检测步态event，确定stance time和swing time&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TODO Several works have classified gait pattern using machine learning methods like the random forest [25], support vector machines (SVM) [26] or using spectral feature analysis like the Gaussian Mixture Model [27].&lt;/p&gt;
&lt;p&gt;[25] Casale, P., Pujol, O., &amp;amp; Radeva, P. (2011, June). Human activity recognition from accelerometer data using a wearable device. In Iberian Conference on Pattern Recognition and Image Analysis (pp. 289-296). Springer, Berlin, Heidelberg.
[26] Prasertsung, P., &amp;amp; Horanont, T. (2016, December). A classification of accelerometer data to differentiate pedestrian state. In 2016 International Computer Science and Engineering Conference (ICSEC) (pp. 1-5). IEEE.
[27] Ibrahim, R. K., Ambikairajah, E., Celler, B., Lovell, N. H., &amp;amp; Kilmartin, L. (2008). Gait patterns classification using spectral features.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
        <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
        <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
        <description>&lt;p&gt;A lower limb exoskeleton based on recognition of lower limb walking intention&lt;/p&gt;
&lt;p&gt;intention定义: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706212640448.png&#34; alt=&#34;image-20210706212640448&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driver’s intention, and human–robot interface.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BLEEX
&lt;ul&gt;
&lt;li&gt;intention定义: step initiation, step velocity, and step termination&lt;/li&gt;
&lt;li&gt;sensors: more than 40; including encoders, linear accelerometers, force sensors, and an inclinometer&lt;/li&gt;
&lt;li&gt;actuators: hydraulic actuators&lt;/li&gt;
&lt;li&gt;intention recognition the driver by using foot switch sensors, encoders, and force sensors to monitor toe-off movement, joint movement, or force variability&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HAL
&lt;ul&gt;
&lt;li&gt;sensors: potentiometers, floor reaction force sensors, accelerometers, a gyroscope, and electromyography (EMG) sensors&lt;/li&gt;
&lt;li&gt;actuators: DC motors with a harmonic drive directly placed on the hip and knee joints&lt;/li&gt;
&lt;li&gt;intention recognition: faster than BLEEX, using bio-signals from EMG sensors&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ReWalk
&lt;ul&gt;
&lt;li&gt;intention recognition: with forearm crutches, installing buttons, and torso angles; slower than recognition of walking intention in real time using sensors&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;specifications&#34;&gt;specifications&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sensors: insole-type FSRs(force sensing resistors) and three axis F/T sensors&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;actuators: four DC motors (two at each hip and each knee)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706195312079.png&#34; alt=&#34;image-20210706195312079&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;system&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706195358285.png&#34; alt=&#34;image-20210706195358285&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;control&#34;&gt;Control&lt;/h2&gt;
&lt;p&gt;Flowchart of control strategy&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706200803466.png&#34; alt=&#34;image-20210706200803466&#34;  /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;step initiation: using the insole-type FSRs with two particular GRF events before visible movement occurs, such as heel off, toe off, or knee flexion&lt;/li&gt;
&lt;li&gt;after step initiation: reference torque(reference torque for each hip and each knee were calculated from gait pattern analysis using the &lt;strong&gt;inverse dynamics model&lt;/strong&gt;.) $\rightarrow$ motion controller&lt;/li&gt;
&lt;li&gt;push-off impulse time $\Leftarrow$ three axis F/T sensors.
&lt;ul&gt;
&lt;li&gt;&lt;a id=&#34;dependence&#34;&gt;&lt;/a&gt;We found that &lt;strong&gt;push-off impulse time depends on step velocity&lt;/strong&gt;, using gait analysis based on force plates. shorter at faster step velocity, longer at slower step velocity, and rapidly minimized at step termination.&lt;/li&gt;
&lt;li&gt;measured from heel strike time to push-off time by the trailing leg.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intention-recognition&#34;&gt;Intention Recognition&lt;/h2&gt;
&lt;p&gt;Moore Automation for Robot Behavior(MARB) (Konig et al. 2009).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706203132337.png&#34; alt=&#34;image-20210706203132337&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href = &#34;#dependence&#34;&gt;TODO gait analysis&lt;/a&gt; $\Rightarrow$ push-off impulse time depends on step velocity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这个结果还是通过基于force plates的gait analysis得来的，可能有借鉴意义&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706212616125.png&#34; alt=&#34;image-20210706212616125&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;最开始看的那篇生物统计的也用到了impulse但是现在不太记得具体内容了XD&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TODO 这个里面因为速度和push-off impulse time统计相关所以用push-off impulse time估计速度，用的方式是最直观的将速度划分成区间&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The mean push-off impulse time of normal step velocity from three axis F/T sensors was
0.45 s (SD 0.05), of faster step velocity was 0.225 s (SD 0.05), and of slower step velocity was 0.75 s (SD 0.01). The mean push-off impulse time of normal step velocity from force plates was 0.35 s (SD 0.05), of faster step velocity was 0.15 s (SD 0.05), and of slower step velocity was 0.67 s (SD 0.01). The results clearly indicate that UTRCEXO recognized the walking intentions of drivers for acceleration, deceleration, and step termination with different push-off impulse times of drivers at three different velocities and step termination.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706213607461.png&#34; alt=&#34;image-20210706213607461&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为什么佩戴者wearer被描述成pilot driver❓ 都这么用吗&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TODO EMG数据处理：高通滤波(二阶巴特沃思，20hz截止频率)，整流，然后低通滤波(二阶巴特沃思，3hz截止频率)。然后采用方差分析(ANOVA)比较安装UTRCEXO与未安装UTRCEXO的肌肉活动，采用SPSS 19.0软件对肌肉活动进行归一化处理，显著性水平为0.05。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Electrodes were placed on the anatomical locations of the rectus femoris muscle, gastrocnemius muscle, and abdominal muscle, based on guidelines from previous research (Gallagher et al. 2011). The EMG sensor had a 1 KHz sampling rate and 8–500 Hz band- width, and was low-pass filtered at 500 Hz by the EMG recording system. The EMG signals were collected and used to record muscle activity during stance phase and swing phase. The EMG signal was high-pass filtered        (second-order Butterworth, 20 Hz cut-off frequency), rectified, and then low-pass filtered (second-order Butterworth, 3 Hz cut-off frequency). Then ANOVA was conducted to compare the muscle activity of drivers equipped and not equipped with UTRCEXO, normalizing muscle activity using SPSS version 19.0 software based on a significance level of0.05. The ANOVA results are shown in Table 6.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;他们用的这个MARB讲得也太不清楚了，没太看懂&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Intention Recgonition for Exoskeleton</title>
        <link>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</link>
        <pubDate>Tue, 06 Jul 2021 13:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</guid>
        <description>&lt;p&gt;Intention Recgonition for Exoskeleton&lt;/p&gt;
&lt;p&gt;intention定义: walk/stand&lt;/p&gt;
&lt;h2 id=&#34;assistance-exoskeleton-system&#34;&gt;assistance exoskeleton system&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;支持4种state: L swing, R swing, Double stance(L), Double stance(R)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;control&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706151917632.png&#34; alt=&#34;image-20210706151917632&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;online SVM; features: ZMP(Zero Moment Point), IMU&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ZMP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;concept: The distributed floor reaction force can be replaced by a single force R acts on ZMP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ZMP can be obtained from ground reaction force (GRF) measurement or inverse dynamics of system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;calculation&lt;/p&gt;
&lt;p&gt;$r=[\delta\ \varepsilon\ 0]$  is a vector on the ground and $ \rho(\delta, \varepsilon) $ is the vertical force acted on unit area at point $ r$. So the sum of vertical force is like $f_{z}=\int_{s} \rho(\delta, \varepsilon) d S$&lt;/p&gt;
&lt;p&gt;torque at  $p=\left[p_{x}\ p_{y}\ 0\right]$  is  $\tau_{n}(p) $.&lt;/p&gt;
&lt;p&gt;$\begin{aligned} 
\tau_{nx} &amp;amp;=\int_{S}(\delta-p_{x}) \rho(\delta, \varepsilon) d S  \\ 
\tau_{ny} &amp;amp;=\int_{S}(\varepsilon-p_{y}) \rho(\delta, \varepsilon) d S  \\ 
\tau_{nz} &amp;amp;=0
\end{aligned}$&lt;/p&gt;
&lt;p&gt;At ZMP  $\tau_{n x}=0, \tau_{n y}=0$ , we can get&lt;/p&gt;
&lt;p&gt;$\begin{aligned}
p_{x} &amp;amp;=\frac{\int_{S} \delta \rho(\delta, \varepsilon)}{\int_{S} \rho(\delta, \varepsilon)}\\p_{y} &amp;amp;=\frac{\int_{S} \varepsilon \rho(\delta, \varepsilon)}{\int_{S}\rho(\delta, \varepsilon)}\end{aligned}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As $\rho(\delta, \varepsilon) $ is the distribution of reaction force on foot, ZMP  p  is also the center of pressure(COP).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ZMP for one foot&lt;/th&gt;
&lt;th&gt;ZMP of system&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$P_{l x} =\frac{\sum_{i=1}^{7} p_{i}^{x} f_{i}}{\sum_{i=1}^{7} f_{i}}$&lt;br&gt;&lt;br/&gt;$ P_{l y} =\frac{\sum_{i=1}^{7} p_{i}^{y} f_{i}}{\sum_{i=1}^{7} f_{i}}$&lt;br&gt;&lt;br/&gt;$F_{l} =\sum_{i=1}^{7} f_{i}$&lt;/td&gt;
&lt;td&gt;$Z M P_{x} =\frac{P_{l x} F_{l}+P_{r x} F_{r}}{F_{l}+F_{R}}$&lt;br/&gt;&lt;br/&gt;$Z M P_{y} =\frac{P_{l y} F_{l}+P_{r y} F_{r}}{F_{l}+F_{R}}$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SVM&lt;/p&gt;
&lt;p&gt;polynomial kernel; Gaussian kernel&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706161222476.png&#34; alt=&#34;image-20210706161222476&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210706161235490.png&#34; alt=&#34;image-20210706161235490&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TODO ZMP之后应该用得上，这个推导可以看一眼&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>页内跳转</title>
        <link>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</link>
        <pubDate>Mon, 05 Jul 2021 16:52:26 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</guid>
        <description>&lt;p&gt;&lt;a id=&#34;series&#34;&gt;&lt;/a&gt;这是一段文字，我想跳转到这里。&lt;/p&gt;
&lt;p&gt;⏬&lt;/p&gt;
&lt;p&gt;⏬&lt;/p&gt;
&lt;p&gt;⏬&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#series&#34;&gt;我实现了跳转。&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;series&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;这是一段文字，我想跳转到这里。

⏬

⏬

⏬

&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;link&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;href&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#series&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;我实现了跳转。&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
        </item>
        <item>
        <title>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses</title>
        <link>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</link>
        <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</guid>
        <description>&lt;p&gt;A Classification Method for &lt;strong&gt;User-Independent&lt;/strong&gt; Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses&lt;/p&gt;
&lt;p&gt;intention定义—locomotion modes: level walking, ramp ascent, ramp descent, stair ascent, and stair descent&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;to develop a user-independent intent recognition system capable of recognizing level-ground walking, slopes, and stairs and to compare this system with a user-dependent intent recognition system.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prior studies in which pattern recognition algorithms: current methods to initiate transitions between modes, such as visual, audio, or compensatory movement commands, are &lt;strong&gt;unintuitive&lt;/strong&gt; and impose a &lt;strong&gt;cognitive burden&lt;/strong&gt;. An inherent disadvantage of pattern recognition-based intent recognition systems is that a considerable &lt;strong&gt;amount of training data&lt;/strong&gt; must be collected.&lt;/li&gt;
&lt;li&gt;previous able-bodied gait studies with accelerometer data: by pooling data from a large subject group(e.g. n = 52), high accuracies (~96% ) of gait mode identification for a novel subject can be obtained for level-ground walking, slopes, and stairs. In addition, &lt;strong&gt;to obtain these high accuracies for novel subjects, group gait features were normalized to the novel subject’s level-ground walking data&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Experimental testing factors&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/7061495-table-1-source-large.gif&#34; alt=&#34;img&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;training and testing: A group of eight transfemoral amputees walked over different terrains using a powered knee and ankle prosthesis. We created a pooled classifier using data from all subjects except one: data from this single subject was withheld from the pool and used to test how well the pooled classifier generalized to that subject in an offline analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;partially-dependent&#34;&gt;&lt;/a&gt;the partially-dependent classification system: including data from some of the novel subject’s steady-state level-ground walking in the training pool, to determine whether generalization to that subject improved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mode-specific: having a separate classifier active for each locomotion mode. The previous locomotion mode determines the classifier model used for predicting the next stop. Each “mode specific” classifier was trained using the steady-state locomotion mode, and only the relevant transitions leaving the current locomotion mode. This enabled each transition to be statistically classified as a separate class, and to only be considered at the appropriate times.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/7061495-fig-3-source-large.gif&#34; alt=&#34;img&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DBN: dynamic Bayesian network&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDA: linear discriminant analysis (LDA)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Experimental Protocol&lt;/li&gt;
&lt;li&gt;Signal Processing
&lt;ul&gt;
&lt;li&gt;Sensors: potentiometers and encoders at the knee and ankle, an axial load cell, and a six-axis IMU on the shank; Sensor signals were generated for knee and ankle positions, velocity and torque, axial force, and shank three-directional accelerations and rotational velocities.&lt;/li&gt;
&lt;li&gt;normalization; 数据迁移到另一侧截肢的被试&lt;/li&gt;
&lt;li&gt;划窗 segmented into analysis windows of 300ms at eight different points for each stride&lt;/li&gt;
&lt;li&gt;特征提取 From each analysis window, six features were extracted: the signal mean and standard deviation, the minimum and maximum signal values over the window, and the starting and ending signal values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Signal Classification Strategies
&lt;ul&gt;
&lt;li&gt;Baseline Configuration: LDA&lt;/li&gt;
&lt;li&gt;Time History Configuration: DBN to integrate information over the gait cycle to include time history (TH) information.&lt;/li&gt;
&lt;li&gt;Mode-Specific Configuration&lt;/li&gt;
&lt;li&gt;Mode Specific + Time History Configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Classification Procedure&lt;/li&gt;
&lt;li&gt;Performance Evaluation
&lt;ul&gt;
&lt;li&gt;intent recognition error rate, averaged across all steps for each subject, as our primary performance metric.&lt;/li&gt;
&lt;li&gt;statistical analyses
&lt;ul&gt;
&lt;li&gt;two-way ANOVAs transitional and steady-state errors with subject as a random factor. Classification condition (user-independent, partially dependent, and user-dependent) and classifier configuration were included as fixed factors.&lt;/li&gt;
&lt;li&gt;a post hoc Bonferronni test on significant factors to determine specific differences ($\alpha$=0.05).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;For both user-dependent and user-independent classification, mode-specific classification reduced error (p &amp;lt; 0.05) on transitional steps by 50 without affecting steady-state classification. Incorporating sensor time history and level-ground walking data from the novel subject into the training data resulted in decreasing errors (p &amp;lt; 0.05) on steady-state classification by over 60% without affecting transitional error.&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;为什么&lt;a class=&#34;link&#34; href=&#34;#partially-dependent&#34;&gt;partially-dependent &lt;/a&gt;可以判断generalization to that subject是否improve&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Multi-sensor based human motion intention recognition algorithm for walking-aid robot</title>
        <link>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</link>
        <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</guid>
        <description>&lt;p&gt;Multi-sensor based human motion intention recognition algorithm for walking-aid robot&lt;/p&gt;
&lt;p&gt;intention定义：velocity; 这里表征为一个自定概念IM&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;A multi-sensor(force sensors and LRF; for both lower and upper limbs) based human motion intention recognition algorithm for walking-aid robot.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;assistive rehabilitation robots: PAMM, Walking Helper, HAL, Omni RT Walker-II (ORTW-II)&lt;/li&gt;
&lt;li&gt;简略说了一些human motion estimation methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Sensors: push-pull force sensors and LRF(Laser Range Finder)&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LRF: Range Segmentation, Identification of Circle, Leg detection, Intention detection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;using the center position of line segment which consists of two legs position to estimate human motion intention:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210705140247777.png&#34; alt=&#34;image-20210705140247777&#34; style=&#34;zoom:33%;&#34; /&gt; {h} and {r} are local coordinate systems, which are fixed on the human and robot respectively.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210705110528352.png&#34; alt=&#34;image-20210705110528352&#34; align=&#34;right&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;Define intentional motion (IM) to describe the human walking intention during using the walking-aid robot&lt;/p&gt;
&lt;p&gt;$S_{I M}(n)= \{\dot{\theta}_{I M}(n), \rho_{I M}(n), v_{I M}(n)\}$（角速度、线速度）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210705141414587.png&#34; alt=&#34;image-20210705141414587&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multi-sensor fusion: Kalman filter&lt;/p&gt;
&lt;p&gt;$^h \mathbf{V}_{H} $ $^h \mathbf{V}_{L}$: human intent motion velocities estimated by force sensors and laser ranger finder respectively; input of Kalman filter&lt;/p&gt;
&lt;p&gt;$\mathbf{V}_{R}=[\dot{x}_{R}\  \dot{y}_{R} ]^{T} $: output of Kalman filter; filtered human motion intention&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Online Estimation of the IM: different dimension of conventional Kalman filter&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210705143709665.png&#34; alt=&#34;image-20210705143709665&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210705142524600.png&#34; alt=&#34;image-20210705142524600&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Terms</title>
        <link>https://K7288.github.io/posts/terms/</link>
        <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/terms/</guid>
        <description>&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Terms&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Definition&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;inertia matrix&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;damping matrix&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;stiffness matrix&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;centripetal and Coriolis matrix&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Cartesian coordinate&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;mass-damper-spring model&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;impedance control&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;admittance control 导纳控制&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;push-off impulse time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;transition function&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;adaptive frequency oscillators&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;one-way ANOVA&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;two-way ANOVA&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;a neural interface&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;linear discriminant analysis&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;drift(signal/integral/zero/integral/temperature drift)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;a rigid body&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;刚体&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;time-varying, adaptive compensation term, manifold, coarse/fine-grained level granularity, an inertial frame, oscillator, denominator,&lt;/p&gt;
&lt;p&gt;Kinematic Kinetic&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Difference Between Kinetics and Kinematics&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Kinetics&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Kinematics&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Studies the cause for the motions of the object&lt;/td&gt;
&lt;td&gt;Studies the position, acceleration, speed of an object&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The mass of the object is taken into consideration&lt;/td&gt;
&lt;td&gt;The mass of the object is not taken into consideration&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Its application lies in the design of automobiles&lt;/td&gt;
&lt;td&gt;It is applied to study the movement of celestial bodies&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Force is considered&lt;/td&gt;
&lt;td&gt;Force is not considered&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;It does not involve any mathematical expressions&lt;/td&gt;
&lt;td&gt;It involves mathematical expressions&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        <item>
        <title>行文常见说法</title>
        <link>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</link>
        <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</guid>
        <description>&lt;p&gt;prior studies/research&lt;/p&gt;
&lt;p&gt;Experimental Protocol&lt;/p&gt;
&lt;p&gt;Representative diagram&lt;/p&gt;
&lt;p&gt;the integrated design&lt;/p&gt;
&lt;p&gt;cognitive effort&lt;/p&gt;
&lt;p&gt;methodology&lt;/p&gt;
&lt;p&gt;prototype&lt;/p&gt;
&lt;p&gt;Sensory Information&lt;/p&gt;
</description>
        </item>
        <item>
        <title>A review of human activity recognition methods</title>
        <link>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</link>
        <pubDate>Thu, 01 Jul 2021 00:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</guid>
        <description>&lt;p&gt;A review of human activity recognition methods&lt;/p&gt;
&lt;p&gt;Recognizing human activities &lt;strong&gt;from video sequences or still images&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;intention定义: activity; 一个描述性词&lt;/p&gt;
&lt;p&gt;Usually, the terms “activity” and “behavior” are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term “activity” is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term “behavior” is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person. Some&lt;/p&gt;
&lt;h2 id=&#34;decomposition-of-human-activities-depending-on-complexity&#34;&gt;Decomposition of human activities (depending on complexity)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210703164104152.png&#34; alt=&#34;image-20210703164104152&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary-of-previous-surveys&#34;&gt;Summary of previous surveys&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210703144744639.png&#34; alt=&#34;image-20210703144744639&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;proposed-hierarchical-categorization-of-human-activity-recognition-methods&#34;&gt;Proposed hierarchical categorization of human activity recognition methods&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210703164133523.png&#34; alt=&#34;image-20210703164133523&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Unimodal methods represent human activities from data of a single modality, such as images.&lt;/p&gt;
&lt;p&gt;其实是一个纯CV问题，应该用不到，后面一半就没看了&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>
        <link>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</link>
        <pubDate>Tue, 29 Jun 2021 20:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</guid>
        <description>&lt;p&gt;Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network&lt;/p&gt;
&lt;p&gt;intention定义：velocity+trajectory; 只涉及到一个接触点&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;a method based on radial basis function neural network (&lt;strong&gt;RBFNN&lt;/strong&gt;) model is presented to &lt;strong&gt;identify the motion intention of collaborator&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Here, the &lt;strong&gt;human intention is defined as the desired velocity&lt;/strong&gt; in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Kazuhiro Kosuge and Norihide Kazamura proposed several algorithms to generate the motion based on the intentional force and experimentally compare them, including method of force augmentation type, method of position control type, and method of velocity control type [8].&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dylan P. Losey et al. provided a unifying view of human and robot sharing task execution. They defined &lt;strong&gt;three key themes that emerge in shared control scenarios&lt;/strong&gt;, namely, &lt;strong&gt;intent detection, arbitration, and feedback&lt;/strong&gt; [9].&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Definition of intent in this paper: In many physical human-robot interaction (pHRI) applications, the intent can be defined in a binary way. It is often ascertained from a brain-machine interface (BMI), as seen in[10]. In other applications, user intent is defined in terms of a velocity or position trajectory, the predicted forward path of the user and/or robot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;human intention recognition based on myographic signals 肌电信号&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;pattern recognition&lt;/p&gt;
&lt;p&gt;The pattern recognition approach is to map patterns of any number of signal features to desired prosthesis poses, grasps, or functions. The way in which control algorithms learn this mapping varies, but common approaches are LDA, SVMs, and artificial neural networks (ANNs) [11, 12, 15].&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mapping to continuous effort.&lt;/p&gt;
&lt;p&gt;control systems that learn the mapping between EMG signals and user’s desired joint torque, e.g. relationship between the root-mean square (RMS) of measured EMG signals and the estimated user’s desired torques [16].&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;human intention recognition based on interaction force&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dynamics model
&lt;ul&gt;
&lt;li&gt;Pehlivanet al. use an &lt;strong&gt;inverse dynamics model of the robot&lt;/strong&gt; to estimate the user force applied to the robot from the robot encoder measurements [17].&lt;/li&gt;
&lt;li&gt;In [20–22], human intentions are predicted by establishing a dynamic model of collaborator. Passenberg C. uses human models and jerk models to recognize human intention with extended Kalman filtering method [23]. These estimation methods based on the &lt;strong&gt;human body model&lt;/strong&gt; are very difficult because the impedance parameters of the human body are variable and can be hardly obtained [24].&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NN method
&lt;ul&gt;
&lt;li&gt;the motion intention of the human partner is defined as the desired trajectory in the employed human limb model; difficult to obtain in practice.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hidden Markov Model
&lt;ul&gt;
&lt;li&gt;very complex and difficult to establish a model of intention recognition.&lt;/li&gt;
&lt;li&gt;C. Lee uses the Baum-Welch algorithm to train Hidden Markov Model, which predicts
the collaborator&amp;rsquo;s intention by learning the meaning of the collaborators’ gestures. However, this method does not really realize the purpose of identifying partner intention [19].&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In addition, the measured interaction force can be used to estimate other forms of motion intention. For example, the interaction forces measured in the handles to predict possible walking modes or the walker’s forward path in [25, 26].&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;assumption: the end effector of robot physically interacts with the human hand and there is only one interaction point.&lt;/p&gt;
&lt;p&gt;sensor: Six-Dimensional Force Sensor&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;in order to &lt;strong&gt;obtain training data and test data&lt;/strong&gt; of neural network, the adaptive impedance control method is used to collect sample data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;basis neural network model is established after mapping sample data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;data matching&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;K-means method used to define the number of the hidden layer nodes. Weighted mean value (Wmv) parameter (as follows) of cluster radius to determine K value.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210703115112299.png&#34; alt=&#34;image-20210703115112299&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the intention of the collaborator is identified through online prediction.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In order to verify the validity of the RBFNN method in this paper, the robot’s contact point speed and interaction force are analyzed by comparing with the corresponding experimental parameters values from the adaptive impedance control algorithm. 
&lt;img src=&#34;https://K7288.github.io/assets/4141269.fig.002.svg&#34; align=&#34;center&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;K-means是怎么用在hidden layer nodes数量的确定上的？？(p5)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先有鸡还是现有蛋&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有时间看一下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这个自适应方法是怎么得出的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210701181613356.png&#34; alt=&#34;image-20210701181613356&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;质量-弹簧-阻尼器系统等（Dr. F毕业论文那里好像有张图）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210701181822246.png&#34; alt=&#34;image-20210701181822246&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Froude Numbers</title>
        <link>https://K7288.github.io/posts/froude-numbers/</link>
        <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/froude-numbers/</guid>
        <description>&lt;h1 id=&#34;the-gaits-of-bipedal-and-quadrupedal-animals&#34;&gt;The Gaits of Bipedal and Quadrupedal Animals&lt;/h1&gt;
&lt;p&gt;Alexander R. The gaits of bipedal and quadrupedal animals. The International Journal of Robotics Research. 1984;&lt;/p&gt;
&lt;p&gt;mammals of different sizes tend to move &lt;strong&gt;in dynamically similar fashion whenever their Froude numbers $u^2 /gh$ are equal&lt;/strong&gt;: here u is speed, g is the acceleration of free fall, and h is the height of the hip joint from the ground.&lt;/p&gt;
&lt;h2 id=&#34;research-problem&#34;&gt;Research Problem&lt;/h2&gt;
&lt;p&gt;description of the gaits of two- and four-legged animals and some of the important optimization criteria(e.g. cost, reliability, and maneuverability).&lt;/p&gt;
&lt;h2 id=&#34;hypothesis&#34;&gt;Hypothesis&lt;/h2&gt;
&lt;p&gt;dynamic similarity is possible only if the
motions have equal Froude numbers  $u^2 /gh$ (Duncan1953).&lt;/p&gt;
&lt;p&gt;The dynamic similarity hypothesis&lt;/p&gt;
&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524120558263.png&#34; alt=&#34;image-20210524120558263&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;四足哺乳动物之间、两足与四足哺乳动物之间、鸟类和两足哺乳动物之间 相似的运动状态和相似的Froude number对应&lt;/p&gt;
&lt;h1 id=&#34;humans-geometric-similarity-and-the-froude-number-is-reasonably-close-really-close-enough&#34;&gt;Humans, geometric similarity and the Froude number: is ‘‘reasonably close’’ really close enough?&lt;/h1&gt;
&lt;p&gt;William Froude developed the Froude number in the context of his simulation of ships with the goal of creating similar wave patterns (Vaughan and O&amp;rsquo;Malley, 2005) with drag as the feature of importance (Langhaar, 1951), but his concept has been extended to other mechanical phenomena that are driven by gravity and inertia (Duncan, 1953)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;（针对不同物种）size does not affect mass-specific mechanical cost of transport (Alexander and Jayes, 1983). The known shape differences among modern humans are, however, sufficiently large to account for much of the observed variation in metabolic energy expenditure and we expect this to be the case for any group that is of similar size but different shape. Unfortunately, we currently do not have a simple method to control or adjust for size–shape differences in individuals that are not geometrically similar. Musculoskeletal modeling is the only method that accounts for both size and shape. Those shape differences that are “reasonably close” at the mouse-to-elephant level may become “grossly different” for within-species energetic comparisons.目前尚没有一种简单的方法来控制或调整几何上不相似的个体的大小-形状差异。&lt;/p&gt;
&lt;h1 id=&#34;the-energetics-of-human-walking-is-froude-number-fr-useful-for-meta--bolic-comparisons&#34;&gt;The energetics of human walking: Is Froude number (Fr) useful for meta- bolic comparisons?&lt;/h1&gt;
&lt;p&gt;Kramer PA, Sarton-Miller I. The energetics of human walking: Is Froude number (Fr) useful for meta- bolic comparisons? Gait &amp;amp; Posture. 2008; 27(2):209–215. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2007.03.009&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.gaitpost.2007.03.009&lt;/a&gt; PMID: 17459708&lt;/p&gt;
&lt;p&gt;回归分析，速度、速度平方、Fr或LiMb的预测能力没有显著差异，所以Fr和LiMb都不能补偿腿长的影响。腿的长度确实影响行走的人的能量消耗&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Duncan W. J. (1953). Physical Similarity And Dimensional Analysis: An Elementary Treatise London: Edward Arnold and Company.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>F-Scan</title>
        <link>https://K7288.github.io/posts/f-scan/</link>
        <pubDate>Tue, 18 May 2021 14:21:37 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/f-scan/</guid>
        <description>&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;采样频率：$50\text{Hz}$&lt;/p&gt;
&lt;p&gt;测力点尺寸：$5.1\times5.1(\text{mm})$&lt;/p&gt;
&lt;p&gt;翻译问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;力度 $\Rightarrow$ 力&lt;/li&gt;
&lt;li&gt;压力 $\Rightarrow$ 压强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;测力片无所谓正反&lt;/p&gt;
&lt;h2 id=&#34;流程&#34;&gt;流程&lt;/h2&gt;
&lt;p&gt;裁剪（只要不剪断横向线路即可）&lt;/p&gt;
&lt;p&gt;部署（信号采集/通信装置用魔力贴固定在小腿，插上测力片）&lt;/p&gt;
&lt;p&gt;校准（需要被试单脚站立各5s）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522080806900.png&#34; alt=&#34;image-20210522080806900&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;在fsx窗口右键“单位”选择单位和精度&lt;/p&gt;
&lt;p&gt;录制&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522083343350.png&#34; alt=&#34;image-20210522083343350&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据导出&#34;&gt;数据导出&lt;/h2&gt;
&lt;p&gt;1.完整数据：选中相应fsx窗口在“文件”中导出&lt;/p&gt;
&lt;p&gt;格式：每一帧的全部测力点所测压强（包括灰色边界&amp;quot;B&amp;quot;和剪去的测力点）&lt;/p&gt;
&lt;p&gt;单位：自选，会在导出的csv文件头列出&lt;/p&gt;
&lt;p&gt;写了计算每一帧总压力的代码，也可用采样区选中整个区域得到总压力&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522081309612.png&#34; alt=&#34;image-20210522081309612&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;2.取样区&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522081558082.png&#34; alt=&#34;image-20210522081558082&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;所在窗格右键“对象”导出 或者直接在生成的图线上ctrl+c粘贴到excel&lt;/p&gt;
&lt;p&gt;格式：不保留每个采样点信息，只有整体数据（这一个区域的总压力/压强等）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522081702659.png&#34; alt=&#34;image-20210522081702659&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;在右键&amp;quot;属性&amp;quot;中可以更改采样区显示的信息&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522082516227.png&#34; alt=&#34;image-20210522082516227&#34;  /&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hugo HTML Tips</title>
        <link>https://K7288.github.io/posts/hugo-html-tips/</link>
        <pubDate>Tue, 18 May 2021 11:23:29 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/hugo-html-tips/</guid>
        <description>&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;原生html支持&lt;/p&gt;
&lt;p&gt;hugo采用goldmark作为默认渲染器，需要在config中开启&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;   markup:
    goldmark:
        renderer:
            unsafe: true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;html
图片需要绝对路径，形式如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-HTML&#34; data-lang=&#34;HTML&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;img&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/assets/image-20210416142714352.png&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;alt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;image-20210416142714352&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;zoom:33%;&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;而不能是&lt;code&gt;src=&amp;quot;assets\&lt;/code&gt;
所以也不太支持网络图片&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;code&gt;****&lt;/code&gt;好像不能出现&lt;code&gt;。&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>(Draft)Image Processing and Computer Vision</title>
        <link>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</link>
        <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</guid>
        <description>&lt;p&gt;参考书目 Digital Image Processing by Rafael C. Gonzalez, Richard E. Woods, 3rd Edition&lt;/p&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;第一章-数字图像的采集方式以及特性&#34;&gt;第一章 数字图像的采集方式以及特性&lt;/h2&gt;
&lt;h3 id=&#34;11-图像概述&#34;&gt;1.1 图像概述&lt;/h3&gt;
&lt;p&gt;图像是一个二维亮度函数；&lt;/p&gt;
&lt;p&gt;模拟图像：一幅活动、彩色、立体的图像——$I=f(x,y,z,λ,t)$，三维空间+波谱上+时间上连续，想象中的虚拟图像&lt;/p&gt;
&lt;p&gt;数字图像：数字图像是由模拟图象数字化得到的，以像素为基本元素、可以用数字计算机或数字电路存储和处理的图像。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416141649190.png&#34; alt=&#34;image-20210416141649190&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;把一幅图画分割成如图所示的一个个小区域（像素），并将各小区域灰度用整数来表示，形成一幅点阵式的数字图像。它包括&lt;strong&gt;采样&lt;/strong&gt;和&lt;strong&gt;量化&lt;/strong&gt;两个过程。像素的位置和灰度就是像素的属性。&lt;/p&gt;
&lt;h3 id=&#34;12-图像数字化&#34;&gt;1.2 图像数字化&lt;/h3&gt;
&lt;p&gt;图像数字化:将模拟图像经过离散化之后，得到用数字表示的图像。&lt;/p&gt;
&lt;p&gt;一幅模拟图像的坐标及幅度都是连续的，为了把它转换为数字形式，必须对坐标和幅度都作离散化操作。&lt;strong&gt;数字化坐标值称为采样&lt;/strong&gt;，它确定了图像的&lt;strong&gt;空间分辨率&lt;/strong&gt;；&lt;strong&gt;数字化幅度值称为量化&lt;/strong&gt;，它确定了图像的&lt;strong&gt;幅度分辨率&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;121图像数字化采样&#34;&gt;1.2.1图像数字化——采样&lt;/h4&gt;
&lt;p&gt;（1）图像的采样：将在空间上连续的图像转换成离散的采样点（即像素）集的操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416142714352.png&#34; alt=&#34;image-20210416142714352&#34; style=&#34;zoom:33%;&#34; /&gt;
&lt;code&gt;z=f(x,y), x∈[0,a], y∈[0,b], z∈[0,c]&lt;/code&gt; $\rightarrow$ &lt;code&gt;z=f(x,y), x=0,1,…,N-1,y=0,1,…,M-1, z=0,1,…,L-1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;采样间隔太小，则增大数据量；太大，则会发生信息的混叠，导致细节无法辨认。&lt;/p&gt;
&lt;h5 id=&#34;一维连续信号的采样&#34;&gt;一维连续信号的采样&lt;/h5&gt;
&lt;p&gt;在工程中的许多信号，实际上都是连续信号，或者称为连续时间函数，记为x(t)，t的取值是从$-\infty$ 连续变化到$+ \infty $ 。但是，用计算机处理这些信号，必须首先对连续信号进行采样，即按一定的时间间隔Ts进行取值：
$$
𝑥_𝑑 (𝑛)=𝑥(𝑛𝑇_𝑠)   , 𝑛=…−1,0,1…
$$
$T_s$为采样间隔，$ x_d (n)$为离散信号或时间序列&lt;/p&gt;
&lt;p&gt;连续信号x(t)和频谱X(f)的具体关系为：
$$
X(f)=\int _{−\infty}^\infty x(t)e^{−j2\pi ft} dt\\\\x(t)=\int _{−\infty}^\infty X(f)e^{j2\pi ft} df
$$&lt;/p&gt;
&lt;p&gt;一维空间采样的Nyquist条件：$X(f)$有截频$ f_c$，即当$|f|≥ f_c$时, $X(f)=0$；$T_s≤\frac{1}{2f_c}$ 或$2f_c≤f_s$&lt;/p&gt;
&lt;p&gt;如果信号不是有限带宽信号，采样频率或采样间隔不满足Nyquist条件，就会产生混叠现象。&lt;/p&gt;
&lt;p&gt;在满足Nyquist条件下，从离散信号$x(nT_s)$可恢复连续信号$x(t)$
$$
x(t)=\Sigma_{n=−\infty}^{+\infty}x(nT_s)sinc(\frac{\pi}{T_s} (t-nT_s))
$$&lt;/p&gt;
&lt;p&gt;$sinc(x)=\frac{sinx}{x}$&lt;img src=&#34;https://K7288.github.io/assets/image-20210416152431983-1621304859786.png&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;h5 id=&#34;二维连续图像信号的采样&#34;&gt;二维连续图像信号的采样&lt;/h5&gt;
&lt;p&gt;设图像f(x,y)是一连续二维信号，其空间频谱$F(f_x,f_y )$在x方向具有截止频率$f_xc$ ，在y方向具有截止频率$f_yc$ 。所谓采样是对f(x,y)乘以空间采样函数：
$$
s(x,y)=\Sigma_{i=−\infty }^{+\infty }∑_{j=−\infty }^{+\infty }\delta(x−i\Delta x,y−i\Delta y)
$$
式中Δx和Δy为x、y两个方向的采样间隔，上式为脉冲函数δ(x,y)沿x、y两个方向的展开。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416155641596.png&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;//脉冲函数：&lt;img src=&#34;https://K7288.github.io/assets/09fa513d269759ee348f4897bffb43166c22df8a&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;经过采样以后所得的信号为：
$$
f_s (x,y)=f(x,y)∙ s(x,y)\\=∑_{i=−\infty }^{+\infty }∑_{j=−\infty }^{+\infty }f(i\Delta x,j\Delta y)\sigma(x−i\Delta x,y−j\Delta y)
$$&lt;/p&gt;
&lt;h6 id=&#34;二维nyquist条件&#34;&gt;二维Nyquist条件&lt;/h6&gt;
&lt;p&gt;为使采样以后的信号$f_s (x,y)$能完全恢复原来连续信号f(x,y) ，采样间隔Δx和Δy就必须满足$∆x≤1/(2f_{xc} ) ,∆y≤1/(2f_{yc})$，即在x和y方向的采样频率必须大于图像在x和y方向最高频率的两倍&lt;/p&gt;
&lt;p&gt;二维信号重建&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416160057963.png&#34; alt=&#34;image-20210416160057963&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;亚采样&#34;&gt;亚采样&lt;/h6&gt;
&lt;p&gt;（1）降低采样频率&lt;/p&gt;
&lt;p&gt;（2）将按采样定理获得的图像再抽样，即每隔K个像素，保留1个像素，其余的丢掉，重构时用内插法恢复丢失的数据。256×256每隔2个像素，保留1个像素-&amp;gt;128×128&lt;/p&gt;
&lt;h4 id=&#34;122图像数字化量化&#34;&gt;1.2.2图像数字化——量化&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416160641526.png&#34; alt=&#34;image-20210416160641526&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;L在&lt;strong&gt;3bit以下&lt;/strong&gt;的量化，会出现伪轮廓现象（画面平场区域出现明显的类似于等高线的不连续过渡带，从而对于画面感观质量造成影响的现象）。&lt;/p&gt;
&lt;p&gt;均匀量化：简单地在灰度范围内等间隔量化。&lt;/p&gt;
&lt;p&gt;非均匀量化：对像素出现频度少的部分量化间隔取大，而对频度大的量化间隔取小。&lt;/p&gt;
&lt;h3 id=&#34;13-数字图像基本要素&#34;&gt;1.3 数字图像基本要素&lt;/h3&gt;
&lt;h4 id=&#34;131基本要素&#34;&gt;1.3.1基本要素&lt;/h4&gt;
&lt;p&gt;像素是数字图像最小的单位&lt;/p&gt;
&lt;p&gt;图像尺寸——一幅数字图像矩阵的大小&lt;/p&gt;
&lt;p&gt;像素坐标系——对图像分布进行二维空间采样&lt;/p&gt;
&lt;p&gt;像数值—对单个像素灰度值进行数字化采样（k bits/pixel）&lt;/p&gt;
&lt;h4 id=&#34;132图像质量&#34;&gt;1.3.2图像质量&lt;/h4&gt;
&lt;p&gt;灰度：表示图像&lt;strong&gt;像素明暗程度&lt;/strong&gt;的数值&lt;/p&gt;
&lt;p&gt;灰度级——表明图象中&lt;strong&gt;不同灰度的最大数量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对比度=最大灰度值/最小灰度值 ——反映一幅图像中灰度方差的大小&lt;/p&gt;
&lt;h4 id=&#34;133图像颜色红绿蓝三基色&#34;&gt;1.3.3图像颜色：红、绿、蓝三基色&lt;/h4&gt;
&lt;h4 id=&#34;134图像的描述灰度黑白彩色图像链表拓扑结构距离&#34;&gt;1.3.4图像的描述：灰度/黑白/彩色图像、链表、拓扑结构、距离&lt;/h4&gt;
&lt;p&gt;灰度图像&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像中每个像素的信息由一个量化的灰度级来描述，没有彩色信息。&lt;/li&gt;
&lt;li&gt;当一幅图像有2&lt;em&gt;k&lt;/em&gt;灰度级时，通常称该图像是&lt;em&gt;k&lt;/em&gt;比特图像。&lt;/li&gt;
&lt;li&gt;灰度图像像素的灰度级通常为8 Bits，即0~255。“0”表示纯黑色，“255”表示纯白色。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;黑白图像（二值图像）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;像素值为0、1。二值图像通常用于文字、线条图的扫描识别(OCR)和掩模图像的存储。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;彩色图像&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;三维矩阵，可用&lt;em&gt;M&lt;/em&gt;×&lt;em&gt;N&lt;/em&gt;×3表示，&lt;em&gt;M&lt;/em&gt;、&lt;em&gt;N&lt;/em&gt;分别表示图像的行、列数，三个&lt;em&gt;M&lt;/em&gt;×&lt;em&gt;N&lt;/em&gt;的二维矩阵分别表示各个像素的R、G、B三个颜色分量。每个颜色分量的数据类型一般为8位无符号整型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;链表—描述目标物体的边界&lt;/p&gt;
&lt;p&gt;拓扑结构——描述一组图形及其相互关系&lt;/p&gt;
&lt;p&gt;距离—描述图像中像素之间的接近程度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416161847144.png&#34; alt=&#34;image-20210416161847144&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;欧氏、曼哈顿（城区）（坐标差绝对值相加）、棋盘（坐标差绝对值最大的那个）&lt;/p&gt;
&lt;h4 id=&#34;135图像的矩阵特性距离邻域临接连通&#34;&gt;1.3.5图像的矩阵特性：距离、邻域、临接、连通&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;邻域&lt;/strong&gt;—描述与像素相邻的其他像素&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416162246265.png&#34; alt=&#34;image-20210416162246265&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;邻接&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;像素间邻接的两个必要条件：①一个像素在另一个像素的&lt;strong&gt;邻域&lt;/strong&gt;中；②两个像素的灰度值满足特定的&lt;strong&gt;相似准则&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;令V表示关于邻接的灰度值集合(相似准则)。&lt;/p&gt;
&lt;p&gt;①4-邻接 像素&lt;em&gt;p&lt;/em&gt;和&lt;em&gt;q&lt;/em&gt;的灰度值都属于&lt;em&gt;V&lt;/em&gt;，且&lt;em&gt;q&lt;/em&gt;在p的4-邻域集合**$N_4(p)$**中，则称像素*p*和*q*是4-邻接的。&lt;/p&gt;
&lt;p&gt;②8-邻接 像素&lt;em&gt;p&lt;/em&gt;和&lt;em&gt;q&lt;/em&gt;的灰度值都属于&lt;em&gt;V&lt;/em&gt;，且&lt;em&gt;q&lt;/em&gt;在集合$N_8(p)$中，则称像素&lt;em&gt;p&lt;/em&gt;和&lt;em&gt;q&lt;/em&gt;是8-邻接的。&lt;/p&gt;
&lt;p&gt;③m-邻接 像素&lt;em&gt;p&lt;/em&gt;和&lt;em&gt;q&lt;/em&gt;的灰度值都属于&lt;em&gt;V&lt;/em&gt;，若满足下列条件&lt;strong&gt;之一&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;•&lt;em&gt;q&lt;/em&gt;在集合$N_4(p)$中；&lt;/p&gt;
&lt;p&gt;•&lt;em&gt;q&lt;/em&gt;在集合$N_D(p)$中（对角邻域）,且集合$N_4(p)\cap N_4(q)$中的像素的灰度值不属于&lt;em&gt;V&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;则称像素&lt;em&gt;p&lt;/em&gt;和&lt;em&gt;q&lt;/em&gt;是m-邻接的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;像素间的通路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从坐标为$(x_0,y_0 )$的像素&lt;em&gt;p&lt;/em&gt;到坐标为$(x_n,y_n )$的像素&lt;em&gt;q&lt;/em&gt;的一条通路由像素序列组成对应坐标序列为:&lt;/p&gt;
&lt;p&gt;$ (x_0,y_0 ) ,(x_1,y_1 ), ⋯,(x_i,y_i ) ⋯,(x_n,y_n ) $，这里$(x_i,y_i )$与$(x_{i-1},y_{i-1} )$相邻接，n为通路长度。&lt;/p&gt;
&lt;p&gt;若$(x_0,y_0 )=(x_n,y_n )$则该通路是闭合通路。&lt;strong&gt;根据不同的邻接类型，可以得到不同的通路，如4-通路，8-通路和&lt;em&gt;m&lt;/em&gt;-通路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;连通&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;若像素p和q之间存在着一条通路，则称p和q是连通的，即像素间的连通。反之，若两个像素间是连通的，那么至少存在一条通路，也可能存在多条通路。&lt;strong&gt;根据通路的类型，像素间的连通可分为4-连通，8-连通和m-连通&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;136图像文件格式&#34;&gt;1.3.6图像文件格式&lt;/h4&gt;
&lt;p&gt;每一种图像文件均有一个&lt;strong&gt;文件头&lt;/strong&gt;，在文件头之后是&lt;strong&gt;图像数据&lt;/strong&gt;。文件头的内容一般包括&lt;strong&gt;文件类型、版本号、文件大小等&lt;/strong&gt;内容。各种图像文件的制作还涉及到图像文件的压缩方式和存储效率等。常用的图像文件存储格式主要有：BMP格式、JPEG格式、GIF格式、TIFF格式等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BMP&lt;/strong&gt;(bitmap)图像文件也称位图文件，其文件结构如下：&lt;/p&gt;
&lt;p&gt;a) BITMAPFILEHEADER：BMP文件头或表头；b) BITMAPINFOHEADER：BMP文件信息头；&lt;/p&gt;
&lt;p&gt;c) RGBQUAD：BMP文件调色板或位图信息；d) BITMAP DATA：BMP文件数据或位图阵列；&lt;/p&gt;
&lt;p&gt;位图文件头长度为固定的54个字节，给出了文件的类型、大小和位图阵列的起始位置等信息。位图文件信息头基本上包含图像的所有信息，包括宽度、高度、每像素的位数、压缩方法、目标设备的水平和垂直分辨率等信息。位图文件调色板是BMP所包含的颜色表，接在BITMAPINFOHEADER结构之后含有位图中每种颜色的RGB信息。BMP文件数据是以连续行的形式存储的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JPEG&lt;/strong&gt; (Joint Photographic Experts Group)的文件后辍名为“.jpg”或“.jpeg”。有损压缩格式，支持24位颜色，并保留照片和其他连续色调图像中存在的亮度和色相的显著和细微的变化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GIF&lt;/strong&gt; (Graphics Interchange Format)的文件后缀名为“.gif”。GIF格式的特点是其在一个GIF文件中可以存多幅彩色图像，如果把存于一个文件中的多幅图像数据逐幅读出并显示到屏幕上，就可构成一种最简单的动画。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TIFF&lt;/strong&gt; (Tag Image File Format)的文件后缀名为“.tif”或“.tiff”。TIFF文件一般可分为文件头、参数指针表、参数数据表的偏移。参数指针表由一系列参数块构成，它们描写图像的压缩种类、长度、彩色数、扫描分辨率等许多参数。参数数据表中存放的是实际参数数据。最后一部分是图像数据。&lt;/p&gt;
&lt;h3 id=&#34;14-数字图像处理意义及内容&#34;&gt;1.4 数字图像处理意义及内容&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;数字图像处理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）利用计算机对数字图像进行各种目的的处理&lt;/p&gt;
&lt;p&gt;（2）将一幅图像变为另一幅经过加工的图像，图像到图像的过程&lt;/p&gt;
&lt;p&gt;（3）将一幅图像转化为一种非图像的表示，分析、识别与理解的过程&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.提高图像视觉质量，提供人眼主观满意或较满意的效果；2.提取目标某些特征，以便于后续分析或识别；3.图像压缩，便于存储和传输庞大的图像和视频信息。4.信息的可视化，以便于人们观察、分析、研究、理解大规模数据和许多复杂现象5.信息安全需要，如数字图像水印和图像信息隐藏&lt;/p&gt;
&lt;p&gt;•数字图像处理是利用计算机的计算，实现与光学系统模拟处理相同效果的过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1)再现性好。数字化，存储，传输或复制不会退化图像质量.(2)处理精度高。灰度等级量化为16位(3)适用面宽。多种信息源：可见光，波谱（X射线，R射线，超声或红外）客观实体尺度：电子显微、航空、遥感、天文图像(4)灵活性高。线性处理，非线性处理。凡是可以用数学公式或逻辑关系来表示的一切运算均可用数字图像处理实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主要内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）几何处理：坐标变换、图像放大、缩小、旋转、移动；多个图像的配准、全景畸变校正、扭曲校正；计算周长、面积、体积&lt;/p&gt;
&lt;p&gt;（2）算数处理：对图像进行加减乘除运算，与、或等逻辑运算；主要针对像素医学图像的减影处理&lt;/p&gt;
&lt;p&gt;（3）图像增强：突出图像中感兴趣的信息，去掉或削弱不感兴趣的信息，使其在特定的应用中更便于解释和识别提高图像质量（去除噪声、提高图像的清晰度）；方法：灰度修正、平滑、几何校正、图像锐化、频域增强、维纳滤波、卡尔曼滤波…&lt;/p&gt;
&lt;p&gt;（4）图像复原：去掉干扰和污染，恢复图像的本来面目；1)图像噪声：随机点、相干噪声(网纹干扰)2)模糊：透镜散光、相对运动3)遥感：大气流、云层遮挡；主要方法：维纳滤波、卡尔曼滤波、逆滤波、同态滤波等&lt;/p&gt;
&lt;p&gt;（5）图像重建：从数据到图像的过程，CT、x-ray、NMR（核磁共振）、超声CT、ECT；•成像方法：代数法、迭代法、傅立叶反投影法、卷积三维重建-用于虚拟现实、科学可视化技术&lt;/p&gt;
&lt;p&gt;（6）图像编码：运用图像信号的统计特性以及视觉的生理学和心理学特性实现高效编码 ；目的：I.减少数据存储空间II.降低数据率、减少传输带宽III.压缩信息、提取特征，以便识别&lt;/p&gt;
&lt;p&gt;（7）图像识别：方法：统计识别（特征）、句法结构（结构基元）、模糊识别(模糊学习、人的思维方法)&lt;/p&gt;
&lt;p&gt;（8）图像理解：利用客观世界的知识，使计算机进行联想、思考、推论，从而理解图像表现的内容（景物理解）&lt;/p&gt;
&lt;p&gt;（9）图像分割：提取出感兴趣的对象，为进一步理解识别做准备；灰度阀值分割、基于纹理的分割、区域生长法&lt;/p&gt;
&lt;h3 id=&#34;15-数字图像处理系统及应用&#34;&gt;1.5 数字图像处理系统及应用&lt;/h3&gt;
&lt;h4 id=&#34;151数字图像特性图像显示分辨率打印机分辨率-像素深度-位面数量&#34;&gt;1.5.1数字图像特性：图像/显示分辨率/打印机分辨率 像素深度 位面数量&lt;/h4&gt;
&lt;p&gt;图像分别率：指组成一幅图像的像素密度，即图幅参数。单位：像素*像素&lt;/p&gt;
&lt;p&gt;e.g.数码相机指标：640*480=307200,30万像素&lt;/p&gt;
&lt;p&gt;显示分辨率:指显示屏上能够显示出的像素数目。例如，显示分辨率为640x480表示显示屏分成480行，每行显示640个像素。整个显示屏就含有307200个显像点。&lt;/p&gt;
&lt;p&gt;打印机、扫描仪分辨率：dpi（display pixels/incj）每英寸显示的线数&lt;/p&gt;
&lt;p&gt;像素深度：存储每个像素所用的位数，它也是用来度量图像的分辨率&lt;/p&gt;
&lt;p&gt;位面数量：组成图像的像素矩阵维数。&lt;/p&gt;
&lt;h4 id=&#34;152数字图像处理系统&#34;&gt;1.5.2数字图像处理系统&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416165102682.png&#34; alt=&#34;image-20210416165102682&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;图像采集系统将模拟图像转换成适合数字计算机处理的数字图像，包括1.数码摄像机：它通过接口电路与计算机连接，在有关软件的控制下将图像数据输入计算机2.数码照相机：与数码摄像机的区别在于没有连续获取图像的能力3.扫描仪：它可以将胶片上的摄影图像或纸质载体上的文字、图形、表格扫描成数字信息直接载入计算机&lt;/p&gt;
&lt;p&gt;计算机执行数字图像处理；•安装有各种图像处理软件，如Ps，Matlab中的图像处理工具箱; 图像处理软件接受来自图像采集系统的数字图像并执行所需的操作，如图像增强、图像复原、图像压缩编码、图像分析等操作，最后输出处理结果&lt;/p&gt;
&lt;p&gt;图像输出设备主要指喷墨打印机、激光打印机、图像监视器、视频拷贝仪等，它们的发展趋势是高速、真彩色&lt;/p&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;第二章-数字图像预处理方法&#34;&gt;第二章 数字图像预处理方法&lt;/h2&gt;
&lt;p&gt;主要目的：&lt;/p&gt;
&lt;p&gt;•消除图像中无关的信息，恢复有用的真实信息。&lt;/p&gt;
&lt;p&gt;•增强有关信息的可检测性、最大限度地简化数据，从而改进特征提取、图像分割、匹配和识别的可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤：1.灰度化 2.去噪声&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;21-灰度化&#34;&gt;2.1 灰度化&lt;/h3&gt;
&lt;p&gt;图像灰度化的原理就是在RGB模型中，假定三个通道的值相等，然后用统一的灰度值表征该点的色彩信息，灰度值的范围是0到255。&lt;/p&gt;
&lt;p&gt;像素点矩阵中的每一个像素点都满足下面的关系：R=G=B，此时的这个值叫做灰度值。&lt;/p&gt;
&lt;h4 id=&#34;211灰度化主要方法&#34;&gt;2.1.1灰度化主要方法&lt;/h4&gt;
&lt;p&gt;1）分量法：将彩色图像中的三分量RGB的亮度作为三个灰度图像的灰度值，可根据应用需要选取三种中的一种灰度图像。&lt;/p&gt;
&lt;p&gt;2）最大值法：将彩色图像中的三分量亮度的最大值作为灰度图的灰度值。&lt;/p&gt;
&lt;p&gt;3）平均值法：将彩色图像中的三分量亮度求平均得到一个灰度图。&lt;/p&gt;
&lt;p&gt;4）加权平均法：根据重要性及其它指标，将三个分量以不同的权值进行加权平均。&lt;/p&gt;
&lt;p&gt;由于人眼对绿色的敏感最高，对蓝色敏感最低。Gray=0.11B+0.59G+0.3R；OpenCV开放库所采用的灰度权值 Gray=0.072169B+0.715160G+0.212671R&lt;/p&gt;
&lt;h4 id=&#34;212图像二值化&#34;&gt;2.1.2图像二值化&lt;/h4&gt;
&lt;p&gt;p二值化通用方法：选择某个阈值T，将原始图像变为二值图像：&lt;/p&gt;
&lt;p&gt;当f(x,y)≥T时， f(x,y)=1&lt;/p&gt;
&lt;p&gt;当f(x,y) ≤T时， f(x,y)=0&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如同其他图像分割算法一样，没有一个现有方法对各种各样的图像都能得到令人满意的结果。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;几种阈值确定办法：&lt;/p&gt;
&lt;h5 id=&#34;1全局二值化&#34;&gt;1.全局二值化&lt;/h5&gt;
&lt;p&gt;目的：从多值的数字图像中直接提取出目标物体）设定一个全局的阈值T，用T将图像的数据分成两部分：大于T的像素群和小于T的像素群。将大于T的像素群的像素值设定为白色（或者黑色），小于T的像素群的像素值设定为黑色（或者白色）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;a)&lt;/strong&gt; 取阀值为127（相当于0~255的中数），让灰度值小于等于127的变 为0（黑色），灰度值大于127的变为255（白色），这样做的好处是计算量小速度快，但是缺点也是很明显的，因为这个阀值在不同的图片中均为127，但是不同的图片，他们的颜色分布差别很大，所以用127做阀值，白菜萝卜一刀切，效果肯定是不好的。&lt;/p&gt;
&lt;p&gt;b)计算像素点矩阵中的所有像素点的&lt;strong&gt;灰度值的平均值K&lt;/strong&gt;。然后让每一个像素点与K一 一比较，小于等于K的像素点就为0（黑色）大于K的 像素点为255（白色），这样做比方法1好一些。但是使用平均值作为二值化阈值同样有个致命的缺点，可能导致部分对象像素或者背景像素丢失。二值化结果不能真实反映源图像信息。&lt;/p&gt;
&lt;p&gt;c)使用&lt;strong&gt;直方图方法&lt;/strong&gt;（也叫双峰法）来寻找二值化阀值直方图是图像的重要特质。直方图方法认为图像由前景和背景组成，在&lt;strong&gt;灰度直方图上，前景和背景都形成高峰&lt;/strong&gt;，在双峰之间的最低，谷处就是阀值所在。取到阀值之后再一 一比较就可以了&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直方图&lt;/strong&gt;：表示数字图像中每一灰度级像素出现的频次（该灰度级的像素数目）。&lt;/p&gt;
&lt;p&gt;$p(k)=n_{k }$或 $p(k)=\frac{n_{k }}{n}$  $n_{k}$:&amp;ldquo;图像中第k个灰度级的像素总数 &amp;ldquo;，$n$:图像的像素总数&lt;/p&gt;
&lt;p&gt;直方图性质：1.无空间信息；2.直方图与图像一对多关系；3.可叠加性（全图与子图像）&lt;/p&gt;
&lt;p&gt;直方图反映了图像清晰程度。直方图均匀分布时，图像最清晰。&lt;strong&gt;判断一幅图像是否清晰，查看是否合理的利用了全部被允许的灰度级&lt;/strong&gt; 一幅图像应该尽可能利用全部可能的灰度级。&lt;/p&gt;
&lt;p&gt;直方图也反映图像对比度和亮度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416184148236.png&#34; alt=&#34;image-20210416184148236&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416184156275.png&#34; alt=&#34;image-20210416184156275&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416184227637.png&#34; alt=&#34;image-20210416184227637&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;直方图分为四个基本类型：RGB直方图、通道直方图、明度直方图和颜色直方图。&lt;/p&gt;
&lt;p&gt;通道直方图：R G B通道分别画直方图。RGB直方图就是通道直方图的叠加。&lt;/p&gt;
&lt;p&gt;明度直方图是复合计算单个像素之后绘制的直方图，相对RGB更能反映一张照片的亮度分布趋势。&lt;/p&gt;
&lt;p&gt;•只有当一个像素中的R、G、B值同时为0 的时候，明度直方图的最左端才有凸起，而RGB直方图只要有任意一个像素中的任意一个R、G、B值为0，它的最左端就有凸起。&lt;/p&gt;
&lt;p&gt;颜色直方图，可以理解为加了颜色的RGB直方图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;d)&lt;strong&gt;一种使用&lt;/strong&gt;近似一维Means方法&lt;/strong&gt;寻找二值化阈值：&lt;/p&gt;
&lt;p&gt;①初始化一个阈值T，可以自己设置或者根据随机方法生成。&lt;/p&gt;
&lt;p&gt;②根据阈值图将每个像素数据P(n,m)分为对象像素数据G1与背景像素数据G2。(n为行，m为列)&lt;/p&gt;
&lt;p&gt;③G1的平均值是m1, G2的平均值是m2&lt;/p&gt;
&lt;p&gt;④一个新的阈值T^′=(m1+m2)/2&lt;/p&gt;
&lt;p&gt;⑤回到第二步，用新的阈值继续分像素数据为对象与背景像素数据，继续2～4步，&lt;/p&gt;
&lt;p&gt;⑥直到计算出来的新阈值等于上一次阈值。&lt;/p&gt;
&lt;h5 id=&#34;2局部二值化&#34;&gt;2.局部二值化&lt;/h5&gt;
&lt;p&gt;全局二值化在表现&lt;strong&gt;图像细节&lt;/strong&gt;方面存在很大缺陷。为了弥补这个缺陷，出现了局部二值化方法。&lt;/p&gt;
&lt;p&gt;•局部二值化的方法就是按照一定的规则将整幅图像**划分为N个窗口，&lt;strong&gt;对这N个窗口中的&lt;/strong&gt;每一个窗口再按照一个统一的阈值$T_i$**将该窗口内的像素划分为两部分，进行二值化处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.局部自适应二值化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;局部二值化值是没有经过合理的运算得来，一般是取该窗口的平局值。这就导致在每一个窗口内仍然出现的是全局二值化的缺陷。为了解决这个问题，就出现了局部自适应二值化方法。&lt;/p&gt;
&lt;p&gt;•局部自适应二值化的阈值是通过对该窗口像素的平均值E，像素之间的差平方P，像素之间的均方根值Q等各种&lt;strong&gt;局部特征&lt;/strong&gt;，设定一个参数方程进行阈值的计算，例如：T=a*E+b*P+c*Q，其中a,b,c是自由参数。这样得出来的二值化图像就更能表现出二值化图像中的细节。&lt;/p&gt;
&lt;h3 id=&#34;22图像噪声&#34;&gt;2.2图像噪声&lt;/h3&gt;
&lt;p&gt;•图像噪声是指存在于图像数据中的不必要的或多余的干扰信息。 图像中各种妨碍人们对其信息接受的因素即可称为图像噪声 。&lt;/p&gt;
&lt;p&gt;•噪声在图像上&lt;strong&gt;常表现为&lt;/strong&gt;一&lt;strong&gt;引起较强视觉效果&lt;/strong&gt;的&lt;strong&gt;孤立像素点或像素块&lt;/strong&gt;。是图像信息或者像素亮度的随机变化。一般，噪声信号与要研究的对象不相关，它以&lt;strong&gt;无用的信息&lt;/strong&gt;形式出现，扰乱图像的可观测信息。通俗的说就是噪声让图像不清楚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;来源&lt;/strong&gt;1.图像获取过程中，图像传感器CCD和CMOS采集图像过程中受传感器材料属性、工作环境、电子元器件和电路结构等影响，会引入各种噪声2.图像信号传输过程中，传输介质和记录设备等的不完善，数字图像在其传输记录过程中往往会受到多种噪声的污染。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;影响&lt;/strong&gt;•对于数字图像信号，噪声表为或大或小的极值，这些极值通过加减作用于图像像素的真实灰度值上，对图像造成亮、暗点干扰，极大降低了图像质量，影响图像复原、分割、特征提取、图像识别等后继工作的进行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;脉冲噪声模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416190134462.png&#34; alt=&#34;image-20210416190134462&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;221分类&#34;&gt;2.2.1分类&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;基于产生原因&lt;/strong&gt;：&lt;strong&gt;外部噪声&lt;/strong&gt;，即指系统外部干扰以电磁波或经电源串进系统内部而引起的噪声。如外部电气设备产生的电磁波干扰、天体放电产生的脉冲干扰等。由系统电气设备内部引起的噪声为内部噪声，如内部电路的相互干扰。&lt;strong&gt;内部噪声&lt;/strong&gt;一般又可分为以下四种：(1)由光和电的基本性质所引起的噪声。(2)电器的机械运动产生的噪声。(3)器材材料本身引起的噪声。(4)系统内部设备电路所引起的噪声。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于噪声与信号的关系&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;a)&lt;strong&gt;加性噪声&lt;/strong&gt;g=f+n：加性噪声和图像信号强度是不相关的和&lt;/p&gt;
&lt;p&gt;b)&lt;strong&gt;乘性嗓声&lt;/strong&gt;g=f+fn：乘性嗓声和图像信号是相关的，往往随图像信号的变化而变化，载送每一个象素信息的载体的变化而产生的噪声受信息本身调制。在某些情况下，如信号变化很小，噪声也不大。为了分析处理方便，常常将乘性噪声近似认为是加性噪声，而且总是假定信号和噪声是互相统计独立。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于统计后的概率密度函数&lt;/strong&gt;：比较重要；引入数学模型，就有助于运用数学手段去除噪声。在不同场景下噪声的施加方式都不同，由于&lt;strong&gt;在外界的某种条件下，噪声下图像-原图像（没有噪声时）的概率密度函数（统计结果）服从某种分布函数，就把它归类为相应的噪声。&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&#34;2211基于统计后的概率密度函数的噪声分类及其消除方式&#34;&gt;2.2.1.1基于统计后的概率密度函数的噪声分类及其消除方式&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;高斯噪声&lt;/strong&gt;是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。如果一个噪声的幅度分布服从高斯分布，而它的功率谱密度又是均匀分布的，则称它为高斯白噪声。&lt;strong&gt;高斯白噪声的二阶矩不相关，一阶矩为常数，是指先后信号在时间上的相关性。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416190707039.png&#34; alt=&#34;image-20210416190707039&#34; style=&#34;zoom:70%;&#34; /&gt;其中x表示灰度值，μ表示x的平均值或期望值，σ表示x的标准差。&lt;/p&gt;
&lt;p&gt;•产生原因：a)电路各元器图像传感器在拍摄时市场不够明亮、亮度不够均匀；b)件自身噪声和相互影响；&lt;/p&gt;
&lt;p&gt;c)图像传感器长期工作，温度过高。&lt;/p&gt;
&lt;p&gt;•噪声对原图像的影响是随机的，直方图呈现的分布形式是基于统计的结果。直方图表示了（归一化后）灰度值的概率密度分布，因此可以使用直方图来表示灰度值的概率密度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;瑞利噪声&lt;/strong&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416191359199.png&#34; alt=&#34;image-20210416191359199&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;伽马（爱尔兰）噪声&lt;/strong&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416191444291.png&#34; alt=&#34;image-20210416191444291&#34; style=&#34;zoom:50%;&#34; /&gt;，其中 α称为形状参数（shape parameter），主要决定了分布曲线的形状，而 β称为 rate parameter（或叫 inverse scale parameter， 1/β称为scale parameter），主要决定曲线有多陡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;脉冲（椒盐）噪声&lt;/strong&gt; &lt;img src=&#34;https://K7288.github.io/assets/image-20210416191636444.png&#34; alt=&#34;image-20210416191636444&#34; style=&#34;zoom:50%;&#34; /&gt;一种随机出现的白点或者黑点，可能是亮的区域有黑色像素或是在暗的区域有白色像素（或是两者皆有）。成因可能是影像讯号受到突如其来的强烈干扰而产生、类比数位转换器或位元传输错误等。例如失效的感应器导致像素值为最小值，饱和的感应器导致像素值为最大值。&lt;/p&gt;
&lt;p&gt;如果b&amp;gt;a，灰度值b在图像中将显示为一个亮点，相反，a的值将显示为一个暗点。若Pa或Pb为零，则脉冲噪声称为单极脉冲。如果Pa和Pb均不可能为零，尤其是它们近似相等时，脉冲噪声值将类似于随机分布在图像上的胡椒和盐粉微粒。由于这个原因，双极脉冲噪声也称为椒盐噪声。同时，它们有时也称为散粒和尖峰噪声。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416191556048.png&#34; alt=&#34;image-20210416191556048&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;椒盐噪声是惟一一种引起退化的视觉可见的噪声类型&lt;/strong&gt;。其他的虽然直方图相似但也很难看出区别。&lt;/p&gt;
&lt;p&gt;直方图和概率密度函数有对应关系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/20160629115825424.png&#34; alt=&#34;img&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/20160629115835408.png&#34; alt=&#34;img&#34; style=&#34;zoom:63%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;222图像过滤噪声-空间域滤波-频率域滤波-形态学运算&#34;&gt;2.2.2图像过滤噪声 空间域滤波 频率域滤波 形态学运算&lt;/h4&gt;
&lt;p&gt;空间域滤波是指直接通过原图像中像素点的灰度值进行数据运算去除噪声的方法,常见的空间域滤波方法主要有均值滤波、中值滤波、高斯低通滤波等；&lt;/p&gt;
&lt;p&gt;//线性 非线性 fo(x,y)= T[ fi(x,y) ]，T是线性/非线性算子&lt;/p&gt;
&lt;h5 id=&#34;中值滤波器&#34;&gt;中值滤波器&lt;/h5&gt;
&lt;p&gt;非线性平滑滤波器，将图像中以某像素点为中心的窗口范围内的所有像素点的灰度值(包括该中心像素点)进行排序,然后将灰度序列的中间值赋给该中心像素点。&lt;/p&gt;
&lt;p&gt;其他线性滤波考量每个像素，中值滤波会忽略那些相对邻域(此处设为n*n窗口)内大部分像素点而言,亮度偏暗或偏亮,且所占区域小于总像素点一半(即n/2)的像素点的影响,从而有效滤除孤立的噪声点。&lt;/p&gt;
&lt;p&gt;中值滤波法对于某些类型的随机噪声，如图像扫描噪声等等，具有良好的去噪效果，特别是在滤除噪声的同时，能够保护信号的边缘，使之不被模糊。这些优良特性是线性滤波方法所不具有的。中值滤波的算法比较简单，也易于用硬件实现。&lt;/p&gt;
&lt;h5 id=&#34;超限中值滤波法&#34;&gt;超限中值滤波法&lt;/h5&gt;
&lt;p&gt;相对中值滤波保留图像细节&lt;/p&gt;
&lt;p&gt;•基于个数的中值滤波法：通过设定阈值&lt;strong&gt;T限制&lt;/strong&gt;邻域内像素点与中心像素点灰度差绝对值&lt;strong&gt;的范围，从而将含噪图像中的像素点的属性划分为&lt;/strong&gt;平坦区域、图像边缘、噪点三类。&lt;/p&gt;
&lt;h5 id=&#34;均值滤波邻域平均法&#34;&gt;均值滤波/邻域平均法&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;线性滤波&lt;/strong&gt;算法，它是指在图像上对目标像素给一个模板，该模板包括了其周围的临近像素（以目标象素为中心的周围8个像素，构成一个滤波模板，即去掉目标像素本身），再用模板中的全体像素的平均值来代替原来像素值。&lt;/p&gt;
&lt;p&gt;对噪声图像特别是有大的孤立点的图像非常敏感，即使有极少数量点存在较大差异也会导致平均值的明显波动。不能很好地保护图像细节，在图像去噪的同时也破坏了图像的细节部分，从而使图像变得模糊，模糊程度与邻域半径成正比不能很好地去除噪声点。特别是椒盐噪声。&lt;/p&gt;
&lt;h5 id=&#34;超限邻域平均法&#34;&gt;超限邻域平均法&lt;/h5&gt;
&lt;p&gt;如果某个像素的灰度值大于其邻域像素的平均值，且达到了一定水平，则判断该像素为噪声，继而用邻域像素的均值取代这一像素值&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416193522476.png&#34; alt=&#34;image-20210416193522476&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;一般的,“超限邻域平均法”比一般邻域平均法的效果要好&lt;/p&gt;
&lt;p&gt;在操作中对窗口的大小及门限的选择要慎重，T太小，噪声消除不干净；T太大，易使图像模糊&lt;/p&gt;
&lt;p&gt;在实际应用中一般选用3×3窗口加权均值滤波器&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416193638514.png&#34; alt=&#34;image-20210416193638514&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;高斯滤波&#34;&gt;高斯滤波&lt;/h5&gt;
&lt;p&gt;1、定义 &lt;strong&gt;线性滤波器&lt;/strong&gt;，适用于消除高斯噪声，广泛应用于图像处理的减噪过程。&lt;/p&gt;
&lt;p&gt;2、作用原理 和均值滤波器类似，用一个模板（或称&lt;strong&gt;卷积&lt;/strong&gt;、掩模）扫描图像中的每一个像素，用模板确定的&lt;strong&gt;邻域内像素的加权平均灰度值&lt;/strong&gt;去&lt;strong&gt;替代模板中心像素点&lt;/strong&gt;的值。&lt;/p&gt;
&lt;p&gt;3、系数特征 均值滤波器的模板系数都是1；而高斯滤波器的模板系数，则&lt;strong&gt;随着距离模板中心的增大而系数减小&lt;/strong&gt;（高斯分布）。所以，高斯滤波器相比于均值滤波器对图像个模糊程度较小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;卷积核：高斯核&lt;/strong&gt; 理论上，高斯分布在所有定义域上都有非负值，这就需要一个无限大的卷积核。实际上，仅需要取均值周围3倍标准差内的值，以外部份直接去掉即可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210416194507618.png&#34; alt=&#34;image-20210416194507618&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;4、真实图像在空间内的像素是缓慢变化的，因此临近点的像素变化不会很明显，所以高斯滤波在保留信号的条件下减少噪声。这种方法&lt;strong&gt;在接近边缘处无效&lt;/strong&gt;，因此高斯滤波会破平边缘。但是，高斯平滑滤波器对于抑制服从正态分布的噪声仍非常有效。&lt;/p&gt;
&lt;p&gt;5、性质 （1）二维高斯函数具有&lt;strong&gt;旋转对称性&lt;/strong&gt;，即&lt;strong&gt;滤波器在各个方向上的平滑程度相同&lt;/strong&gt;一般来说，一幅图像的边缘方向是事先不知道的，因此，在滤波前是无法确定一个方向上比另一方向上需要更多的平滑．旋转对称性意味着高斯平滑滤波器在后续&lt;strong&gt;边缘检测中不会偏向任一方向&lt;/strong&gt;（2）高斯函数是&lt;strong&gt;单值函数&lt;/strong&gt;，高斯滤波器用像素邻域的加权均值来代替该点的像素值，而每一邻域像素点权值是随该点与中心点的距离单调增减的（3）高斯函数的傅立叶变换频谱是单瓣的；既能保留低频分量，又能保留高频分量，因此能比较好地保留图像的低频和高频信息，并在保留图像信息和滤出噪声之间找到一个平衡点。（4）高斯&lt;strong&gt;滤波器宽度(决定着平滑程度)&lt;strong&gt;是由&lt;/strong&gt;参数σ&lt;/strong&gt;表征的。σ越大，高斯滤波器的频带就越宽，平滑程度就越好。通过调节平滑程度参数σ，可在图像特征过分模糊(过平滑)与平滑图像中由于噪声和细纹理所引起的过多的不希望突变量(欠平滑)之间取得折衷（5）由于&lt;strong&gt;高斯函数的可分离性&lt;/strong&gt;，较大尺寸的高斯滤波器可以得以有效地实现．&lt;strong&gt;二维高斯函数卷积可以分两步来进行&lt;/strong&gt;，首先将图像与一维高斯函数进行卷积，然后将卷积结果与方向垂直的相同一维高斯函数卷积．因此，二维高斯滤波的&lt;strong&gt;计算量随滤波模板宽度成线性增长&lt;/strong&gt;而不是成平方增长．&lt;/p&gt;
&lt;p&gt;6、特征&lt;/p&gt;
&lt;p&gt;1)一个高斯函数跟另外一个高斯函数的卷积仍然是一个高斯函数，A*B=C  C的标准差的平方是A和B的标准差的平方和，也就是说卷积后的高斯函数更宽，模糊的效果更明显（直观上看，连续做高斯模糊运算，图像会越来越模糊） 2)高斯函数的傅立叶变换仍然是一个高斯函数，如果原来的高斯函数越宽（标准差越大），变换后的高斯函数就越窄（标准差越小），也就是说一个越宽的高斯函数，低通（高阻）滤波的效果越明显，处理后的图像的细节就越不清楚（更模糊）&lt;/p&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;第三章-图像增强&#34;&gt;第三章 图像增强&lt;/h2&gt;
&lt;h3 id=&#34;31-图像增强概述&#34;&gt;3.1 图像增强概述&lt;/h3&gt;
&lt;h4 id=&#34;311-定义&#34;&gt;3.1.1 定义&lt;/h4&gt;
&lt;p&gt;图像增强(Image enhancement)是图像处理的基本内容之一。图像增强是指按特定的需要突出一幅图像中的某些信息，同时，削弱(weaken)或去除(eliminate)某些不需要的信息。这类处理是为了某种应用目的去改善图像质量，处理的结果更适合于人的视觉特性或机器识别系统。增强处理并&lt;strong&gt;不能增加原始图像的信息&lt;/strong&gt;，而只能&lt;strong&gt;增强对某种信息的辨识能力&lt;/strong&gt;，并且这种处理有&lt;strong&gt;可能损失一些其它信息&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;312-应用&#34;&gt;3.1.2 应用&lt;/h4&gt;
&lt;p&gt;第一类是改善图像的视觉效果；第二是突出图像的特征，便于计算机处理&lt;/p&gt;
&lt;p&gt;图像在生成、获取、传输等过程中,往往会发生质量的损伤，造成&lt;strong&gt;图像质量的损坏的因素&lt;/strong&gt;有：
图像传输等过程中,由于信道带宽的限制所造成的图像模糊；图像中的噪声干扰
信号减弱，对比度下降；成象条件的欠缺，获取图像的清晰度偏低&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图像质量退化的原因&lt;/strong&gt;
对比度问题：对比度局部或全部偏低,影响图像视觉
噪声干扰问题：使图像蒙受干扰和破坏
清晰度下降问题,使图像模糊不清,甚至严重失真&lt;/p&gt;
&lt;p&gt;图像增强并&lt;strong&gt;不去估计图像实际退化的过程和实际退化的因素&lt;/strong&gt;而加以矫正，而&lt;strong&gt;只考虑图像退化的一般性质&lt;/strong&gt;，加以修正，以求得一般的或平均地图像质量的改进。例如，边缘锐化去模糊、平滑去噪声、直方图修正对比度增强等&lt;/p&gt;
&lt;h3 id=&#34;32-图像增强方法&#34;&gt;3.2 图像增强方法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518093527644.png&#34; alt=&#34;image-20210518093527644&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;33-灰度变换点运算&#34;&gt;3.3 灰度变换/点运算&lt;/h3&gt;
&lt;p&gt;空间域处理 $g(x,y)=T[f(x,y)]$&lt;/p&gt;
&lt;p&gt;当每次处理只基于一点 $s=T(r)$，$s,r$为该点像素值——点运算&lt;/p&gt;
&lt;p&gt;应用场景：曝光不足或过度，或由于成像设备的非线性和图像记录设备动态范围太窄等因素，会产生对比度不足的弊病，使图像中的细节分辨不清可以使用灰度变换方法解决这些问题&lt;/p&gt;
&lt;p&gt;灰度变换定义：将一个灰度区间映射到另一个灰度区间的变换称为灰度变换&lt;/p&gt;
&lt;p&gt;在图像增强方面的作用：使图像动态范围加大，图像对比度扩展，图像清晰，特征明显&lt;/p&gt;
&lt;p&gt;灰度级变换的应用：亮度调整——加亮、减暗图像；对比度拉伸——提高、降低对比度；灰度级切片，主要用于突出某个特定的灰度范围，从而增强某个专门的特征&lt;/p&gt;
&lt;h4 id=&#34;331线性灰度变换&#34;&gt;3.3.1线性灰度变换&lt;/h4&gt;
&lt;h5 id=&#34;加常数&#34;&gt;加常数&lt;/h5&gt;
&lt;p&gt;作用：压缩动态范围，降低对比度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518095726076.png&#34; alt=&#34;image-20210518095726076&#34;  /&gt;&lt;/p&gt;
&lt;h5 id=&#34;图像反转反色&#34;&gt;图像反转（反色）&lt;/h5&gt;
&lt;p&gt;灰度级范围为$[0,L-1]$的图像：$s=L-1-r$&lt;/p&gt;
&lt;h5 id=&#34;乘常数&#34;&gt;乘常数&lt;/h5&gt;
&lt;p&gt;动态范围压缩/扩展&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518100201061.png&#34; alt=&#34;image-20210518100201061&#34;  /&gt;&lt;/p&gt;
&lt;h5 id=&#34;一般形式&#34;&gt;一般形式&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518100246602.png&#34; alt=&#34;image-20210518100246602&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518100329461.png&#34; alt=&#34;image-20210518100329461&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;332-分段线性灰度变换&#34;&gt;3.3.2 分段线性灰度变换&lt;/h4&gt;
&lt;h5 id=&#34;对比度拉伸拓展&#34;&gt;对比度拉伸/拓展&lt;/h5&gt;
&lt;p&gt;将感兴趣的灰度范围线性拓展，相对抑制不感兴趣的灰度区域。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518100429289.png&#34; alt=&#34;image-20210518100429289&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;削波&#34;&gt;削波&lt;/h5&gt;
&lt;p&gt;削波(cliping)可以看做是对比度拓展的一个特例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518100904729.png&#34; alt=&#34;image-20210518100904729&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;阈值化&#34;&gt;阈值化&lt;/h5&gt;
&lt;p&gt;阈值化（thresholding）可以看作是削波的一个特例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518100925182.png&#34; alt=&#34;image-20210518100925182&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;得到二值黑白图像&lt;/p&gt;
&lt;h5 id=&#34;灰度级分层灰度窗口变换灰度切分&#34;&gt;灰度级分层/灰度窗口变换/灰度切分&lt;/h5&gt;
&lt;p&gt;将某一区间的灰度级和其它部分（背景）分开。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518122509164.png&#34; alt=&#34;image-20210518122509164&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;将兴趣区域显示为一个值，其他区域另一个值；或背景不变，兴趣区域灰度变亮/变暗。&lt;/p&gt;
&lt;h5 id=&#34;位图切割比特平面分层&#34;&gt;位图切割/比特平面分层&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518194648999.png&#34; alt=&#34;image-20210518194648999&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;高比特平面包含视觉上重要的大多数数据；低比特平面贡献更精细的灰度细节。&lt;/p&gt;
&lt;p&gt;分层方式：灰度信息由n个比特位存储的图像，根据每个二进制位的取值(0/1)得到n个层；其实就是将比特深度将图像矩阵“切开”&lt;/p&gt;
&lt;h4 id=&#34;333-非线性灰度变换&#34;&gt;3.3.3 非线性灰度变换&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518200656670.png&#34; alt=&#34;image-20210518200656670&#34;  /&gt;&lt;/p&gt;
&lt;h5 id=&#34;指数函数变换&#34;&gt;指数函数变换&lt;/h5&gt;
&lt;h5 id=&#34;对数函数变换&#34;&gt;对数函数变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518201054849.png&#34; alt=&#34;image-20210518201054849&#34; align=&#34;left&#34; style=&#34;zoom:20%;&#34; /&gt;通用形式：$s=clog(1+r)$&lt;/p&gt;
&lt;p&gt;图中对数变换：将输入中范围较窄的低灰度值映射为输出中较宽范围的灰度值；扩展暗像素，&lt;strong&gt;压缩高灰度值的动态范围&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;应用：标定傅立叶频谱（图像显示系统一般显示不出来动态范围大的图像）&lt;/p&gt;
&lt;h5 id=&#34;幂函数变换伽马变换&#34;&gt;幂函数变换/伽马变换&lt;/h5&gt;
&lt;p&gt;通用形式：$s=cr^{\gamma}$ 用于压缩和扩展灰度值范围&lt;/p&gt;
&lt;p&gt;&lt;em&gt;lookup&lt;/em&gt; &lt;em&gt;table&lt;/em&gt; (&lt;em&gt;LUT)&lt;/em&gt; 查找表 灰度级变换定义了输入像素值与输出像素之间的映射关系，通常通过查表实现。可用户自定义转换（一般功能包括直方图均衡化,伽马校正,对数修正,指数修正）&lt;/p&gt;
&lt;h3 id=&#34;34-基于直方图的图像增强&#34;&gt;3.4 基于直方图的图像增强&lt;/h3&gt;
&lt;h4 id=&#34;341-灰度直方图简称直方图&#34;&gt;3.4.1 灰度直方图（简称直方图）&lt;/h4&gt;
&lt;p&gt;定义：对一幅数字图像，若对应于每一灰度值，统计出具有该灰度值的象素数，并据此绘出象素数-灰度值图形。有时直方图亦采用某一灰度值的象素数占全图总象素数的百分比作为纵坐标。&lt;/p&gt;
&lt;p&gt;性质：1. 直方图只包含概率，丢失了位置信息。 2.图像与直方图是&lt;strong&gt;多对一&lt;/strong&gt;的映射关系。3. 一幅图像各子区的直方图之和就等于该图全图的直方图。&lt;/p&gt;
&lt;p&gt;直方图修正：通过灰度映射函数，$G_{new}=T(G_{old})$将原灰度直方图改造成所希望的直方图。&lt;/p&gt;
&lt;h4 id=&#34;342-直方图均衡化&#34;&gt;3.4.2 直方图均衡化&lt;/h4&gt;
&lt;p&gt;给定图像的分布$\Rightarrow$均匀直方图分布；均衡化后，图像直方图是平直的，即各灰度级具有相同的出现频次，或各灰度级具有均匀的概率分布。图像看起来就更清晰了（&lt;strong&gt;图像对比度增强&lt;/strong&gt;）。&lt;/p&gt;
&lt;h5 id=&#34;直方图均衡化灰度变换函数的条件&#34;&gt;直方图均衡化灰度变换函数的条件&lt;/h5&gt;
&lt;p&gt;$$
s=T(r),0\leq r \leq L-1
$$&lt;/p&gt;
&lt;p&gt;(a) $T(r)$在区间$0\leq r \leq L-1$严格递增$\Rightarrow$ 1️⃣保证输出灰度值不少于输入2️⃣保证反函数存在，即s到r的反映射一一对应，消除二义性&lt;/p&gt;
&lt;p&gt;(b)$0\leq r \leq L-1$时 $0\leq T(r) \leq L-1$
灰度变换不影响像素的位置分布，也不会增减像素数目：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518205025301.png&#34; align=&#39;middle&#39; alt=&#34;image-20210518205025301&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;直方图均衡化步骤&#34;&gt;直方图均衡化步骤&lt;/h5&gt;
&lt;p&gt;1.求出原图f的灰度直方图h&lt;/p&gt;
&lt;p&gt;2.求出图像f的总体像素个数，$N_f=n×m$&lt;/p&gt;
&lt;p&gt;3.计算每个灰度$r_k$的像素个数在整个图像中出现的概率 $p (r_k),k=0,1…L-1$&lt;/p&gt;
&lt;p&gt;4.理论灰度变换函数&lt;/p&gt;
&lt;p&gt;\\连续情况：$s=T(r)=(L-1)\int_0^r p(w)dw $&lt;/p&gt;
&lt;p&gt;离散：$s_k=T(r_k)=(L-1)\Sigma_{j=0}^kp(r_j),k=0,1,2,&amp;hellip;,L-1$&lt;/p&gt;
&lt;p&gt;5.将s近似到最接近的整数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.B.&lt;/strong&gt; $r_k$可能被归一化为$r_k/(L-1)$，此时s近似到最近的$r_k$，在实际计算中请注意。&lt;/p&gt;
&lt;h5 id=&#34;缺点&#34;&gt;缺点&lt;/h5&gt;
&lt;p&gt;1.不能用于交互方式的图像增强应用，因为直方图均衡化只能产生唯一一个结果，恒定值直方图近似&lt;/p&gt;
&lt;p&gt;2.并不总是能产生希望的结果。尤其当原始图像的直方图十分集中时，直方图均衡后将可能产生假边沿或区域，同时增强图像的条纹或斑点&lt;/p&gt;
&lt;h4 id=&#34;343-直方图匹配规定化&#34;&gt;3.4.3 直方图匹配/规定化&lt;/h4&gt;
&lt;p&gt;令$r_k$为原始图像的灰度密度函数，$ z_k$是期望通过匹配的图像灰度密度函数&lt;/p&gt;
&lt;p&gt;目标：找到一个灰度变换H $z=H(r)$&lt;/p&gt;
&lt;p&gt;使得经过H对原图像进行灰度变换后，结果图像z具有期望的直方图&lt;/p&gt;
&lt;h5 id=&#34;算法设计&#34;&gt;算法设计&lt;/h5&gt;
&lt;h6 id=&#34;连续灰度级情况&#34;&gt;连续灰度级情况&lt;/h6&gt;
&lt;p&gt;1.直方图均衡化&lt;img src=&#34;https://K7288.github.io/assets/image-20210518212718078.png&#34; alt=&#34;image-20210518212718078&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;2.$z=G^{-1}(u)$&lt;/p&gt;
&lt;p&gt;3.根据均衡化概念，s, u的直方图都是常量，由此可用s替代u进行上述逆变换：$z=G^{-1}(s)=G^{-1}(T(r))\Rightarrow H$&lt;/p&gt;
&lt;h6 id=&#34;离散灰度级情况&#34;&gt;离散灰度级情况&lt;/h6&gt;
&lt;p&gt;1.直方图均衡化；可计算得到两张映射表：r→s；u→z&lt;/p&gt;
&lt;p&gt;2.从s, u中选取最接近的一对$s_j,u_k$，使$u_k \approx s_j$&lt;/p&gt;
&lt;p&gt;3.在从两张表中查得对应的$r_j, z_k$&lt;/p&gt;
&lt;p&gt;4.由此建立从r到z的映射关系r→z，实现数字图像的直方图匹配&lt;/p&gt;
&lt;h4 id=&#34;344-基于直方图统计特性的增强局部增强&#34;&gt;3.4.4 基于直方图统计特性的增强/局部增强&lt;/h4&gt;
&lt;h6 id=&#34;直方图统计特性&#34;&gt;直方图统计特性&lt;/h6&gt;
&lt;p&gt;令$p(r) $为原始图象的灰度密度函数&lt;/p&gt;
&lt;p&gt;统计特性：均值m；n阶中心矩$\mu_n(r)=\Sigma_{i=0}^{L-1}(r_i-m)^np(r_i)$&lt;/p&gt;
&lt;p&gt;m平均灰度； 方差$\sigma^2$平均对比度&lt;/p&gt;
&lt;h6 id=&#34;局部增强&#34;&gt;局部增强&lt;/h6&gt;
&lt;p&gt;利用均值、方差的前述特性，通过对图像局部区域亮度、对比度的判断，实现有选择性地增强&lt;/p&gt;
&lt;p&gt;1️⃣在当前像素r(x,y)周围，确定一个邻域范围S(x,y) $\rightarrow$ 2️⃣统计该局部区域的统计特性 p m $\sigma^2$ $\rightarrow$ 3️⃣ 确定算法&lt;img src=&#34;https://K7288.github.io/assets/image-20210518214531130.png&#34; alt=&#34;image-20210518214531130&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;$M_G$：整幅图像的灰度平均值； $D_G$ ：整幅图像的灰度级方差 $k0, k1, k2$：局部增强加权因子，用以确定是否对当前像素f(x,y)进行增强&lt;/p&gt;
&lt;h3 id=&#34;35-彩色图像增强&#34;&gt;3.5 彩色图像增强&lt;/h3&gt;
&lt;h4 id=&#34;351-彩色模型颜色空间&#34;&gt;3.5.1 彩色模型（颜色空间）&lt;/h4&gt;
&lt;h5 id=&#34;rgb&#34;&gt;RGB&lt;/h5&gt;
&lt;p&gt;CCD技术直接感知R,G,B三个分量；是图像成像、显示、打印等设备的基础&lt;/p&gt;
&lt;h5 id=&#34;hsi-色调饱和度亮度&#34;&gt;HSI (色调、饱和度、亮度）&lt;/h5&gt;
&lt;p&gt;I分量与图像的彩色信息无关，H和S分量与人感受颜色的方式是紧密相连的&lt;/p&gt;
&lt;p&gt;将亮度(I)与色调（H）和饱和度（S）分开，避免颜色受到光照明暗(I)等条件的干扰，仅仅分析反映色彩本质的色调和饱和度&lt;/p&gt;
&lt;p&gt;广泛用于计算机视觉、图像检索和视频检索&lt;/p&gt;
&lt;h5 id=&#34;yuv&#34;&gt;YUV&lt;/h5&gt;
&lt;p&gt;Y指亮度(Brightness),即灰度值；U和V指色调&lt;/p&gt;
&lt;p&gt;Y分量可提供黑白电视机的所有影像信息；用于彩色电视广播，被欧洲的电视系统所采用（属于PAL系统）&lt;/p&gt;
&lt;h5 id=&#34;ycbcr&#34;&gt;YCbCr&lt;/h5&gt;
&lt;p&gt;Y指亮度,与YUV的Y相同；Cb和Cr由U和V调整得到；JPEG采用的彩色空间&lt;/p&gt;
&lt;h5 id=&#34;彩色空间转换&#34;&gt;彩色空间转换&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;RGB $\rightarrow$ HSI&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518215210711.png&#34; alt=&#34;image-20210518215210711&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HSI $\rightarrow$ RGB&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518215223907.png&#34; alt=&#34;image-20210518215223907&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RGB $\rightarrow$ YUV&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518215328057.png&#34; alt=&#34;image-20210518215328057&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RGB $\rightarrow$ YCbCr&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518215403470.png&#34; alt=&#34;image-20210518215403470&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;352-颜色平衡&#34;&gt;3.5.2 颜色平衡&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;灰度平衡&lt;/strong&gt;：使RGB彩色设备的彩色分量混合后，颜色失去色调和饱和度产生灰色，这种颜色混合效果被称为灰度平衡，一般情况下，等量的RGB产生灰色。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;彩色平衡&lt;/strong&gt;：纠正偏色的过程；通过调整灰平衡，使偏色区域恢复成灰色实现；当灰色的亮度达到一定程度时，显现为白色，因此有时亦称之为白平衡调整&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判断偏色&lt;/strong&gt;：1️⃣ 检查图像的灰平衡（白平衡）情况，即检查在现实中应该是灰色（白色）的物体，在图像中是否是灰色（白色）；2️⃣ 检查高饱和度的颜色是否正常，即检查在现实中应该是纯色的物体，在图像中是否有偏色&lt;/p&gt;
&lt;p&gt;&lt;em&gt;e.g.某黑色区域的平均取值是：R = 0 ，G = 12，B = 7说明有青色色偏&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;彩色平衡实现的算法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;选择两个颜色分量(如RB)，去匹配第三个(如G)&lt;/p&gt;
&lt;p&gt;1.在图像中选取两个浅灰或深灰区域（这些区域也许已经不是灰色）&lt;/p&gt;
&lt;p&gt;2.计算这两个域的&lt;strong&gt;RGB平均值&lt;/strong&gt;，设为$F_1=(R_1,G_1,B_1)\quad F_2=(R_2,G_2,B_2)$&lt;/p&gt;
&lt;p&gt;3.以G分量为基准，修改R和B分量使之等于G，可有对应关系：
$$
F_1=(R_1,G_1,B_1)\Rightarrow F_1^\star=(R_1^{\star},G_1,B_1^{\star})=(G_1,G_1,G_1)
$$
$F_2和F_2^\star$同理。&lt;/p&gt;
&lt;p&gt;4.构造线性变换&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522233819472.png&#34; alt=&#34;image-20210522233819472&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;5.分别对R、G、B图像实施变换&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522233842402.png&#34; alt=&#34;image-20210522233842402&#34; style=&#34;zoom:53%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;353-伪彩色增强&#34;&gt;3.5.3 伪彩色增强&lt;/h4&gt;
&lt;p&gt;人类可以分辨比灰度层次更多的颜色种类,伪彩色图像处理就是根据一定的准则对灰度值赋以彩色的处理。方法：伪彩色变换，密度分割&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;独立映射表变换法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对灰度图像f(x, y)，建立颜色映射表：$I_R=T_R(I),I_G=T_G(I),I_B=T_B(I)$&lt;/p&gt;
&lt;p&gt;形成RGB图像各分量：&lt;/p&gt;
&lt;p&gt;$R(x,y)=T_R(f(x,y)),G(x,y)=T_G(f(x,y)),B(x,y)=T_B(f(x,y))$&lt;/p&gt;
&lt;p&gt;经典变换函数（映射表）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;分段线性映射表&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522234541466.png&#34; alt=&#34;image-20210522234541466&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;彩虹映射表：其效果类似彩虹；按照灰度值增加对应于波长增加进行映射（低灰度→蓝色，中灰度→绿色，高灰度→红色&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;正弦函数变换表：移动函数值范围以适应实际图像像素值范围&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210522234650107.png&#34; alt=&#34;image-20210522234650107&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;36-空域滤波&#34;&gt;3.6 空域滤波&lt;/h3&gt;
&lt;h4 id=&#34;361-线性系统响应卷积理论&#34;&gt;3.6.1 线性系统响应：卷积理论&lt;/h4&gt;
&lt;p&gt;卷积的离散表达式，基本上可以理解为模板运算的数学表达方式
$g(x,y)=f*h=\sum \limits_{m=0}^{M-1} \sum \limits_{n=0}^{N-1} f(m,n)h(x-m,y-n)$&lt;/p&gt;
&lt;p&gt;卷积的冲击响应函数h(x,y)，称为空域卷积模板&lt;/p&gt;
&lt;h4 id=&#34;362-空域滤波及滤波器&#34;&gt;3.6.2 空域滤波及滤波器&lt;/h4&gt;
&lt;p&gt;使用空域模板进行的图像处理，被称为空域滤波。模板本身被称为空域滤波器&lt;/p&gt;
&lt;p&gt;输出图像中的每一点，为输入图像中某个相关区域象素集的映射&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523084057760.png&#34; alt=&#34;image-20210523084057760&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;分类&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523084137261.png&#34; alt=&#34;image-20210523084137261&#34;  /&gt;&lt;/p&gt;
&lt;h5 id=&#34;线性滤波器&#34;&gt;线性滤波器&lt;/h5&gt;
&lt;p&gt;定义：$R=\sum \limits_{i}^{n}w_iz_i$，其中$w_i$是模板的系数， $z_i$是被计算像素及其邻域像素的值。&lt;/p&gt;
&lt;p&gt;分类：低通滤波器（平滑图像，去除噪声）；高通滤波器（边缘增强，边缘提取）；带通滤波器（删除特定频率，增强中很少用）&lt;/p&gt;
&lt;h5 id=&#34;非线性滤波器&#34;&gt;非线性滤波器&lt;/h5&gt;
&lt;p&gt;中值滤波（平滑图像，去除噪声）$R=mid{z_k|k=1,2,&amp;hellip;,9}$&lt;/p&gt;
&lt;p&gt;最大值滤波（寻找最亮点）$R=max{z_k|k=1,2,&amp;hellip;,9}$&lt;/p&gt;
&lt;p&gt;最小值滤波（寻找最暗点）$R=min{z_k|k=1,2,&amp;hellip;,9}$&lt;/p&gt;
&lt;h4 id=&#34;363-平滑低通滤波器&#34;&gt;3.6.3 平滑/低通滤波器&lt;/h4&gt;
&lt;p&gt;1.应用：对大图像处理前，删去无用的细小细节；连接中断的线段和曲线；降低噪音；平滑处理，恢复过分锐化的图像；图像创艺（阴影、软边、朦胧效果）&lt;/p&gt;
&lt;p&gt;2.滤波器模板系数的设计
根据空域中低通冲激响应函数的图形设计模板的系数
设计模板系数的原则
（1）大于0
（2）很多情况：都选1，或中间选1，周围选0.5
（3）最后通过求均值，解决超出灰度范围问题
例如：均值滤波器；加权平均滤波器&lt;/p&gt;
&lt;p&gt;3.模板尺寸越大，图像越模糊，细节丢失越多&lt;/p&gt;
&lt;p&gt;4.低通空域滤波：（缺点）处理噪音的同时也平滑了边和尖锐的细节；（特征）某些情况下，对图像的低通滤波具有&lt;strong&gt;增强大尺度特征&lt;/strong&gt;的作用&lt;/p&gt;
&lt;h4 id=&#34;364-中值滤波器&#34;&gt;3.6.4 中值滤波器&lt;/h4&gt;
&lt;p&gt;优点：抑制噪声；在去除噪音的同时，可以比较好地保留边缘轮廓信息和图像的细节&lt;/p&gt;
&lt;h4 id=&#34;365-锐化高通滤波器&#34;&gt;3.6.5 锐化/高通滤波器&lt;/h4&gt;
&lt;p&gt;1.应用：加强图像中景物的边缘和轮廓；印刷中的细微层次强调。弥补扫描、 挂网对图像的平滑；超声 探测 成 象 ， 分辨率低 ， 边 缘 模糊 ， 通 过 锐 化 来 改善；图 像 识 别 中 ， 分 割 前 的 边缘 提取；锐 化 处 理 恢复 过 度 平 滑 、 暴 光 不 足 的 图 像；图 像 创 艺 (只 剩 下 边界 的 特殊 图 像 )；尖端 武器 的 目标 识别 、 定 位&lt;/p&gt;
&lt;h5 id=&#34;2滤波器模板系数的设计&#34;&gt;2.滤波器模板系数的设计&lt;/h5&gt;
&lt;p&gt;​	根据空域中高通冲激响应函数的图形设计模板的系数
​	1）中心系数为正值，外围为负值。2）系数之和为0&lt;/p&gt;
&lt;h5 id=&#34;3滤波器效果&#34;&gt;3.滤波器效果&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;常数或变化平缓的区域，结果为0或很小，图像很暗，亮度被降低了&lt;/li&gt;
&lt;li&gt;在暗的背景上边缘被增强了&lt;/li&gt;
&lt;li&gt;图像的整体对比度降低了&lt;/li&gt;
&lt;li&gt;计算时会出现负值，归0处理为常见&lt;/li&gt;
&lt;li&gt;高通滤波在增强了边的同时，丢失了图像的层次和亮度&lt;/li&gt;
&lt;li&gt;在某些情况下，高通滤波增强小尺度特征&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;4高增益滤波&#34;&gt;4.高增益滤波&lt;/h5&gt;
&lt;p&gt;(a)作用：高通滤波可看作为：高通= 原图–低通;高增益滤波弥补高通滤波的缺陷，在增强边和细节的同时，不丢失原图像的低频成分。&lt;/p&gt;
&lt;p&gt;(b)定义：&lt;/p&gt;
&lt;p&gt;在上式原图上乘一个扩大因子A，有高增益滤波：高增益= A*原图–低通&lt;/p&gt;
&lt;p&gt;高增益= A原图–低通
= (A – 1)原图+ （原图–低通）
= (A – 1)原图+ 高通
当A = 1时，高增益就是高通滤波，
当A &amp;gt;1 时，原图像的一部分被加到高通中&lt;/p&gt;
&lt;p&gt;(c)滤波器扩大因子及模板系数设计：&lt;/p&gt;
&lt;p&gt;对于3x3的模板，设w = 9A – 1；（高通时w = 8）A的值决定了滤波器的特性&lt;img src=&#34;https://K7288.github.io/assets/image-20210523104504950.png&#34; alt=&#34;image-20210523104504950&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;当A = 1.1时，意味着把0.1个原图像加到基本高通上。当A = 1.2时，结果处在上限的边缘&lt;/p&gt;
&lt;p&gt;理论上，高通和高增益的模板尺寸可为任意尺寸。例如：模板取7x7，高通权值为48，其它均为-1，规整化系数为1/49&lt;/p&gt;
&lt;p&gt;根据经验，高通滤波模板很少大于3x3&lt;/p&gt;
&lt;p&gt;(d)效果分析：&lt;/p&gt;
&lt;p&gt;增强了边，又保留了层次；高增益增强了边的同时也增强了噪音。&lt;/p&gt;
&lt;h5 id=&#34;5微分滤波器-数字函数的微分梯度拉普拉斯算子&#34;&gt;5.微分滤波器 数字函数的微分、梯度、拉普拉斯算子&lt;/h5&gt;
&lt;p&gt;均值平滑，均值类似积分$\Rightarrow$ 微分锐化？ ☑️&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数字函数的微分、梯度、拉普拉斯算子&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一阶微分&lt;/strong&gt; $\frac{\partial f}{\partial x}=f(x+1)-f(x)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二阶微分&lt;/strong&gt; $\frac{\partial^2 f}{\partial x^2}=f(x+1)+f(x-1)-2f(x)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;梯度&lt;/strong&gt;   $\nabla f\equiv grad(f)=[g_x,g_y]^T=[ \frac {\partial f}{\partial x} \frac {\partial f}{\partial y}]^T$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;拉普拉斯算子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$\nabla^2 F(x,y)= \frac {\partial^2 F}{\partial x^2} +\frac{\partial^2 F}{\partial y^2} $ （连续函数）&lt;/p&gt;
&lt;p&gt;$G(x,y)=4F(x,y)-F(x+1,y)-F(x-1,y)-F(x,y+1)-F(x,y-1)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幅度&lt;/strong&gt;   $M(x,y)=mag(\nabla f)=\sqrt{g_x^2+g_y^2}$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523133356552.png&#34; alt=&#34;image-20210523133356552&#34; align=&#34;right&#34; style=&#34;zoom:45%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$M(x,y)\approx |g_x|+|g_y|$&lt;/li&gt;
&lt;li&gt;点$z_5$ $g_x \approx z_5-z_6,g_y \approx z_5-z_8$&lt;/li&gt;
&lt;li&gt;交叉差：点$z_5$ $g_x \approx z_5-z_9,g_y \approx z_6-z_8 $&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523133634050.png&#34; alt=&#34;image-20210523133634050&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Roberts交叉梯度算子 $mag(\nabla f)\approx |z_5-z_9|+| z_6-z_8|$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;梯度计算由两个模板组成，第一个求得梯度的第一项，第二个求得梯度的第二项，然后求和，得到梯度的幅度。&lt;/li&gt;
&lt;li&gt;两个模板称为Roberts 交叉梯度算子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prewitt梯度算子——3x3的梯度模板&lt;/p&gt;
&lt;p&gt;$mag(\nabla f)\approx |(z_7+z_8+z_9)-(z_1+z_2+z_3)|+| (z_3+z_6+z_9)-(z_1+z_4+z_7)|$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sobel梯度算子——3x3的梯度模板&lt;/p&gt;
&lt;p&gt;$mag(\nabla f)\approx |(z_7+2z_8+z_9)-(z_1+2z_2+z_3)|+| (z_3+2z_6+z_9)-(z_1+2z_4+z_7)|$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;拉普拉斯算子—二阶微分算法&lt;/p&gt;
&lt;p&gt;标准拉普拉斯算子：&lt;img src=&#34;https://K7288.github.io/assets/image-20210523134853235.png&#34; alt=&#34;image-20210523134853235&#34; style=&#34;zoom:55%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;先平滑后增强：&lt;img src=&#34;https://K7288.github.io/assets/image-20210523134927809.png&#34; alt=&#34;image-20210523134927809&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;与高增益滤波技术相结合（A&amp;gt;1）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523135022986.png&#34; alt=&#34;image-20210523135022986&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;微分滤波器的两种特殊应用：&lt;/p&gt;
&lt;p&gt;1）梯度&amp;gt;25的赋最大值255，否则赋原值。边被突出，背景保留&lt;/p&gt;
&lt;p&gt;2）梯度&amp;gt;25的赋最大值255，否则赋0。边被突出，图被二值化&lt;/p&gt;
&lt;h3 id=&#34;37-频域增强&#34;&gt;3.7 频域增强&lt;/h3&gt;
&lt;h4 id=&#34;371-频域增强原理&#34;&gt;3.7.1 频域增强原理&lt;/h4&gt;
&lt;h5 id=&#34;频域增强步骤&#34;&gt;频域增强步骤&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523165359386.png&#34; alt=&#34;image-20210523165359386&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;F(u,v)—待增强图像f(x,y)的傅立叶变换；定义了待增强图像f(x,y)分解为一系列基图像后的变换系数&lt;/p&gt;
&lt;p&gt;H(u,v)—对应于空域线性系统单位冲击响应函数的傅立叶变换，称之为传递函数或滤波器函数&lt;/p&gt;
&lt;p&gt;通过H(u,v)对f(x,y)分解为基图像后加权系数的修改，从而实现图像的增强——图像的频域滤波增强&lt;/p&gt;
&lt;p&gt;理论上，任何变换只要具有正交性与完备性，均可定义类似的运算方式，但只有傅立叶变换具有严格的卷积定理证明&lt;/p&gt;
&lt;h5 id=&#34;相对空域滤波的优势&#34;&gt;相对空域滤波的优势&lt;/h5&gt;
&lt;p&gt;在傅立叶变换域，变换系数反映了图像在空域难以定义的某些特征&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;频谱的直流低频分量对应于图像的平滑区域&lt;/li&gt;
&lt;li&gt;频谱的高频分量对应于图像的边沿或变化剧烈区域&lt;/li&gt;
&lt;li&gt;外界叠加噪声对应于频谱中频率较高的部分&lt;/li&gt;
&lt;li&gt;恒定的干扰条纹对应于频谱中的某些特征点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;构造一个滤波器，刻意地提升某些频率分量、压低或去除另一些分量，从而达到图像增强的目的&lt;/p&gt;
&lt;p&gt;空域滤波基本上借助于模板运算实现，难于实现真正意义上的线性系统滤波；在实际应用中空域模板的尺寸难以扩大，使滤波增强所需信息局限在较小的局部区域，难以获得更为理想的结果和处理较为复杂的杂波去除、多特征增强等&lt;/p&gt;
&lt;h4 id=&#34;372-同态滤波器&#34;&gt;3.7.2 同态滤波器&lt;/h4&gt;
&lt;h5 id=&#34;原理&#34;&gt;原理&lt;/h5&gt;
&lt;p&gt;成像过程：图像的灰度函数f (x, y)看作为入射光分量和反射光分量两部分组成$f(x,y)=i(x,y)r(x,y)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$i(x,y)$ 入射光（明度分量），较均匀，随空间位置变化较小$\rightarrow$占据&lt;strong&gt;低频段&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$r(x,y)$ 反射光（反射分量），由于物体性质和结构特点不同而反射强弱很不相同的光，随空间位置变化较剧烈；物体亮度特征主要取决于反射光$\rightarrow$占据&lt;strong&gt;高频段比较宽的范围&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;成像中的问题：当入射光不均匀时，反射光构成的图像将难以表现物体的全貌&lt;/p&gt;
&lt;p&gt;解决思路：将入射光和反射光分别处理，在增强物体对比度的同时，适当压缩入射光形成的灰度值范围&lt;/p&gt;
&lt;h5 id=&#34;算法&#34;&gt;算法&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;图像 $f(x,y)=i(x,y)r(x,y)$&lt;/li&gt;
&lt;li&gt;取对数 $z(x,y)=\ln f(x,y)=\ln i(x,y)+\ln r(x,y)$&lt;/li&gt;
&lt;li&gt;傅立叶  $Z(u,v)=F[z(x,y)]=F[\ln i(x,y)]+F[\ln r(x,y)]=I(u,v)+R(u,v)$&lt;/li&gt;
&lt;li&gt;滤波处理  $S(u,v) = H(u,v)Z(u,v)$&lt;/li&gt;
&lt;li&gt;傅立叶反变换得到$s(x,y)$&lt;/li&gt;
&lt;li&gt;滤波结果$g(x,y)=e^{s(x,y)}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关键点：将明度和反射分量用对数进行分离；同态滤波器函数H(u,v)能够分别对这两部分进行操作，必须能够压缩i (x,y)的动态范围，同时增强r(x,y) 的对比度&lt;/p&gt;
&lt;p&gt;同态滤波器函数H(u,v)&lt;/p&gt;
&lt;p&gt;此特性的滤波器可满足前述要求&lt;img src=&#34;https://K7288.github.io/assets/image-20210523191245420.png&#34; alt=&#34;image-20210523191245420&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上述滤波器特性曲线可以通过基本滤波器改造得出，例如&lt;img src=&#34;https://K7288.github.io/assets/image-20210523191304460.png&#34; alt=&#34;image-20210523191304460&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;373低通滤波&#34;&gt;3.7.3低通滤波&lt;/h4&gt;
&lt;p&gt;以牺牲图像清晰度为代价来减少干扰效果的修饰过程&lt;/p&gt;
&lt;h5 id=&#34;理想圆形低通滤波ilpf&#34;&gt;理想圆形低通滤波ILPF&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523180946346.png&#34; alt=&#34;image-20210523180946346&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;理论上，半径内的频率分量无损通过，而圆外的频率成分被滤除&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;截止频率的设计&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;总的信号能量$P_T=\sum \limits_{u=0}^{N-1}\sum \limits_{v=0}^{N-1} P(u,v)$&lt;/p&gt;
&lt;p&gt;能量模$P(u,v)=|F(u,v)|^2=R(u,v)^2+I(u,v)^2$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将变换作中心平移，则一个以频域中心为原点，r为半径的圆就包含了百分之β的能量$\beta=100[\sum \limits_{u}\sum \limits_{v}P(u,v)/P_T]$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$r=D_0$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;作用&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;D0半径内的频率分量无损通过&lt;/li&gt;
&lt;li&gt;园外的频率分量会被滤除&lt;/li&gt;
&lt;li&gt;若滤除的高频分量中含有大量的边缘信息，会发生图像边缘模糊现象&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;整个能量的90%被一个半径为8的小圆周包含,大部分尖锐的细节信息都存在于被去掉的10%的能量中&lt;/li&gt;
&lt;li&gt;小的边界和其它尖锐细节信息被包含在频谱的至多0.5%的能量中&lt;/li&gt;
&lt;li&gt;被平滑的图像被一种非常严重的振铃效果——理想低通滤波器的一种特性所影响&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;butterworth低通滤波器-blpf&#34;&gt;Butterworth低通滤波器 BLPF&lt;/h5&gt;
&lt;p&gt;一个截止频率在与原点距离为D0的n阶Butterworth低通滤波器（BLPF）的变换函数：&lt;img src=&#34;https://K7288.github.io/assets/image-20210523182010659.png&#34; alt=&#34;image-20210523182010659&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;三维透视图、幅频谱图与截面图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523182045799.png&#34; alt=&#34;image-20210523182045799&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;空域响应&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523182120790.png&#34; alt=&#34;image-20210523182120790&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;截止频率设计&lt;/strong&gt;
变换函数中不存在一个不连续点作为一个通过的和被滤波掉的截止频率的明显划分
通常把使得H(u,v)开始小于其最大值的一定比例的点当作其截止频率点$D_0$，通常H(u,v)=0.5或H(u,v)=$\frac{1}{\sqrt{2}}$ &lt;img src=&#34;https://K7288.github.io/assets/image-20210523184009074.png&#34; alt=&#34;image-20210523184009074&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特性分析&lt;/strong&gt; 没有明显的振铃效果 ，这是滤波器在低频和高频之间平滑过渡的结果&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;和ILPF相比&lt;/strong&gt; 无明显跳跃；模糊程度减少；尾部有较多高频，对噪声的平滑效果不如ILPF&lt;/p&gt;
&lt;h5 id=&#34;指数低通滤波器elpf&#34;&gt;指数低通滤波器(ELPF)&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523185302584.png&#34; alt=&#34;image-20210523185302584&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特性分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有更加平滑的过渡带，平滑后的图象没有跳跃现象&lt;/p&gt;
&lt;p&gt;与BLPF相比，衰减更快，经过ELPF滤波的图象比BLPF处理的图象更模糊一些&lt;/p&gt;
&lt;p&gt;一般的，2阶指数低通滤波具有较好的特性&lt;/p&gt;
&lt;h5 id=&#34;高斯低通滤波器glpf&#34;&gt;高斯低通滤波器(GLPF)&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523185402501.png&#34; alt=&#34;image-20210523185402501&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523185414461.png&#34; alt=&#34;image-20210523185414461&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;梯形低通滤波器tlpf&#34;&gt;梯形低通滤波器(TLPF)&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523185509554.png&#34; alt=&#34;image-20210523185509554&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;其中D0 &amp;lt; D1，一般情况下，定义D0为截止频率&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特性分析&lt;/strong&gt; 结果图像的清晰度优于ILBF，噪声滤波好于BLBF9振铃效应好于ILBF，差于BLBF&lt;/p&gt;
&lt;h4 id=&#34;374高通滤波&#34;&gt;3.7.4高通滤波&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;基本形式&lt;/strong&gt; $H_{hp}(u,v)=1-H_{lp}(u,v)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三类基本高通滤波器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523185703181.png&#34; alt=&#34;image-20210523185703181&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;375从频域规范产生空域模板&#34;&gt;3.7.5从频域规范产生空域模板&lt;/h4&gt;
&lt;p&gt;用空域模板来模拟一个给定频域滤波器&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;频域的滤波器操作基于等式$G(u,v)=H(u,v)F(u,v)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;频域的滤波器操作可以由空域上的卷积公式实现 $g(x,y)=\sum \limits_{i=0}^{N-1}\sum \limits_{j=0}^{N-1}h(x-i,y-k)f(i,k)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;h通常称作空域卷积模板，可理解为H(u,v)的逆傅立叶变换。假定已找到了H与h的关系 $h(x,y)=H^{-1}(u,v)\quad x,y=0,1,2,&amp;hellip;,N-1$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523192133200.png&#34; alt=&#34;image-20210523192133200&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;但直接通过傅立叶反变换得到的h(x,y)其理论范围N太大，不是实用模板&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523192356020.png&#34; alt=&#34;image-20210523192356020&#34; align=&#34;right&#34; style=&#34;zoom:50%;&#34; /&gt;假设h(x, y)在x&amp;gt;n 且y&amp;gt;n 时值均为0，其中n&amp;lt;N；可创建一个n×n大小的用傅立叶变换H(u,v)得到的卷积模板&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对$\hat{h}$进行傅立叶变换 &lt;img src=&#34;https://K7288.github.io/assets/image-20210523192718836.png&#34; alt=&#34;image-20210523192718836&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;$\hat{H}=C\hat{h}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;确定$\hat{h}(x,y)$的系数，目标函数：误差$e^2=\sum \limits_{u=0}^{N-1}\sum \limits_{v=0}^{N-1}|\hat H(u,v)-H(u,v)|^2$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对$e^2$函数通过取空域的导数求极小值，最终可推导出公式$\hat{h}=(C^*C)^{-1}C^*H=C^{\star}H$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523193444846.png&#34; alt=&#34;image-20210523193444846&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;频域滤波器与空域滤波器的对应关系&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523193504340.png&#34; alt=&#34;image-20210523193504340&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;第四章-图像变换&#34;&gt;第四章 图像变换&lt;/h2&gt;
&lt;h3 id=&#34;41-空域变换&#34;&gt;4.1 空域变换&lt;/h3&gt;
&lt;h4 id=&#34;411-图像像素级运算&#34;&gt;4.1.1 图像像素级运算&lt;/h4&gt;
&lt;h5 id=&#34;点运算&#34;&gt;点运算&lt;/h5&gt;
&lt;h6 id=&#34;线性点运算&#34;&gt;线性点运算&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523194010921.png&#34; alt=&#34;image-20210523194010921&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;非线性点运算&#34;&gt;非线性点运算&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523194124247.png&#34; alt=&#34;image-20210523194124247&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;C&amp;gt;0,增强中间部分亮度；C&amp;lt;0,减小中间部分亮度&lt;/p&gt;
&lt;h5 id=&#34;代数运算-针对两幅图像&#34;&gt;代数运算 （针对两幅图像）&lt;/h5&gt;
&lt;p&gt;加法 $C(x,y)=A(x,y)+B(x,y)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;去除“叠加性”噪音&lt;/p&gt;
&lt;p&gt;定理：对M幅加性噪声图像进行平均，可以使图像的平方信噪比提高M倍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523194436669.png&#34; alt=&#34;image-20210523194436669&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图像叠加效果&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523194510175.png&#34; alt=&#34;image-20210523194510175&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;减法 $C(x,y)=A(x,y)-B(x,y)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用：去除不需要的叠加性图案（A前景背景混合图像；B背景）；检测同一场景两幅图像之间的变化；计算物体边界的梯度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;乘法 $C(x,y)=A(x,y)\times B(x,y)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用：二值模板图像乘原图像&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;逻辑运算&#34;&gt;逻辑运算&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523195358767.png&#34; alt=&#34;image-20210523195358767&#34; align=&#34;right&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;求反&#34;&gt;求反&lt;/h6&gt;
&lt;p&gt;定义：$h(x,y)=DN-f(x,y)$ $DN$为$f(x,y)$的灰度级&lt;/p&gt;
&lt;p&gt;主要应用：获得图像的负像；获得子图像的补图像；绘制区别于背景的、可恢复的图像&lt;/p&gt;
&lt;h6 id=&#34;与&#34;&gt;与&lt;/h6&gt;
&lt;p&gt;定义：$h(x,y)=f(x,y)\wedge  g(x,y)$&lt;/p&gt;
&lt;p&gt;主要应用：求两子图像的相交子图&lt;/p&gt;
&lt;h4 id=&#34;412-几何变换&#34;&gt;4.1.2 几何变换&lt;/h4&gt;
&lt;p&gt;几何失真一般分为&lt;strong&gt;系统失真&lt;/strong&gt;和&lt;strong&gt;非系统失真&lt;/strong&gt;。系统失真是有规律的、能预测的；非系统失真则是随机的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;几何变换可以改变图像中物体之间的空间关系&lt;/strong&gt;。&lt;/p&gt;
&lt;h5 id=&#34;基本方式多项式变换透视变换&#34;&gt;基本方式：多项式变换、透视变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523200017332.png&#34; alt=&#34;image-20210523200017332&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523200111014.png&#34; alt=&#34;image-20210523200111014&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523200146792.png&#34; alt=&#34;image-20210523200146792&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523200250629.png&#34; alt=&#34;image-20210523200250629&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;平移变换&#34;&gt;平移变换&lt;/h5&gt;
&lt;p&gt;$a(x,y)=x+x_0;b(x,y)=y+y_0;$&lt;/p&gt;
&lt;p&gt;$g(x^′,y^′)=f(x+x_0,y+y_0)$&lt;/p&gt;
&lt;h5 id=&#34;镜像变换水平镜像垂直镜像&#34;&gt;镜像变换：水平镜像、垂直镜像&lt;/h5&gt;
&lt;p&gt;水平：$x^′=-x,y^′=y$&lt;/p&gt;
&lt;p&gt;垂直：$x^′=x,y^′=-y$&lt;/p&gt;
&lt;h5 id=&#34;拉伸缩放变换&#34;&gt;拉伸/缩放变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523200602813.png&#34; alt=&#34;image-20210523200602813&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;旋转变换&#34;&gt;旋转变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523200617584.png&#34; alt=&#34;image-20210523200617584&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【注意】&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;图像旋转之前，为了避免信息的丢失，一定有平移坐标。&lt;/li&gt;
&lt;li&gt;图像旋转之后，会出现许多的空洞点，对这些空洞点必须进行填充处理，否则画面效果不好，称这种处理为&lt;strong&gt;差值处理&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;错切变换&#34;&gt;错切变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523201522896.png&#34; alt=&#34;image-20210523201522896&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;错切后原图像像素排列方向改变；与旋转的不同：x方向与y方向独立变化&lt;/p&gt;
&lt;h5 id=&#34;伪仿射变换双线性几何变换&#34;&gt;伪仿射变换——双线性几何变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523201720605.png&#34; alt=&#34;image-20210523201720605&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;任意变形变换非线性几何变换&#34;&gt;任意变形变换——非线性几何变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523201815443.png&#34; align=&#34;right&#34; alt=&#34;image-20210523201815443&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在二维平面上，实现图像几何形状的任意变换&lt;/p&gt;
&lt;p&gt;在二维平面上，校正图像的几何失真图像的空域变换—几何变换&lt;/p&gt;
&lt;p&gt;特征：一般的，原始图像与目标图像之间，存在一一对应的特征点（tiepoints，GCPs）&lt;/p&gt;
&lt;p&gt;模型：一般的，原始图像与目标图像之间的坐标变换函数为非线性函数，需用&lt;strong&gt;高阶多项式&lt;/strong&gt;进行近似描述&lt;/p&gt;
&lt;p&gt;通过原始图像与目标图像之间多个对应特征点（GCP点），可以确定上述多项式中的未知参数&lt;/p&gt;
&lt;h5 id=&#34;基本几何变换的特征&#34;&gt;基本几何变换的特征&lt;/h5&gt;
&lt;p&gt;坐标空间变换：范围发生变化，大小发生变化&lt;/p&gt;
&lt;p&gt;像素值的变化：位置变化不引起像素值变化，旋转、缩放、变形变换像素值发生变化&lt;/p&gt;
&lt;h5 id=&#34;离散几何变换的计算问题&#34;&gt;离散几何变换的计算问题&lt;/h5&gt;
&lt;p&gt;空间坐标：向前映射法，向后映射法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;向前映射计算法$g(x^′,y^′)=f(a(x,y),b(x,y))$ 从原图像坐标计算出目标图像坐标，镜像、平移变换使用这种计算方法&lt;/li&gt;
&lt;li&gt;向后映射计算法$g(a^′ (x,y),b^′ (x,y))=f(x,y)$ 从结果图像的坐标计算原图像的坐标,旋转、缩放、变形可以使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;像素值计算——灰度插值(重采样)：最邻近插值法，双线性内插法(一阶插值)，高阶插值&lt;/p&gt;
&lt;h4 id=&#34;412-灰度插值&#34;&gt;4.1.2 灰度插值&lt;/h4&gt;
&lt;h5 id=&#34;最近邻插值法&#34;&gt;最近邻插值法&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523202705414.png&#34; alt=&#34;image-20210523202705414&#34; align=&#34;right&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;选择最临近点像素灰度值 $(x^′,y^′ )$点像素的灰度值为原图像中(x,y)点的像素值&lt;/p&gt;
&lt;p&gt;特点：简单快速、灰度保真性好、误差较大、视觉特性较差、马赛克效应&lt;/p&gt;
&lt;h5 id=&#34;双线性插值法&#34;&gt;双线性插值法&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/img2020.cnblogs.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg&#34; alt=&#34;image-20210523205852927&#34; align=&#34;right&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线性插值&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;线性函数 $\frac{y-y_0}{x-x_0}=\frac{y_1-y_0}{x_1-x_0} \Rightarrow y=\frac{x_1-x}{x_1-x_0}y_0+\frac{x-x_0}{x_1-x_0}y_1$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523211117571.png&#34; alt=&#34;image-20210523205852927&#34; align=&#34;right&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;双线性插值&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;x方向插值&lt;/p&gt;
&lt;p&gt;$R_1:f(R_1)=\frac{x_1-x^′}{x_1-x_0}f(R(x,y))+\frac{x^′-x_0}{x_1-x_0}f(R(x+1,y))$&lt;/p&gt;
&lt;p&gt;$R_2:f(R_2)=\frac{x_1-x}{x_1-x_0}f(R(x,y+1))+\frac{x-x_0}{x_1-x_0}f(R(x+1,y+1))$&lt;/p&gt;
&lt;p&gt;y方向插值&lt;/p&gt;
&lt;p&gt;$f(R(x^′,y^′))=\frac{y_1-y^′}{y_1-y_0}f(R_1)+\frac{y^′-y_0}{y_1-y_0}f(R_2)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简化计算方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523211529983.png&#34; alt=&#34;image-20210523211529983&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;双线性插值法一阶插值&#34;&gt;双线性插值法（一阶插值）&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523211716595.png&#34; alt=&#34;image-20210523211716595&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;最佳插值函数&#34;&gt;最佳插值函数&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523204345275.png&#34; alt=&#34;image-20210523204345275&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;高阶插值&#34;&gt;高阶插值&lt;/h5&gt;
&lt;p&gt;简化计算，仅取原点周围有限范围点&lt;/p&gt;
&lt;p&gt;并利用三次多项式来近似理论上的最佳插值函数sinc(x)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523211806878.png&#34; alt=&#34;image-20210523211806878&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523204427344.png&#34; alt=&#34;image-20210523204427344&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;由此形成常用的三次卷积插值算法，又称三次内插法，两次立方法(Cubic)。CC插值法等&lt;/p&gt;
&lt;h5 id=&#34;三次卷积插值算法&#34;&gt;三次卷积插值算法&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523211958570.png&#34; alt=&#34;image-20210523211958570&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523212016592.png&#34; alt=&#34;image-20210523212016592&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;其中$I_i$是$i$点亮度值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为满足二维Nyquist条件下，最佳重构公式的近似&lt;/p&gt;
&lt;p&gt;只有图像满足特定的条件，三次卷积插值算法才可获得最佳结果&lt;/p&gt;
&lt;p&gt;可使待求点的灰度值更好地模拟实际可能值&lt;/p&gt;
&lt;p&gt;可取得更好的视觉效果&lt;/p&gt;
&lt;p&gt;三次卷积内插突出的优点是高频信息损失少，可将噪声平滑&lt;/p&gt;
&lt;p&gt;4×4时，像元均值和标准差信息损失小&lt;/p&gt;
&lt;p&gt;计算量大为增加&lt;/p&gt;
&lt;h5 id=&#34;内插方法选择&#34;&gt;内插方法选择&lt;/h5&gt;
&lt;p&gt;内插方法的选择除了考虑图像的现实要求及计算量，还要考虑内插结果对分析的影响&lt;/p&gt;
&lt;p&gt;当纹理信息为主要信息时，最邻近采样将严重改变原图像的纹理信息&lt;/p&gt;
&lt;p&gt;但灰度信息为主要信息时，双线性内插及三次卷积插值将减少图像异质性，增加图像同质性，其中，双线性内插方法使这种变化更明显&lt;/p&gt;
&lt;h3 id=&#34;42-频域变换&#34;&gt;4.2 频域变换&lt;/h3&gt;
&lt;p&gt;意义：（1）利用频率成分和图像外表之间的对应关系，一些在空间 域表述困难的增强任务，在频率域中变得非常普通 （2）图像的变换过程可类比于数学上去相关处理，在空域相 互交叉难以描述的特征，在频域往往得到更为直观的表 达、分离甚至集中（3）图像的滤波在频率域更为直观，它可以解释空间域滤波 难以解释的某些性质（4）理论上可以在频率域指定滤波器，通过反变换，以其空 域响应作为构建空间域滤波器的指导（5）一旦通过频率域试验选择了空间滤波，具体实施可在空间域进行&lt;/p&gt;
&lt;h4 id=&#34;421-频域变换概述&#34;&gt;4.2.1 频域变换概述&lt;/h4&gt;
&lt;h5 id=&#34;卷积&#34;&gt;卷积&lt;/h5&gt;
&lt;p&gt;对于一个线性系统的输入f(t)和输出y(t)，其间必定存在关系（卷积积分）：&lt;img src=&#34;https://K7288.github.io/assets/image-20210523213644037.png&#34; alt=&#34;image-20210523213644037&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;h(t) 称为线性系统的单位冲激响应函数，其含 义为：当线性系统输入f(t)为单位脉冲函数时， 线性系统的输出响应&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523213821381.png&#34; alt=&#34;image-20210523213821381&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;相关函数&#34;&gt;相关函数&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523214029949.png&#34; alt=&#34;image-20210523214029949&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;正交变换&#34;&gt;正交变换&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;连续函数几何的正交性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523214408780.png&#34; alt=&#34;image-20210523214408780&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正交函数集合的完备性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523214450778.png&#34; alt=&#34;image-20210523214450778&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正交函数集合完备性的物理意义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;任何数量的奇函数累加仍为奇函数，任何数量的偶函数累加仍为偶函数&lt;/p&gt;
&lt;p&gt;因此，为了能用累加展开式来表示一个任意函数，就要求这个函数集合中既有奇函数又有偶函数（e.g. a 完备 b 不完备）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523214515428.png&#34; alt=&#34;image-20210523214515428&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正交函数的离散情况&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523214713500.png&#34; alt=&#34;image-20210523214713500&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一维正交变换&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523214808642.png&#34; alt=&#34;image-20210523214808642&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;可进行图像变换的基本条件正交完备&#34;&gt;可进行图像变换的基本条件：正交、完备&lt;/h5&gt;
&lt;p&gt;常用的几种变换 : 傅立叶变换 、WALSH 变 换 、哈达玛变换 、Haar 变 换 、SLANT 变 换 、K-L 变换以 及 特定 条 件下的CONSINE 变换 、SINE变换等，都满足正交 性和完备性两个条件&lt;/p&gt;
&lt;h4 id=&#34;422-傅立叶变换&#34;&gt;4.2.2 傅立叶变换&lt;/h4&gt;
&lt;h5 id=&#34;调谐信号欧拉公式&#34;&gt;调谐信号(欧拉公式)&lt;/h5&gt;
&lt;p&gt;$$
f(t)=e^{j\omega t}=\cos⁡(\omega t)+j\sin(\omega t), j^2=−1
$$&lt;/p&gt;
&lt;h5 id=&#34;傅立叶积分&#34;&gt;傅立叶积分&lt;/h5&gt;
&lt;p&gt;$$
H(f)=\int\limits_{-\infty}^{+\infty}h(t)e^{−j2\pi ft} dt
$$&lt;/p&gt;
&lt;h5 id=&#34;一维傅立叶变换&#34;&gt;一维傅立叶变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523215713099.png&#34; alt=&#34;image-20210523215713099&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指数形式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523215811547.png&#34; alt=&#34;image-20210523215811547&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;一维离散傅立叶变换&#34;&gt;一维离散傅立叶变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523215911509.png&#34; alt=&#34;image-20210523215911509&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;二维傅立叶变换&#34;&gt;二维傅立叶变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523215956346.png&#34; alt=&#34;image-20210523215956346&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;二维离散傅立叶变换&#34;&gt;二维离散傅立叶变换&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523220027536.png&#34; alt=&#34;image-20210523220027536&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;傅立叶变换的性质&#34;&gt;傅立叶变换的性质&lt;/h5&gt;
&lt;h6 id=&#34;1-线性性质加法定理&#34;&gt;1. 线性性质（加法定理）&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523220156722.png&#34; alt=&#34;image-20210523220156722&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;2-比例性质相似性定理&#34;&gt;2. 比例性质（相似性定理）：&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523220222621.png&#34; alt=&#34;image-20210523220222621&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;3-可分离性&#34;&gt;3. 可分离性：&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523233331057.png&#34; alt=&#34;image-20210523233331057&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;一个&lt;strong&gt;二维傅立叶变换可分解为两步进行，其中每一步都是一个一维傅立叶变换&lt;/strong&gt;。 先对f(x,y)按行进行傅立叶变换得到F(x,v)，再对F(x,v)按列进行傅立叶变换，便可得到f(x,y)的傅立叶变换结果F(u,v) 。显然先列再行也可行。&lt;/p&gt;
&lt;h6 id=&#34;4-空间位移性&#34;&gt;4. 空间位移性&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523233707152.png&#34; alt=&#34;image-20210523233707152&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上式N代表图像为NxN&lt;/p&gt;
&lt;p&gt;若为MxN，则：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210529215413681.png&#34; alt=&#34;image-20210529215413681&#34;  /&gt;&lt;/p&gt;
&lt;h6 id=&#34;5-频移性&#34;&gt;5. 频移性&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523233741297.png&#34; alt=&#34;image-20210523233741297&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;6-周期性&#34;&gt;6. 周期性&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523233855182.png&#34; alt=&#34;image-20210523233855182&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;7-共轭对称性&#34;&gt;7. 共轭对称性&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210523233924573.png&#34; alt=&#34;image-20210523233924573&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;423-快速傅立叶变换-见复印件&#34;&gt;4.2.3 快速傅立叶变换 见复印件&lt;/h4&gt;
&lt;h4 id=&#34;424-离散余弦变换&#34;&gt;4.2.4 离散余弦变换&lt;/h4&gt;
&lt;h4 id=&#34;425-沃尔什哈达玛变换&#34;&gt;4.2.5 沃尔什—哈达玛变换&lt;/h4&gt;
&lt;h4 id=&#34;426-小波变换&#34;&gt;4.2.6 小波变换&lt;/h4&gt;
&lt;h2 id=&#34;第五章-图像压缩-见复印件&#34;&gt;第五章 图像压缩 见复印件&lt;/h2&gt;
&lt;h3 id=&#34;51-图像压缩概述&#34;&gt;5.1 图像压缩概述&lt;/h3&gt;
&lt;h3 id=&#34;52-无损压缩&#34;&gt;5.2 无损压缩&lt;/h3&gt;
&lt;h4 id=&#34;熵编码-霍夫曼编码-huffman&#34;&gt;熵编码 霍夫曼编码 (Huffman&lt;/h4&gt;
&lt;h4 id=&#34;熵编码-算术编码哈夫曼编码的改进&#34;&gt;熵编码 算术编码：哈夫曼编码的改进&lt;/h4&gt;
&lt;h4 id=&#34;基于字典的编码-dictionary&#34;&gt;基于字典的编码 (dictionary&lt;/h4&gt;
&lt;h4 id=&#34;行程编码-run-length-encoding&#34;&gt;行程编码 Run Length Encoding&lt;/h4&gt;
&lt;h4 id=&#34;lzw-编码方式&#34;&gt;LZW 编码方式&lt;/h4&gt;
&lt;h3 id=&#34;53-有损压缩&#34;&gt;5.3 有损压缩&lt;/h3&gt;
&lt;h4 id=&#34;预测编码&#34;&gt;预测编码&lt;/h4&gt;
&lt;h5 id=&#34;dpcm-differential-pulse-code-modulation-编码&#34;&gt;DPCM (Differential Pulse Code Modulation) 编码&lt;/h5&gt;
&lt;h5 id=&#34;dm-delta-modulation-编码&#34;&gt;DM Delta Modulation 编码&lt;/h5&gt;
&lt;h4 id=&#34;变换编码&#34;&gt;变换编码&lt;/h4&gt;
&lt;h5 id=&#34;dct-变换编码&#34;&gt;DCT 变换编码&lt;/h5&gt;
&lt;h5 id=&#34;变换编码-1&#34;&gt;变换编码&lt;/h5&gt;
&lt;h5 id=&#34;小波变换编码&#34;&gt;小波变换编码&lt;/h5&gt;
&lt;h3 id=&#34;65-图像分割基于边缘检测的方法&#34;&gt;6.5 图像分割——基于边缘检测的方法&lt;/h3&gt;
&lt;h4 id=&#34;背景知识-见复印件&#34;&gt;背景知识 见复印件&lt;/h4&gt;
&lt;h4 id=&#34;边缘检测-见复印件&#34;&gt;边缘检测 见复印件&lt;/h4&gt;
&lt;h5 id=&#34;原理-见复印件&#34;&gt;原理 见复印件&lt;/h5&gt;
&lt;h5 id=&#34;边缘检测算子-见复印件&#34;&gt;边缘检测算子 见复印件&lt;/h5&gt;
&lt;h4 id=&#34;霍夫变换-见复印件&#34;&gt;霍夫变换 见复印件&lt;/h4&gt;
&lt;h5 id=&#34;基本原理-见复印件&#34;&gt;基本原理 见复印件&lt;/h5&gt;
&lt;h5 id=&#34;算法实现-见复印件&#34;&gt;算法实现 见复印件&lt;/h5&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;第六章-图像分割&#34;&gt;第六章 图像分割&lt;/h2&gt;
&lt;h3 id=&#34;61--图像分割基本介绍&#34;&gt;6.1  图像分割基本介绍&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;图像处理过程&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210419100146477.png&#34; alt=&#34;image-20210419100146477&#34; style=&#34;zoom:60%;&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;图像分割的方法：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;基于&lt;strong&gt;边缘检测&lt;/strong&gt;的方法（基于&lt;strong&gt;灰度值的不连续性&lt;/strong&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;先找出局部特性的不连续性，再将它们连成边界，边界将图像分成不同区域（通过连通边界进行区域分割）。&lt;/p&gt;
&lt;p&gt;如：边缘检测分割法、Hough变换等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于&lt;strong&gt;区域生成&lt;/strong&gt;的方法（基于&lt;strong&gt;灰度值的相似性&lt;/strong&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将像素分成不同的区域（通过同质性基元的聚类进行区域分割）&lt;/p&gt;
&lt;p&gt;如：&lt;strong&gt;阈值分割法，区域生长&lt;/strong&gt;、分裂合并、形态学分割等。&lt;/p&gt;
&lt;h3 id=&#34;62-边缘检测&#34;&gt;6.2 边缘检测&lt;/h3&gt;
&lt;p&gt;1、滤波
边缘检测的算法主要是基于图像强度的一阶和二阶导数，导数对噪声很敏感，因此必须采用滤波器来改善。主要有高斯滤波，采用离散化的高斯函数产生一组归一化的高斯核，然后基于高斯核函数对图像灰度矩阵的每一个点进行加权求和。
2、增强
增强边缘的基础是确定图像各点邻域强度的变化值。增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来，通过计算梯度幅值来确定 。通常我们用小区域模板进行卷积来计算，有 Sobel 算子、 Roberts 算子、 Prewitt 算子等。
3、检测
经过增强的图像，往往邻域中有很多点的梯度值比较大，所以采用某种方法对这些点进行取舍， 常&lt;/p&gt;
&lt;h3 id=&#34;63--阈值分割法&#34;&gt;6.3  阈值分割法&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;阈值分割是直接对灰度图进行计算的分割方法。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;631-阈值分割原理&#34;&gt;6.3.1 阈值分割原理&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;通式$g(x,y)=\begin{cases}  &amp;amp;Z_E     ,\ f(x,y)∈Z\ 
&amp;amp; Z_B, \ else
\end{cases}$	$Z_E=f(x,y)\rightarrow$半阈值化&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;类间最大方差原则：取最佳阈值时，两部分之间的差别最大，此时错分概率最小&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210419111349334.png&#34; alt=&#34;image-20210419111349334&#34; style=&#34;zoom:33%;aligned&#34; /&gt;如图所示，若物体暗，背景亮。门限选双峰间的凹谷&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分类&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;阈值类型&lt;/th&gt;
&lt;th&gt;适用情况&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;全局阈值&lt;/td&gt;
&lt;td&gt;图像中目标和背景有明显差别，而且这种差别在图像中的任何位置都几乎相同。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;局部阈值&lt;/td&gt;
&lt;td&gt;目标和背景的对比度随着位置的不同可能有较大变化(比如光照不均)。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;单阈值&lt;/td&gt;
&lt;td&gt;图像中只有单个目标和单个背景的情况，或者只对图像进行简单的划分。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;多阈值&lt;/td&gt;
&lt;td&gt;图像中存在多个目标或多个背景的情形，或者对图像进行多个层次的划分。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;直接阈值&lt;/td&gt;
&lt;td&gt;对比度较大的图像，图像中在区域内部灰度基本一致，而不同区域之间灰度有较大的差异。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;间接阈值&lt;/td&gt;
&lt;td&gt;图像中的目标和背景差别不是很大，如果不作处理直接选取阈值的话，用这个阈值不能很好地分割图像。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;632-阈值处理&#34;&gt;6.3.2 阈值处理&lt;/h4&gt;
&lt;h5 id=&#34;6321-基本全局阈值处理&#34;&gt;6.3.2.1 基本全局阈值处理&lt;/h5&gt;
&lt;p&gt;1、为全局阈值T选取一个初始估计值&lt;/p&gt;
&lt;p&gt;2、分割图像。产生两组像素G1和G2&lt;/p&gt;
&lt;p&gt;3、对G1和G2中的像素分别计算平均灰度值（均值）m1和m2&lt;/p&gt;
&lt;p&gt;4、在m1和m2之间计算新的阈值 $T=\frac{1}{2}(m_1+m_2)$&lt;/p&gt;
&lt;p&gt;5、重复2-4，直到连续迭代中的两个T的差小于预定义的ΔT&lt;/p&gt;
&lt;h5 id=&#34;6322-otus方法的全局阈值处理类间最大方差法&#34;&gt;6.3.2.2 Otus方法的全局阈值处理/类间最大方差法&lt;/h5&gt;
&lt;p&gt;基本思想：经过适当的阈值化的两个类，就其像素灰度值而言，应当是截然不同的。同理，就其灰度值而言，给出最佳类间分离的阈值将是最佳的阈值。&lt;/p&gt;
&lt;p&gt;求解过程&lt;strong&gt;不需要人为设定其他参数&lt;/strong&gt;，完全由计算机自动选取。它不仅适用于两个区域的分割，也可以推广到多个区域的情形。&lt;/p&gt;
&lt;h6 id=&#34;otus算法实现流程&#34;&gt;Otus算法实现流程&lt;/h6&gt;
&lt;ol&gt;
&lt;li&gt;计算输入图像（大小MxN，有L个不同灰度级[0, 1, 2, &amp;hellip;, L-1]）的归一化直方图，使用$p_i$表示直方图各个分量，其中$i=0,1,2,&amp;hellip;,L-1$&lt;/li&gt;
&lt;li&gt;计算全局灰度均值$m_G$&lt;/li&gt;
&lt;li&gt;计算累积和$P_1(k)=\sum\limits_{i=0}^kp_i,k=0,1,2,&amp;hellip;,L-1$&lt;/li&gt;
&lt;li&gt;计算累积均值$m(k)=\sum\limits_{i=0}^kip_i,k=0,1,2,&amp;hellip;,L-1$&lt;/li&gt;
&lt;li&gt;计算类间方差$\sigma^2_B(k)=\frac{m_GP_1(k)-m(k)}{P_1(1-P_1)}$&lt;/li&gt;
&lt;li&gt;Otus阈值$k^*=\max\limits_{0\leq k\leq L-1} \sigma^2_B(k)$ 若最大值不唯一，用对应的各个$k$的均值作为$k^*$&lt;/li&gt;
&lt;li&gt;*计算可分性度量$\eta^*=\frac{\sigma^2_B(k)}{\sigma^2_G}$,其中$\sigma^2_G=\sum\limits_{i=0}^{L-1}(i-m_G)^2p_i$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于$P_1(k),m(k),\sigma^2_G$均为累加值，可以在遍历各个灰度级的同时进行递推计算，即$P_1(k)=P_1(k-1)+p_{k},k=0,1,2,&amp;hellip;,L-1$，其中$P_1(-1)$记为0。&lt;/p&gt;
&lt;h6 id=&#34;otus方法类间方差公式推导&#34;&gt;Otus方法类间方差公式推导&lt;/h6&gt;
&lt;p&gt;其中$m_1(k)=\frac{1}{P_1(k)}\sum\limits_{i=0}^kip_i,k=0,1,2,&amp;hellip;,L-1$&lt;/p&gt;
&lt;p&gt;1、&lt;img src=&#34;https://K7288.github.io/assets/image-20210619170902579.png&#34; alt=&#34;image-20210619170902579&#34; style=&#34;zoom:25%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210619170845722.png&#34; alt=&#34;image-20210619170845722&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;img src=&#34;https://K7288.github.io/assets/image-20210619191957635.png&#34; alt=&#34;image-20210619191957635&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210619191934163.png&#34; alt=&#34;image-20210619191934163&#34; style=&#34;zoom:70%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;633-改进&#34;&gt;6.3.3 改进&lt;/h4&gt;
&lt;h5 id=&#34;a-图像平滑改进&#34;&gt;a 图像平滑改进&lt;/h5&gt;
&lt;p&gt;噪声会将简单的阈值处理问题变得不可解决，当噪声不能在源头减少，并且需要用阈值处理分割图像时，通常在阈值处理之前平滑图像，以增强阈值处理的性能。&lt;/p&gt;
&lt;h5 id=&#34;b-边缘改进&#34;&gt;b 边缘改进&lt;/h5&gt;
&lt;p&gt;边界明显，但是整体灰度值相近：求梯度，根据梯度幅度图像得到的模板图像P，原图像和P相乘得到的结果进行处理&lt;/p&gt;
&lt;h5 id=&#34;c-可变阈值处理&#34;&gt;c 可变阈值处理&lt;/h5&gt;
&lt;h6 id=&#34;i-基于局部图像性质&#34;&gt;(i) 基于局部图像性质&lt;/h6&gt;
&lt;p&gt;在图像的每个点(x,y)，根据坐标的一个&lt;strong&gt;邻域&lt;/strong&gt;的一条或多条规定性质计算阈值。&lt;/p&gt;
&lt;p&gt;$T_{xy}=aσ_{xy}+bm_{xy}=aσ_{xy}+bm_G$，其中a、b大于0&lt;/p&gt;
&lt;h6 id=&#34;ii-基于移动平均&#34;&gt;(ii) 基于移动平均&lt;/h6&gt;
&lt;p&gt;一维数组 序列信息 沿一幅图像的扫描行计算平均&lt;/p&gt;
&lt;p&gt;z形扫描$(m_{ij})_{n\times n}$ 得到 $[m_{11},m_{12},&amp;hellip;,m_{1n},m_{2n},m_{2n-1}]$&lt;/p&gt;
&lt;p&gt;第$k+1$次扫描遇到的点的灰度：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210518121255049.png&#34; alt=&#34;image-20210518121255049&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;阈值$T_{xy}=c\times m_{xy}$&lt;/p&gt;
&lt;h3 id=&#34;64-区域分割法&#34;&gt;6.4 区域分割法&lt;/h3&gt;
&lt;h4 id=&#34;641-区域生长-bottom-up&#34;&gt;6.4.1 区域生长 Bottom-up&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;步骤&lt;/strong&gt;
1、种子像素作为生长的起点；
2、确定一个相似性标准（评判是否合并的条件）；
3、按照相似性标准，将种子像素的邻域中具有与种子相同和相似性质的像素，合并到种子的区域中；
4、将新像素当作新的种子像素继续进行上面的过程，直到再没满足条件的像素可被包括进来为止，这样就完成了一个区域的生长；
5、按此方法，完成其它区域的生长，直到将整幅图像完全分割。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;种子选取（利用特征或先验知识）
最亮的像素；直方图极大值；聚类中心处像素&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;相似性准则(生长准则)确定
区域灰度差；区域内灰度分布特性；颜色、纹理、尺寸形状等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生长停止条件确定
区域大小；区域与候选像素相似性；正在增长区域的形状。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;
计算简单，通常能将具有相同特征的联通区域分割出来。在没有先验知识可以利用时，可以取得最佳的性能&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;
对噪音敏感，导致抽取的区域有空洞&lt;/p&gt;
&lt;h4 id=&#34;642-区域分离与聚合-up-down&#34;&gt;6.4.2 区域分离与聚合 Up-down&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;步骤&lt;/strong&gt;
1、进行一次分裂；
2、考察所有相邻区域是否可以合并，若可以，则将其一一合并；
3、重复步骤1、2的分裂合并过程，直到分裂和合并都不能再进行为止。&lt;/p&gt;
&lt;p&gt;注意：合并时一般先考虑同一个父节点下的4个区域，之后再扩展到其它父节点下同层次的区域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;难点&lt;/strong&gt;
分裂与合并的准则不好判断。分裂的准则又称为均匀性测试准则，用于判断该块图像是否需要分裂。
当均匀性测试准则选择不当时，很容易会引起“方块效应”。&lt;/p&gt;
&lt;h4 id=&#34;643-空间聚类k均值聚类&#34;&gt;6.4.3 空间聚类/K均值聚类&lt;/h4&gt;
&lt;p&gt;将观测集合Q划分为k个满足如下最优准则的不想交的聚类集合$𝐶={𝐶_1,𝐶_2,…𝐶_𝑘}$:&lt;img src=&#34;https://K7288.github.io/assets/image-20210419113324691.png&#34; alt=&#34;image-20210419113324691&#34; style=&#34;zoom:33%; &#34; /&gt;&lt;/p&gt;
&lt;p&gt;1、初始化算法：规定一组初始均值$m_i (1),i=1,2,…,k$&lt;/p&gt;
&lt;p&gt;2、将样本分配给聚类：将每个样本分配给均值最接近的聚类集合（关系被任意求解，但样本只分配给一个聚类）：&lt;/p&gt;
&lt;p&gt;$z_q→C_i$,如果$‖z_q-m_i^2 ‖&amp;lt;‖z_q-m_j ‖^2$,$j=1,2,…,k(j≠i);q=1,2,…,Q$&lt;/p&gt;
&lt;p&gt;3、更新聚类中心（均值）：&lt;/p&gt;
&lt;p&gt;$m_i=1/|C_i | ∑129_(z∈C_i)▒z,i=1,2,…,k$&lt;/p&gt;
&lt;p&gt;4、完备性检验：计算当前步骤和前几步中平均向量之间的差的欧几里得范数。计算残差E，即k个范数之和。若E≤T，其中T是一个规定的非负阈值，则停止。否则，返回步骤2.&lt;/p&gt;
&lt;h4 id=&#34;644-超像素的区域分割&#34;&gt;6.4.4 超像素的区域分割&lt;/h4&gt;
&lt;h5 id=&#34;基本思想&#34;&gt;基本思想&lt;/h5&gt;
&lt;p&gt;通过将像素组合到比各个像素更有感知意义的原始区域来取代标准原始图像 。
超像素分割的目的是减小计算开销并通过减少不相关的细节来提高分割算法的性能 。&lt;/p&gt;
&lt;h5 id=&#34;slic-超像素算法&#34;&gt;SLIC 超像素算法&lt;/h5&gt;
&lt;p&gt;简单线性迭代聚类SLIC 是 k 均值分割算法的一种改进 。 与其它超像素算法相比 原理简单 具有计算优势和其他性能优势 。&lt;/p&gt;
&lt;h5 id=&#34;具体步骤&#34;&gt;具体步骤&lt;/h5&gt;
&lt;p&gt;1、初始化算法：以规则步长 S 对图像取样 计算初始的超像素聚类中心 𝒎𝑖=[𝑟𝑖,𝑔𝑖,𝑏𝑖,𝑥𝑖,𝑦𝑖] ,𝑖=1,2,…,$n_{sp}$&lt;/p&gt;
&lt;p&gt;2、在种子点的 n*n 邻域内重新选择种子点 一般取 n= 3 。 具体方法为：计算该邻域内所有像素点的梯度值 将种子点移到该邻域内梯度最小的地方&lt;/p&gt;
&lt;p&gt;3、计算距离测度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210619170219160.png&#34; alt=&#34;image-20210619170219160&#34; style=&#34;zoom:30%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;4、将样本分配给聚类中心：在每个种子点周围的邻域内为每个像素点分配类标签 即属于哪个聚类中心 。 和标准的 k means 在整张图中搜索不同 SLIC 的搜索范围限制为 2 S* 2 S 可以加速算法收敛 如下图 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210619170345573.png&#34; alt=&#34;image-20210619170345573&#34; style=&#34;zoom:30%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;5、更新聚类中心
6、收敛性检验：计算当前步骤和前几步中平均向量之间的差的欧几里得范数 。 计算残差 E 即 k 个范数之和 。 若 𝐸 𝑇 其中 T 是一个规定的非负阈值 则停止 。 否则 返回步骤 2
7、后处理超像素区域：将每个区域中的所有超像素替换为他们的平均值&lt;/p&gt;
&lt;h5 id=&#34;优点&#34;&gt;优点&lt;/h5&gt;
&lt;p&gt;1、生成的超像素如同细胞一般紧凑整齐 邻域特征比较容易表达 。
2、不仅可以分割彩色图 也可以兼容分割灰度图 。
3、需要设置的参数非常少 默认情况下只需要设置一个预分割的超像素的数量 。
4、相比其他的超像素分割方法 SLIC 在运行速度 、 生成超像素的紧凑度 、 轮廓保持方面都比较理想&lt;/p&gt;
&lt;h5 id=&#34;总结&#34;&gt;总结&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210619170737920.png&#34; alt=&#34;image-20210619170737920&#34;  /&gt;&lt;/p&gt;
&lt;div style=&#34;page-break-after:always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;第七章-图像的特征提取&#34;&gt;第七章 图像的特征提取&lt;/h2&gt;
&lt;p&gt;定位 初始关键点 localize where to describe features 描述 如何描述这些区域/点&lt;/p&gt;
&lt;h3 id=&#34;71-背景知识&#34;&gt;7.1 背景知识&lt;/h3&gt;
&lt;p&gt;图像分析系统的基本构成&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429143954884.png&#34; alt=&#34;image-20210429143954884&#34; style=&#34;zoom:30%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在图像分割后，为了进一步的处理，分割后的图像一般要进行形式化的表达和描述。
解决形式化表达问题一般有两种选择：
1、根据区域的外部特征来进行形式化表示
2、根据区域的内部特征（比较区域内部的象素值）来进行形式化表示&lt;/p&gt;
&lt;p&gt;选择表达方式，要本着使数据变得更有利于下一步的计算工作。下一步工作是基于所选的表达方式描述这个区域，一般情况下：
1、如果关注的焦点是形状特性，选择外部表示方式
2、如果关注的焦点是反射率特性，如颜色、纹理时，选择内部表示方式。
3、所选表示方式，应该对尺寸、变换、旋转等变量尽可能的不敏感&lt;/p&gt;
&lt;h3 id=&#34;72-边界预处理&#34;&gt;7.2 边界预处理&lt;/h3&gt;
&lt;h4 id=&#34;721-区域骨架抽取-见复印件&#34;&gt;7.2.1 区域骨架抽取 见复印件&lt;/h4&gt;
&lt;p&gt;1、Blum的中轴变换方法（MAT：Medial Axis Transform）
设:𝑅是一个区域，𝐵为𝑅的边界，在𝑅中寻找点𝑝(x, y)，使𝑝最接近于B。如果𝑝有多这个这样的临点（&lt;strong&gt;最近邻点&amp;gt;=2&lt;/strong&gt;)，则𝑝点形成的轨迹为R的中轴（骨架）。
存在问题：计算量大
在保证产生正确的骨架的同时，改进算法的效率。比较典型的是一类细化算法，它们不断删去边缘，但保证删除满足：
1、不移去端点 2、不破坏连通性 3、不引起区域的过度腐蚀&lt;/p&gt;
&lt;h3 id=&#34;73-特征描述子&#34;&gt;7.3 特征描述子&lt;/h3&gt;
&lt;h4 id=&#34;731-边界特征描述子-见复印件&#34;&gt;7.3.1 边界特征描述子 见复印件&lt;/h4&gt;
&lt;h4 id=&#34;732-区域特征描述子&#34;&gt;7.3.2 区域特征描述子&lt;/h4&gt;
&lt;h5 id=&#34;7321-基本描述子-见复印件&#34;&gt;7.3.2.1 基本描述子 见复印件&lt;/h5&gt;
&lt;h5 id=&#34;7322-纹理描述基于直方图基于统计方法基于谱方法&#34;&gt;7.3.2.2 纹理描述(基于直方图、基于统计方法、基于谱方法)&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;1、定义&lt;/strong&gt; 纹理特征刻画了图像中重复出现的局部模式与他们的排列规则，常用于图像分类和场景识别。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、特点&lt;/strong&gt; 反映物体表面的特性，无法完全反映出物体的本质属性，所以仅用纹理特征无法获得图像的高层次内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、基于直方图的纹理测度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;令z是一个表示灰度的随机变量，$𝑝(𝑧_i), i = 0,1,2…𝐿$是对应的&lt;strong&gt;归一化&lt;/strong&gt;直方图，其中𝐿是不同灰度级的数量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;均值 $m=\sum_{i=0}^{L-1}z_ip(z_i) $&lt;/li&gt;
&lt;li&gt;𝑍相对于平均值的𝑛阶矩 $\mu_n=\sum_{i=0}^{L-1}(z_i-m)^np(z_i) $&lt;/li&gt;
&lt;li&gt;一致性测度  $U=\sum_{i=0}^{L-1}p^2(z_i) $&lt;/li&gt;
&lt;li&gt;方差 $\sigma^2(z)=\mu_2(z)$&lt;/li&gt;
&lt;li&gt;相关性测度 $R=1-\frac{1}{1+\sigma^2(z)},$其中$\sigma^2(z)$最好除以$(L-1)^2$进行归一化。&lt;/li&gt;
&lt;li&gt;熵  $e(z)=-\sum_{i=0}^{L-1}p(z_i)log_2p(z_i)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;U对所有灰度级都相等的图像有最大值（极大 一致性） ， 并从最大值开始降低。熵是可变性的测度，对恒定图像其为零。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、基于统计方法的纹理描述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）灰度共生矩阵&lt;/strong&gt;(GLCM, Gray-level co-occurrence matrix)通过计算灰度图像得到它的共生矩阵，然后再计算所得到的共生矩阵的部分特征值，来分别代表图像的某些纹理特征。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）作用&lt;/strong&gt; 灰度共生矩阵能反映图像灰度&lt;strong&gt;关于方向、相邻间隔、变化幅度&lt;/strong&gt;等综合信息（直方图无法体现），它是分析图像的&lt;strong&gt;局部模式&lt;/strong&gt;和它们&lt;strong&gt;排列规则的基础&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（3）灰度共生矩阵构建方法&lt;/strong&gt;
1、矩阵$G$大小为灰度级的数量。
8比特(256灰度级）大小为256x256。为减少计算量，也会采取将灰度级量化，减小数据量
2、$g_{ij}$表示灰度为$z_i$和$z_j$的像素对在Q规定的位置上出现的次数。Q是定义两个像素的相对位置的算子&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（4）共生矩阵特性描述&lt;/strong&gt;
$$
p_{ij}=\frac{g_{ij}}{n}
$$&lt;/p&gt;
&lt;p&gt;$n$满足Q的像素对的总数（G元素加和）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429141308597-1619676790611.png&#34; alt=&#34;image-20210429141308597&#34;  /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429141802556.png&#34; alt=&#34;image-20210429141802556&#34; style=&#34;zoom:53%;&#34; /&gt;&lt;/th&gt;
&lt;th&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429141848754-1619677130509.png&#34; alt=&#34;image-20210429141848754&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/th&gt;
&lt;th&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429141924483.png&#34; alt=&#34;image-20210429141924483&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;随机图像的共生矩阵为随机矩阵&lt;/td&gt;
&lt;td&gt;正弦波的对称性，像素对𝑧i, 𝑧j 的数量与产生对称共生矩阵的像素对𝑧j,𝑧i 数量相同&lt;/td&gt;
&lt;td&gt;很多值沿主对角线也是分组的，但是分布比G2密集，这一性质表明图像的灰度值变化很大&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;4、谱方法&lt;/strong&gt;（了解）
傅立叶谱非常适合描述图像中周期或半周期二维模式的方向性。这样的全局纹理模式很容易区分为谱中高能量的集中爆发。&lt;/p&gt;
&lt;p&gt;用于纹理描述的傅立叶谱的特点
1、谱中的突出峰给出纹理模式的主方向
2、频率平面上的峰值位置给出纹理模式的基本空间周期
3、通过滤波可以消除任何周期分量&lt;/p&gt;
&lt;p&gt;谱特征的检测和解释&lt;/p&gt;
&lt;p&gt;通常可在极坐标中将谱表示为函数𝑆(𝑟, 𝜃)。对于每个方向𝜃，𝑆(𝑟, 𝜃)可表示为一维函数$𝑆_{\theta}(𝑟)$
𝜃固定时，分析$𝑆_{\theta}(𝑟)$得到从原点到径向的方向的谱的特性（如峰的出现）&lt;img src=&#34;https://K7288.github.io/assets/image-20210429144759934.png&#34; alt=&#34;image-20210429144759934&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;𝑟固定时，分析得到一个以原点为圆心的圆上谱的特性&lt;img src=&#34;https://K7288.github.io/assets/image-20210429144832467.png&#34; alt=&#34;image-20210429144832467&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;733-特征描述子的主分量&#34;&gt;7.3.3 特征描述子的主分量&lt;/h4&gt;
&lt;p&gt;假设有n幅配准（目标通过图像变换重合）的图像，那么所有图像中相同空间位置的对应图像可以排列为一个n维向量$\bold{x}= [𝑥_1 ,𝑥_2 ⋯𝑥_n]^T$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;总体平均向量 $\bold{m_x}=E(\bold{x})$     比如每幅图像都是524*524,就是524*524个n维向量求均值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;协方差矩阵 &lt;img src=&#34;https://K7288.github.io/assets/image-20210429145742090.png&#34; alt=&#34;image-20210429145742090&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;霍特林变换&lt;/strong&gt; &lt;img src=&#34;https://K7288.github.io/assets/image-20210429145928863.png&#34; alt=&#34;image-20210429145928863&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429150041193.png&#34; alt=&#34;image-20210429150041193&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;其中A为一个矩阵，这个矩阵的各行由𝑪𝒙的特征向量构成，并按特征值降序排列&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;性质&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;𝑪𝒚是对角阵，主对角元素是𝑪𝒙的特征值&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210429150144822.png&#34; alt=&#34;image-20210429150144822&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;LDA PCA 特征值由x维度决定&lt;/p&gt;
&lt;h3 id=&#34;74尺度不变特征变换-sift-scale-invariant-feature-transform-见复印件&#34;&gt;7.4尺度不变特征变换 SIFT Scale-invariant feature transform 见复印件&lt;/h3&gt;
&lt;p&gt;1、构建尺度空间&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210506135051482.png&#34; alt=&#34;image-20210506135051482&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Octave1 images smoothed using Gaussian lowpass kernels (k&amp;gt;1) （$\sigma$越大越模糊）&lt;/p&gt;
&lt;p&gt;Octave2 Octave1下采样&lt;/p&gt;
&lt;h2 id=&#34;第九章-图像分类&#34;&gt;第九章 图像分类&lt;/h2&gt;
&lt;p&gt;面临的困难和挑战：视角变化 尺度条件 变形 遮挡 光照条件 背景杂乱 类内差异&lt;/p&gt;
&lt;h3 id=&#34;91-原型匹配模式分类&#34;&gt;9.1 原型匹配模式分类&lt;/h3&gt;
&lt;h4 id=&#34;最小距离分类器&#34;&gt;最小距离分类器&lt;/h4&gt;
&lt;p&gt;使用最广泛且最简单的原型匹配分类方法之一&lt;/p&gt;
&lt;p&gt;它在未知模式向量X和每类原型之前计算一个基于距离的测度d，然后将未知模式赋予最接近的原始类。是一种&lt;strong&gt;聚类分析&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;计算每个类别对应特征的均值&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210520143033690.png&#34; alt=&#34;image-20210520143033690&#34; style=&#34;zoom: 33%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;$n_j$ 第j个类别的样本数，$c_j$第j个类别，$N_c$类别总数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最小分类器计算距离&lt;/p&gt;
&lt;p&gt;$D_j(x) = \left |  \boldsymbol{x}-\boldsymbol{m_j} \right |$&lt;/p&gt;
&lt;p&gt;$d_j(x)=\boldsymbol{m}_j^T\boldsymbol{x}-\frac{1}{2}\boldsymbol{m}_j^T\boldsymbol{m}_j$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;决策函数/判别函数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210520143527980.png&#34; alt=&#34;image-20210520143527980&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;决策边界（与两类特征点等距）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210520143850991.png&#34; alt=&#34;image-20210520143850991&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;优点：原理简单、计算速度快
缺点：分类精度不高&lt;/p&gt;
&lt;p&gt;e.g.&lt;img src=&#34;https://K7288.github.io/assets/image-20210520144256479.png&#34; alt=&#34;image-20210520144256479&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;92-最优贝叶斯统计分类器&#34;&gt;9.2 最优（贝叶斯）统计分类器&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210520150332263.png&#34; alt=&#34;image-20210520150332263&#34; style=&#34;zoom:20%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;有监督的学习算法&lt;/p&gt;
&lt;h4 id=&#34;贝叶斯决策函数&#34;&gt;贝叶斯决策函数&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524101311087.png&#34; alt=&#34;image-20210524101311087&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;乘式取对数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524101338324.png&#34; alt=&#34;image-20210524101338324&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt; 原理简单、学习效率高&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点/不足&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;由于该算法以自变量之间的独立（条件特征独立）性和连续变量的正态性假设为前提，会导致算法精度在某种程度上受影响。&lt;/li&gt;
&lt;li&gt;除了均值方差，还有更精准的模式/统计特性（特征值、特征向量$\Rightarrow$ 表征哪个方向变化剧烈）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;93-神经网络分类&#34;&gt;9.3 神经网络分类&lt;/h3&gt;
&lt;p&gt;robust（图像变换后不影响类别等较宏观特征的提取）和sensitive（判断具体图像变换）之间的trade-off：网络到一定深度后分开，一部分robust，另一部分sensitive，结合完成任务&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.B.&lt;/strong&gt; filter的最大的特点是其深度与输入层的深度是一致的。输入层是单通道，单个filter也是单通道。 输入层是三通道，单个filter也是三通道&lt;/p&gt;
&lt;h4 id=&#34;lenet&#34;&gt;LeNet&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524104903557.png&#34; alt=&#34;image-20210524104903557&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;vgg16&#34;&gt;VGG16&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524105012485.png&#34; alt=&#34;image-20210524105012485&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;wide-resnets&#34;&gt;Wide ResNets&lt;/h4&gt;
&lt;p&gt;ResNet的跳连接，导致了只有少量的残差块学到了有用信息，于是出现了一种新的网络WideResNet（在ResNet的基础上减小深度，增加宽度）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524105240443.png&#34; alt=&#34;image-20210524105240443&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524105442212.png&#34; alt=&#34;image-20210524105442212&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;resnext&#34;&gt;ResNeXt&lt;/h4&gt;
&lt;p&gt;ResNeXt 结构基于VGG的“堆叠”与Inception系列网络的“split-transform-merge”思想，可以在不增加参数复杂度的前提下提高准确率，减少了超参数的数量&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524105513030.png&#34; alt=&#34;image-20210524105513030&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;256,1x1,64&lt;/code&gt; 256维输入经过64个1x1(x256)filter降维到64维&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524110307163.png&#34; alt=&#34;image-20210524110307163&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;a,b,c三个子图结构是等价的，最后一个子图用了&lt;strong&gt;分组卷积&lt;/strong&gt;技术使得结构更加紧凑简洁，模型实现使用的是最后一个子图的结构&lt;/p&gt;
&lt;h4 id=&#34;densenet&#34;&gt;DenseNet&lt;/h4&gt;
&lt;p&gt;在保证网络中层与层之间最大程度的信息传输的前提下，让网络每一层和前面所有的层连接起来&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524110405574.png&#34; alt=&#34;image-20210524110405574&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;因为feature map大小不同的时候concat会出现size问题，DenseNet把网络分成了几个Dense Block，中间用transition layer（用来改变feature map大小）连接起来&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524110415948.png&#34; alt=&#34;image-20210524110415948&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;densenet-bc&#34;&gt;DenseNet-BC&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524110644386.png&#34; alt=&#34;image-20210524110644386&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;B表示bottleneck结构，把3x3conv替换成(1x1, 3x3)conv；
C表示压缩，在transition层设一个参数𝜃来减小特征图个数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524111332338.png&#34; alt=&#34;image-20210524111332338&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;#parameters越大，计算量/模型文件大小/加载时间都变大&lt;/p&gt;
&lt;p&gt;DenseNet网络复杂，参数量大，学习/收敛能力强，但也更快达到瓶颈&lt;/p&gt;
&lt;h4 id=&#34;squeeze-and-excitation-networks-senet&#34;&gt;Squeeze-and-Excitation Networks (SENet)&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524110731565.png&#34; alt=&#34;image-20210524110731565&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;squeeze与注意力机制相似，判断不同特征层重要性&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524111043877.png&#34; alt=&#34;image-20210524111043877&#34; style=&#34;zoom:43%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;激活后加权到原特征层&lt;/p&gt;
&lt;p&gt;SE block并不是一个完整的网络结构，而是一个子结构，可以嵌到其他分类或检测模型中&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524112443273.png&#34; alt=&#34;image-20210524112443273&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;mobilenet&#34;&gt;MobileNet&lt;/h4&gt;
&lt;p&gt;卷积神经网络越来越复杂，内存与响应速度问题使得在某些真实的应用场景如移动或者嵌入式设备，如此大而复杂的模型是难以被应用的&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524113534842.png&#34; alt=&#34;image-20210524113534842&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;基本单元：深度级可分离卷积
（depthwise separable convolution）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210524113512941.png&#34; alt=&#34;image-20210524113512941&#34; align=&#34;right&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;depthwise convolution:针对每个
输入通道采用不同的卷积核&lt;/li&gt;
&lt;li&gt;pointwise convolution:采用
1x1的卷积核的普通卷积（&lt;strong&gt;通道整合&lt;/strong&gt;）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;但是降低flops（计算复杂度）后时间不一定减少，还和硬件计算方式有关。MobileNet频繁调度各个channel的filter&lt;/p&gt;
</description>
        </item>
        <item>
        <title>The effect of stride length on lower extremity joint kinetics at various gait speeds</title>
        <link>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</link>
        <pubDate>Sun, 16 May 2021 10:44:02 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</guid>
        <description>&lt;p&gt;The effect of stride length on lower extremity joint kinetics at various gait speeds&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#research-question&#34; &gt;Research question&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#concepts&#34; &gt;Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#notations&#34; &gt;Notations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#background&#34; &gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#materials-and-methods&#34; &gt;Materials and Methods&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#data-analysis&#34; &gt;Data analysis&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#1-%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86&#34; &gt;1. 数据处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#2-protocol-validation&#34; &gt;2. Protocol validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#3-continuum-analysis&#34; &gt;3. Continuum analysis&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#main-effect-analysis&#34; &gt;main effect analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#sl&#34; &gt;SL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#4-torque-pulse-approximation&#34; &gt;4. Torque pulse approximation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#results&#34; &gt;Results&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#protocol-validation&#34; &gt;Protocol validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#continuum-analysis&#34; &gt;Continuum analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#torque-pulse-approximation&#34; &gt;Torque pulse approximation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#conclusion&#34; &gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#limitsfurther-work&#34; &gt;Limits/Further Work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#thoughtscomments&#34; &gt;Thoughts/Comments&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;In this study, we investigated how &lt;strong&gt;sagittal plane joint moments&lt;/strong&gt; are affected by a factorial modulation of two important gait parameters: &lt;strong&gt;gait speed and stride length&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We designed an experimental study to establish the effects of GS and SL on the resulting hip, knee, and ankle joint moments. The findings are intended to inform the design of a robotic controller that delivers pulses of torque to the lower extremity joints with optimal timing and amplitude to induce desirable modulations of GS and SL, and of associated spatiotemporal parameters.&lt;/p&gt;
&lt;h2 id=&#34;concepts&#34;&gt;Concepts&lt;/h2&gt;
&lt;p&gt;sagittal plane矢状面，把身体分成左右两条，解剖学用来描述身体各部分位置（类似经线）N.B.不只有中线&lt;/p&gt;
&lt;p&gt;sagittal plane movement包括任何具有前后成分的运动&lt;/p&gt;
&lt;h2 id=&#34;notations&#34;&gt;Notations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GS: gait speed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TLA: trailing limb angle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SL: stride length&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SL for cycle k was defined based on the right heel strike time t and anteroposterior coordinate in the laboratory frame x and constant velocity of the treadmill v&lt;/p&gt;
&lt;p&gt;$SL_{(k)}=x_{(k+1)}-x_{(k)}+v(t_{(k+1)}-t_{(k)})$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$L_l$: leg length in m&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\alpha_l$: time of application(defined as the set of integers between 5% and 95%, providing a quantization in the  time of application of torque pulses
equal to 1% of a gait cycle duration)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$A_l$: amplitude&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\tau(\overset{\sim}t)$ : an average hip, knee, and ankle joint moment profile(力矩); Segmented gait cycles linearly resampled in the [0, 100] % gait cycle domain $\overset{\sim}t$ and averaged at &lt;u&gt;each point in gait cycle&lt;/u&gt; to yield $\tau(\overset{\sim}t)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\overset{\sim}\tau$/$\overset{-}\tau$: normalized joint moments.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;gait training devices&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;that promote desired changes in gait&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Challenges in developing such devices: limited understanding of human response to robotic input&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比如机器人运动辅助会怎样影响gait speed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Possible method of controller formulation: control robot to apply the change in joint moment applied by human subjects when they achieve a gait feature of interest.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However, it is currently unclear how lower extremity joint moments are modulated by even basic gait spatio-temporal parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GS $\leftrightarrow$ propulsive force + Propulsive impulse $\leftrightarrow$ TLA $\Rightarrow$ GS  $\leftrightarrow$ TLA&lt;/p&gt;
&lt;p&gt;GS correlated with anterior- posterior ground reaction force(the propulsive force of the foot against the ground)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Propulsive impulse冲量(the propulsive force integrated over time), is associated with the posture of the trailing limb at push-off.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; The posture of the trailing limb at push-off is quantified by one kinematic parameter, known as trailing limb angle (TLA), defined as the angle of the line connecting the hip joint center and foot center of pressure at the instant of peak propulsive force, relative to the global vertical axis最大推进力瞬时髋与足中心连线与竖直方向的夹角&lt;/p&gt;
&lt;p&gt;When increasing GS, the increase in TLA contributes twice as much as the increase in ankle moment to the resulting increase in propulsive force. In older adults exposed to a biofeedback paradigm for increasing propulsive force, increased TLA and decreased hip flexor power were the primary means by which they increased propulsive force.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A possible method of controller formulation can be derived from the principle of bio-inspiration, where a robot is controlled to apply the difference in joint moment applied by human subjects when they achieve a desired gait feature (in this case modulation of TLA), relative to their normal walking condition. 控制思路：检测TLA变化，根据正常行走时的关系调整辅助系统的关节运动&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since TLA has not been a primary measure ofinterest in the biome- chanics literature, we extended our search to a more common variable, likely correlated to TLA, such as stride length (SL).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GS modulation和magnitude of peak joint moments的关系研究得比较多，hip knee ankle和变化的先后关系、出现的phase等；However, fewer investigations have focused on the joint kinetics associated with the modulation of spatiotemporal parameters such as SL or TLA, and studied this effect at multiple GS values.又列举了一些证明SL和关节动力学有关的研究；Thus far, the factorial modulation ofboth GS and SL and resulting hip, knee, and ankle kinetics has not been investigated; as such it is unclear how lower extremity joint moments are modulated by both gait parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;materials-and-methods&#34;&gt;Materials and Methods&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;准备：跑步机；36 reflective spherical markers (4 on the pelvis, 4 per thigh, 4 per shank, 2 per knee, and 6 on ankle/foot；摄像头动捕；Marker data were acquired at 100 Hz, while the treadmill analog force/torque data were acquired at 2 kHz；biofeedback 显示当前SL使被试进行调整&lt;/li&gt;
&lt;li&gt;采样（GS 5 * SL 3 = 15种场景）：1️⃣ calculate the subject’s self-selected gait speed (ss-GS) 2️⃣ Non-biofeedback conditions: calculate ss-SL at five speeds (ss-GS [80%, 90%, 100%, 110%, 120%] in random order) 3️⃣ Biofeedback conditions: 被试根据跑步机的SL反馈分别用 1+17% / 1-17% 的ss-SL&lt;/li&gt;
&lt;li&gt;数据分析&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;data-analysis&#34;&gt;Data analysis&lt;/h3&gt;
&lt;h4 id=&#34;1-数据处理&#34;&gt;1. 数据处理&lt;/h4&gt;
&lt;p&gt;1️⃣ 25N门控处理力 2️⃣ 低通滤波处理动捕和力（cut-off currency分别6Hz 30Hz）3️⃣ 插值处理动捕数据（a third order polynomial fit for a maximum gap size of five samples三阶多项式拟合）4️⃣ 将受试者的质量、身高和站立校准标记位置应用到解剖模板中，得到一个7节段(骨盆、大腿、小腿和脚)受试者模型&lt;/p&gt;
&lt;p&gt;(a) In a custom MATLAB (MathWorks, Natick, MA, USA) script, hip, knee, and ankle joint angles and moments for the right leg in the sagittal plane were extracted and filtered with &lt;strong&gt;a 2nd order low-pass zero-shift Butterworth filter with a cut-off frequency of 15 Hz&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;(b) Gait cycles were segmented between subsequent &lt;strong&gt;heel strike events, defined as the instants at which the vertical ground reaction force changed in value from zero to positive, and remained positive for a minimum of 400ms&lt;/strong&gt;. 手动检查排除由于仪器故障/被试踏空导致的异常数据； A minimum of 25 segmented gait cycles were linearly resampled in the [0, 100] % gait cycle domain $\overset{\sim}t$ and averaged at &lt;u&gt;each point in gait cycle&lt;/u&gt; to yield an average hip, knee, and ankle joint moment profile $\tau(\overset{\sim}t)$ for each of the 15 experimental conditions for each of the 20 subjects&lt;/p&gt;
&lt;p&gt;(c) the non-dimensional无量纲 joint moment $\overset{\sim}\tau$ was calculated for each joint as $\overset{\sim}\tau(\overset{\sim}t)=\frac{\tau(\overset{-}t)}{WL_l}$ , where W is body weight in N, and $L_l$ leg length in m, measured as the distance between the hip joint center and the floor during straight-leg standing.&lt;/p&gt;
&lt;h4 id=&#34;2-protocol-validation&#34;&gt;2. Protocol validation&lt;/h4&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用$CV_{Fr}$ 证明不同被试之间动力学相似性；&lt;/li&gt;
&lt;li&gt;计算不同GS下用腿长规范化的步长方差（比较小，同一个GS下的SL是比较稳定的）；&lt;/li&gt;
&lt;li&gt;线性回归得到r值证明$TLA$和$SL_0$统计学意义上相关；&lt;/li&gt;
&lt;li&gt;基于12证明实验计划可以显著改变SL和GS，所以可以进行统计学分析&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;(a) a non-dimensional GS(Froude number) $F_r=GS/\sqrt{L_lg}$ used as an index of across-subject dynamic similarity in ss-GS&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;: a smaller variance of Froude numbers within a group of individuals should reflect consistent gait kinetics. $\rightarrow$ the coefficient of variation $CV_{Fr}$&lt;/p&gt;
&lt;p&gt;(b) $CV_{Fr}=\frac { \sigma _{Fr}}{\mu_{Fr}}$
corresponding to the ss-GS condition$\rightarrow$ compared it to alternative indices, $CV_{ss-GS}$ using $ss-GS$ ; $CV_{ss-GS_0}$ using $ss-GS_0$ normalized by leg length; $\Rightarrow$ 用于量化across-subject variability
(c) calculate SL using &lt;a class=&#34;link&#34; href=&#34;#notations&#34; &gt;this Eq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(d) TLA 根据定义&lt;/p&gt;
&lt;p&gt;(e) To determine if the imposed biofeedback effectively modulated SL in healthy subjects, 计算15种情况的distribution of SL values, the mean $TLA$ and $SL_0$ $\rightarrow$ conducted a linear correlation analysis using these two measurements as factors to assess the statistical association between normalized stride length and TLA.&lt;/p&gt;
&lt;h4 id=&#34;3-continuum-analysis&#34;&gt;3. Continuum analysis&lt;/h4&gt;
&lt;p&gt;总结：时序信息分析&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关节力矩时序信息与GS, SL, interaction GS-SL相关性分析(repeated-measure 2-way ANOVA两因素重复测量方差分析；另一因素是时间),得到GS SL在一个步态周期内与哪些关节运动相关、相关性强度等&lt;/li&gt;
&lt;li&gt;给定关节、GS，对ss-SL vs +17%和ss-SL vs -17%比较组下的关节力矩时序信息进行双侧配对t检验&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h5 id=&#34;main-effect-analysis&#34;&gt;main effect analysis&lt;/h5&gt;
&lt;p&gt;(a) &lt;strong&gt;repeated-measure 2-way ANOVA&lt;/strong&gt; on the mean joint moment profiles measured from each subject and experimental conditions, spanning exhaustively the 15 combinations of factors.&lt;/p&gt;
&lt;p&gt;ANOVA was conducted to test the &lt;strong&gt;null hypothesis&lt;/strong&gt;(零假设/原假设 一般是希望证明其错误的假设) that &lt;strong&gt;neither factor (GS and SL), nor their interaction, induce a significant effect on joint moment at any time point&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;(b) &lt;a id=&#34;series&#34;&gt;&lt;/a&gt;the dependent variable $\overset{\sim}\tau(\overset{\sim}t)$ one-dimensional (1D) smoothed &lt;strong&gt;time series including highly temporally correlated data&lt;/strong&gt;, and not a zero-dimensional scalar quantity $\rightarrow$ confidence intervals置信区间的定义和false positive rates (FPR)的控制需要correction&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; (for multiple comparisons that accounts for the temporal correlations in the input time series) $\rightarrow$ SPM1D software package&lt;/p&gt;
&lt;h5 id=&#34;sl&#34;&gt;SL&lt;/h5&gt;
&lt;p&gt;the null hypothesis: the mean profiles measured at the same speed for nominal and bio-feedback modulated SL conditions were not different from one another at any time point.&lt;/p&gt;
&lt;p&gt;two comparisons (ss vs. increased SL, and ss vs. decreased SL) per speed, per joint, for a total of $n_{comp} $= 30 pairwise comparisons.&lt;/p&gt;
&lt;p&gt;Pairwise comparisons: &lt;strong&gt;two-tailed paired t-tests&lt;/strong&gt; and defining thresholds t-scores for significance at α = 0.05 using a Bonferroni correction ($n = n_{comp}$) on the paired difference thresholds calculated by SPM1D.&lt;/p&gt;
&lt;h4 id=&#34;4-torque-pulse-approximation&#34;&gt;4. Torque pulse approximation&lt;/h4&gt;
&lt;p&gt;to approximate the effect of SL modulation on joint moment profiles with a series of rectangular pulses of torque. 用矩形脉冲的叠加拟合SL调整对关节运动的影响&lt;/p&gt;
&lt;p&gt;(a) the normalized difference $\Delta \overset{-}\tau(\overset{\sim}t)$ of subject specific average joint moment profiles $\tau(\overset{\sim}t)$ between conditions of positive or negative SL, and ss SL, at each gait speed $j$ :&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210520133648009.png&#34; alt=&#34;image-20210520133648009&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(b) rectangular torque pulses $P_{\pm}(\overset{\sim}t)$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210520134046479.png&#34; alt=&#34;image-20210520134046479&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这个工作中$N=1,2$（即进行两种脉冲近似）; 非线性规划求出$a_l,A_l$ ($min$ &lt;img src=&#34;https://K7288.github.io/assets/image-20210520145659319.png&#34; alt=&#34;image-20210520145659319&#34; style=&#34;zoom:43%;&#34; /&gt;)，根据$A_l$（矩形脉冲的振幅）正/负方向分成两组&lt;/p&gt;
&lt;p&gt;(c) to identify pulse magnitude and location&lt;/p&gt;
&lt;p&gt;统计学分析joint, direction of SL modulation, and sign of applied pulse是否significantly modulate pulse magnitude(absolute value of pulse amplitude) and location $\leftarrow$ 独立的线性混合效应模型SAS V9.4, SAS Institute, Cary, NC（包括每个因变量独立带来的effect/两个之间/三者相互带来的effect）&lt;/p&gt;
&lt;p&gt;Heterogeneity due to trials completed under different gait speed conditions, and multiple pulses in the case of the two pulse approximation were accounted for by the inclusion of random effects. Correlation between multiple measurements taken on the same subject were accounted for by the inclusion of a repeated measure effect.
Upon comparing nested model Akaike information criterion (AIC) values, the lowest AIC value came from the unstructured covariance structure and was therefore selected for the final models.&lt;/p&gt;
&lt;p&gt;(d) 若证明了(c)统计学显著性($\alpha&amp;lt;0.05$)，进一步 &lt;strong&gt;post hoc Tukey-Kramer tests&lt;/strong&gt; ($\alpha=0.05$)&lt;/p&gt;
&lt;p&gt;1️⃣ for the joint and SL modulation interaction，用于确定在调整SL时关节间pulse magnitude means的显著差异&lt;/p&gt;
&lt;p&gt;2️⃣ 图基事后检验法把three-way interaction between joint, SL modulation, and pulse sign分解to find the significant differences between torque pulse location, for a given joint, under different combinations of factors SL modulation and torque pulse sign.&lt;/p&gt;
&lt;p&gt;3️⃣ 对于每个关节，比较测量positive pulse torque sign and positive SL modulation的 location variables和negative negative; 比较positive negative和negative positive（找到施加torque pulse的正负与SL调整方向相关的时刻）&lt;/p&gt;
&lt;p&gt;(e) 可视化：location histograms；按关节、SL modulation condition分组；（为方便表示，直方图中根据sign of pulse amplitude的正负和magnitude是否大于均值分组）&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;h3 id=&#34;protocol-validation&#34;&gt;Protocol validation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g002&amp;amp;type=large&#34; alt=&#34;Fig 2&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;(Left) the distribution of mean Froude numbers with 95% confidence intervals at the various treadmill imposed GSs, (center) normalized stride lengths measured at various speeds and biofeedback conditions.&lt;/p&gt;
&lt;p&gt;The box plot shows the median as a horizontal line, and the box at 25% and 75% percentiles, with whiskers extending to ±3&lt;em&gt;σ&lt;/em&gt;, and (right) mean trailing limb angle and mean normalized stride length for each of the 15 conditions for each of the 20 subjects. Linear regression indicates that there is a strong correlation (r = 0.87) between the two measures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;The use of the Froude did not reduce the across-subject variability in ss-GS($CV_{ss-GS}=0.104&amp;lt;CV_{Fr}=0.106&amp;lt;CV_{ss-GS_0}=0.121$)All differences account for an effect size that can be considered very small.&lt;/li&gt;
&lt;li&gt;$\sigma_{max}$ of $SL_0$ values for all five non-
feedback conditions, averaged across all subjects, was relatively small (3.86%)&lt;/li&gt;
&lt;li&gt;$\Rightarrow$ conclude that the protocol &lt;strong&gt;significantly modulated&lt;/strong&gt; values of SL and GS, such that &lt;strong&gt;statistical analysis may be performed&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;linear regression: a strong correlation
(r = 0.87) between $SL_0$ and TLA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5GS 3SL 下的$\overset{-}\tau$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g003&amp;amp;type=large&#34; alt=&#34;Fig 3&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Effect of gait speed (GS) and stride length (SL) modulation on the normalized joint moments $\overset{-}\tau$.&lt;/p&gt;
&lt;p&gt;Joints are organized by row, GS are organized by columns, relative to the subject-specific ss-GS. Conditions corresponding to cued SL values are superimposed on each plot. Lines indicate the group mean, with the shaded region indicating the standard error.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;continuum-analysis&#34;&gt;Continuum analysis&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g004&amp;amp;type=large&#34; alt=&#34;Fig 4&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Main effects of gait speed (GS) and stride length (SL), and of their interaction, on the normalized joint moment profiles during normal walking, as described by the 1D time series of F-statistic extracted by the 2-way repeated measure ANOVA.&lt;/p&gt;
&lt;p&gt;The threshold F statistic for each experimental condition is reported by the red dashed line, and values above (shaded in green) correspond to a significant group effect of the factor, at the corresponding gait cycle instant, for a corrected type I error rate &lt;em&gt;α&lt;/em&gt; &amp;lt; 0.05.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g005&amp;amp;type=large&#34; alt=&#34;Fig 5&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g006&amp;amp;type=large&#34; alt=&#34;Fig 6&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g007&amp;amp;type=large&#34; alt=&#34;Fig 7&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;T-statistic resulting from pairwise comparisons of normalized hip(knee, ankle) torque moment at normal and modulated SL (columns), measured at the same GS, for each GS (row).&lt;/p&gt;
&lt;p&gt;Red dashed lines show the threshold &lt;em&gt;t&lt;/em&gt; value that provides a corrected type I error rate &lt;em&gt;α&lt;/em&gt; = 0.05, extracted using a Bonferroni correction that accounts for all pairwise comparisons $n_{comp}$ = 30.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;torque-pulse-approximation&#34;&gt;Torque pulse approximation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g008&amp;amp;type=large&#34; alt=&#34;Fig 8&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g009&amp;amp;type=large&#34; alt=&#34;Fig 9&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Histogram of one(two) pulse approximation normalized amplitudes, sorted by SL modulation and joint.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g010&amp;amp;type=large&#34; alt=&#34;Fig 10&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g011&amp;amp;type=large&#34; alt=&#34;Fig 11&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pulse magnitude by joint and SL modulation for the one(two) pulse approximation (mean ± standard deviation).&lt;/p&gt;
&lt;p&gt;Asterisks indicate pairwise comparisons significant at the &lt;em&gt;p&lt;/em&gt; &amp;lt; 0.05 corrected level.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g012&amp;amp;type=large&#34; alt=&#34;Fig 12&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.g013&amp;amp;type=large&#34; alt=&#34;Fig 13&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Histogram of one(two) pulse approximation locations in gait cycle, sorted by pulse amplitude sign and magnitude.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t001&amp;amp;type=large&#34; alt=&#34;Table 1&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Magnitude linear mixed effects model results for the one torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t002&amp;amp;type=large&#34; alt=&#34;Table 2&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Magnitude linear mixed effects model results for the two torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t003&amp;amp;type=large&#34; alt=&#34;Table 3&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Magnitude Tukey-Kramer post hoc test results for the one torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t004&amp;amp;type=large&#34; alt=&#34;Table 4&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Magnitude Tukey-Kramer post hoc test results for the two torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t005&amp;amp;type=large&#34; alt=&#34;Table 5&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Location linear mixed effects model results for the one torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t006&amp;amp;type=large&#34; alt=&#34;Table 6&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Location linear mixed effects model results for the two torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t007&amp;amp;type=large&#34; alt=&#34;Table 7&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Location Tukey-Kramer post hoc testing for the one torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/journal.pone.0200862.t008&amp;amp;type=large&#34; alt=&#34;Table 8&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Location Tukey-Kramer post hoc testing for the two torque pulse approximation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;gait speed&lt;/strong&gt; has a significant effect on the moment profiles in &lt;strong&gt;all joints&lt;/strong&gt; considered；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;stride length&lt;/strong&gt; has more localized effects on the &lt;strong&gt;knee moment during stance, and smaller effects observed for the hip joint moment during swing and ankle moment during the loading response&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TLA&lt;/strong&gt; Trailing limb angle, a parameter of interest in programs targeting propulsion at push-off, &lt;strong&gt;significantly correlated with stride length&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;candidate assistance strategies 不同phase不同关节给相应力矩&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitsfurther-work&#34;&gt;Limits/Further Work&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;本工作基于群体分析，在具体应用时需要针对个体&lt;/li&gt;
&lt;li&gt;本工作基于假设：外骨骼施加辅助力矩时人对行动的贡献不会改变；而事实上人非线性；需要迭代优化&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;//第一篇完整看完的生物统计的工作，想学习分析流程和思路，所以记得很详细，也花了不少时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验对象的描述可参考（健康状态、招募途径、对课题的了解、知情同意书格式、被试统计数据、实验时的衣着情况）：&lt;/p&gt;
&lt;p&gt;Subjects 20 healthy adults (10 males, 10 females) were recruited to participate in this study (protocol approved by the University of Delaware Institutional Review Board, protocol no. 619724). Subjects—age (mean ± std) 21.55 ± 2.50 yrs, height 1.73 ± 0.08 m, body mass 69.20 ± 8.73 kg— were naive to the purpose of the study, and free of orthopedic or neurological disorders affecting walking function. Subjects were required to wear their own comfortable athletic shoes and lightweight clothing for the walking experiment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1-%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86&#34; &gt;数据处理&lt;/a&gt;过程可参考&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;统计学&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;null hypothesis&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#2-validation-protocol&#34; &gt;参数的无量纲处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#series&#34;&gt;对包含时间相关性数据的时序信息的处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;使用到的函数和模型（repeated-measure 2-way ANOVA, SAS V9.4, SAS Institute, Cary, NC, post hoc Tukey-Kramer tests）&lt;/li&gt;
&lt;li&gt;对不同步速下实验异质性和同一被试多次测量之间的相关性的说明：Heterogeneity due to trials completed under different gait speed conditions, and multiple pulses in the case of the two pulse approximation were accounted for by the inclusion of random effects. Correlation between multiple measurements taken on the same subject were accounted for by the inclusion of a repeated measure effect.
Upon comparing nested model Akaike information criterion (AIC) values, the lowest AIC value came from the unstructured covariance structure and  was therefore selected for the final models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TODO&lt;/strong&gt; 注意$F_r=GS/\sqrt{L_lg}$与不同subjects&lt;a class=&#34;link&#34; href=&#34;#2-protocol-validation&#34; &gt;动力学相似性&lt;/a&gt;的关系，可以进一步看看参考文献&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Bowden MG, Balasubramanian CK, Neptune RR, Kautz SA. Anterior-Posterior Ground Reaction Forces as a Measure of Paretic Leg Contribution in Hemiparetic Walking. Stroke. 2006; 37:872–877. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1161/01.STR.0000204063.75779.8d&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1161/01.STR.0000204063.75779.8d&lt;/a&gt; PMID: 16456121&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Peterson CL, Cheng J, Kautz SA, Neptune RR. Leg extension is an important predictor of paretic leg propulsion in hemiparetic walking. Gait &amp;amp; Posture. 2010; 32(4):451–456. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2010.06.014&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.gaitpost.2010.06.014&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Kramer PA, Sarton-Miller I. The energetics of human walking: Is Froude number (Fr) useful for meta- bolic comparisons? Gait &amp;amp; Posture. 2008; 27(2):209–215. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.gaitpost.2007.03.009&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.gaitpost.2007.03.009&lt;/a&gt; PMID: 17459708; Alexander R. The gaits of bipedal and quadrupedal animals. The International Journal of Robotics Research. 1984;.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Pataky TC, Vanrenterghem J, Robinson MA. The probability of false positives in zero-dimensional analyses of one-dimensional kinematic, force and EMG trajectories. Journal of Biomechanics. 2016; 49 (9):1468–1476. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.jbiomech.2016.03.032&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.jbiomech.2016.03.032&lt;/a&gt; PMID: 27067363&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Menu</title>
        <link>https://K7288.github.io/posts/menu/</link>
        <pubDate>Sun, 16 May 2021 10:35:13 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/menu/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e5%ae%9e%e7%8e%b0%e9%a1%b5%e5%86%85%e8%b7%b3%e8%bd%ac&#34; &gt;实现页内跳转&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e5%9f%ba%e6%9c%ac%e8%af%ad%e6%b3%95&#34; &gt;基本语法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b3%a8%e6%84%8f%e4%ba%8b%e9%a1%b9&#34; &gt;注意事项&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#a-subtitle-just-for-test&#34; &gt;A subtitle just for test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b5%8b%e8%af%95-a-a&#34; &gt;测试 a A&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b5%8b%e8%af%95%e6%b5%8b%e8%af%95&#34; &gt;测试——测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b5%8b%e8%af%95%e4%b8%80%e4%b8%aa%e6%b5%8b%e8%af%95&#34; &gt;测试:一个测试&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#1%e6%b5%8b%e8%af%95&#34; &gt;1.测试&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%e7%9b%ae%e5%bd%95%e5%ae%9e%e7%8e%b0&#34; &gt;目录实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现页内跳转&#34;&gt;实现页内跳转&lt;/h2&gt;
&lt;h3 id=&#34;基本语法&#34;&gt;基本语法&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;[&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;提示语&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;](#&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;目标内容&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;注意事项&#34;&gt;注意事项&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;若标题是英文，在&lt;code&gt;(#&amp;lt;目标内容&amp;gt;)&lt;/code&gt;中需要小写&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#a-subtitle-just-for-test&#34; &gt;例如&lt;/a&gt; &lt;code&gt;[例如](#a-subtitle-just-for-test)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若标题中出现空格，需要用&lt;code&gt;-&lt;/code&gt;连接&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b5%8b%e8%af%95-a-a&#34; &gt;例如&lt;/a&gt; &lt;code&gt;[例如](#测试-a-a)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;(#&amp;lt;目标内容&amp;gt;)&lt;/code&gt;中不能出现半角点(即英文中的句号)&lt;code&gt;.&lt;/code&gt;，似乎也不支持其他标点，&lt;code&gt;(#&amp;lt;目标内容&amp;gt;)&lt;/code&gt;中需要将标点删除&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b5%8b%e8%af%95%e4%b8%80%e4%b8%aa%e6%b5%8b%e8%af%95&#34; &gt;测试:一个测试&lt;/a&gt; &lt;code&gt;[测试:一个测试](#测试一个测试)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1%e6%b5%8b%e8%af%95&#34; &gt;1.测试&lt;/a&gt; &lt;code&gt;[1.测试](#1测试)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%e6%b5%8b%e8%af%95%e6%b5%8b%e8%af%95&#34; &gt;测试——测试&lt;/a&gt; &lt;code&gt;[测试——测试](#测试测试)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;a-subtitle-just-for-test&#34;&gt;A subtitle just for test&lt;/h3&gt;
&lt;h3 id=&#34;测试-a-a&#34;&gt;测试 a A&lt;/h3&gt;
&lt;h4 id=&#34;测试测试&#34;&gt;测试——测试&lt;/h4&gt;
&lt;h4 id=&#34;测试一个测试&#34;&gt;测试:一个测试&lt;/h4&gt;
&lt;h3 id=&#34;1测试&#34;&gt;1.测试&lt;/h3&gt;
&lt;h2 id=&#34;目录实现&#34;&gt;目录实现&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;VS code插件 Markdown All in One
&lt;ul&gt;
&lt;li&gt;ctrl+shift+p&lt;/li&gt;
&lt;li&gt;Markdown All in One: Create Table of Contents&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TOD0 实现侧边目录&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;😂 已经出现了对“测”的完型崩坏&lt;/p&gt;
</description>
        </item>
        <item>
        <title>步速估计综述整理</title>
        <link>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</link>
        <pubDate>Wed, 12 May 2021 22:17:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</guid>
        <description>&lt;h2 id=&#34;toward-pervasive-gait-analysis-with-wearable-sensors-a-systematic-review&#34;&gt;Toward Pervasive Gait Analysis With Wearable Sensors: A Systematic Review&lt;/h2&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;对当前的定量步态分析技术进行系统的综述，并提出关键指标，来评估&lt;strong&gt;现有的通过可穿戴传感器提取步态特征的方法&lt;/strong&gt;。它旨在突出这一快速发展的研究领域中的关键进展，并概述研究和临床应用的潜在未来方向。&lt;/p&gt;
&lt;h3 id=&#34;section-iii-methods-for-extracting-relevant-gait-features-from-wearable-sensors&#34;&gt;SECTION III. Methods for Extracting Relevant Gait Features From Wearable Sensors&lt;/h3&gt;
&lt;p&gt;A.文献检索&lt;/p&gt;
&lt;p&gt;B. Kinematics&lt;/p&gt;
&lt;p&gt;Kinematic information is a well-established set of gait measures in biomechanical analysis.&lt;/p&gt;
&lt;p&gt;从惯性传感器获取运动学信息似乎很直观，但是要获得关于人体运动学的准确空间信息仍然很困难：全局失准和integration drift&lt;/p&gt;
&lt;p&gt;C.时序特征&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;D.利用惯性传感器的步速提取&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Laudanski &lt;em&gt;et al.&lt;/em&gt; [104] reviewed the current research (16 papers in total) on gait speed estimation using inertial sensors, classifying the current gait speed estimation model into three categories: abstraction model (i.e., machine learning approach), human gait model, and numerical integration, shown in Fig. 5.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;S. Chen and J. Lach, &amp;ldquo;Nonlinear feature for gait speed estimation using inertial sensors&amp;rdquo;, &lt;em&gt;Proc. 8th Int. Conf. Body Area Netw.&lt;/em&gt;, pp. 185-188, 2013.利用了生物力学提出了新的特征，自动特征选择算法&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/chen5-2608720-large.gif&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;E. Novel Features Extracted Using Nonlinear Analysis Techniques 步态稳定性和步态复杂性等&lt;/p&gt;
&lt;p&gt;F. Kinetics and Muscle Activity&lt;/p&gt;
&lt;p&gt;从惯性传感器提取步态特征&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/chen7-2608720-large.gif&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;从鞋垫压力传感器和EMG传感器提取步态特征&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/chen8-2608720-large.gif&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-length-estimation-methods-based-on-inertial-sensors-a-review&#34;&gt;Step Length Estimation Methods Based on Inertial Sensors: A Review&lt;/h2&gt;
&lt;p&gt;//根据Perry经典的阶段模型，利用传感器的时序信号可以进行步态周期的划分，可以估算出步频，使得步速可以推导出步幅。&lt;/p&gt;
&lt;p&gt;由此步速和步幅/步长的估算类似。&lt;/p&gt;
&lt;h2 id=&#34;deep-learning-for-monitoring-of-human-gait-a-review&#34;&gt;Deep Learning for Monitoring of Human Gait: A Review&lt;/h2&gt;
</description>
        </item>
        <item>
        <title>基于几何与物理特征融合的智能下肢假肢运动意图识别</title>
        <link>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</link>
        <pubDate>Wed, 12 May 2021 20:52:44 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</guid>
        <description>&lt;p&gt;基于几何与物理特征融合的智能下肢假肢运动意图识别Movement intention recognition of intelligent lower limb prosthesis based on the fusion of geometric and physical features&lt;/p&gt;
&lt;p&gt;intention定义—locomotion modes 5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡，8类转换模式&lt;/p&gt;
&lt;h2 id=&#34;research-question&#34;&gt;Research question&lt;/h2&gt;
&lt;p&gt;将&lt;strong&gt;关节角表示的几何特征&lt;/strong&gt;与&lt;strong&gt;加速度、角速度表示的物理特征&lt;/strong&gt;有机融合并应用于智能下肢假肢的运动意图识别&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;传统的意图识别方法所用传感器数量及种类较多, 特征向量维数偏高, 统计特征对短时样本具有不稳定性（在1.3 特征选择与提取有公式证明）。related work没有结合几何和物理。&lt;/p&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;采样：健侧大腿、小腿惯性测量单元于&lt;strong&gt;摆动相前期&lt;/strong&gt;所产生的运动&lt;strong&gt;时序数据&lt;/strong&gt;作为样本；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据处理：移动平均滤波器滤波去噪&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特征提取：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;几何特征：根据两个传感器的加速度、角速度计算一维的膝关节角，FDA方法提取最值斜率&lt;/li&gt;
&lt;li&gt;物理特征：加速度、角速度的均值、方差&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;均值、方差、最值斜率融合构成25维的特征基构建特征向量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SVM分类&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210512213113697.png&#34; alt=&#34;image-20210512213113697&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;13种日常行为进行分类。实验结果：对5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡的识别率达到96.9%, 对8类转换模式的识别率达到97.1%, 对13 种模式的识别率为94.3%。&lt;/p&gt;
&lt;h2 id=&#34;highlights&#34;&gt;Highlights&lt;/h2&gt;
&lt;p&gt;减少了传感器的数量及种类, 降低 了特征向量的维数降低了算法复杂度且避免了滞后性问题, 用加速度、 角速度及膝关节角三个参数共同对人体下肢运动的运动学特点进行表征。&lt;/p&gt;
&lt;p&gt;在特征的提取上, 将FDA方法与统计方法相结合, 弥补了仅提取统计特征的不稳定性问题。&lt;/p&gt;
&lt;h2 id=&#34;limitsfurther-work&#34;&gt;Limits/Further Work&lt;/h2&gt;
&lt;p&gt;对于13种动作的识别率有待提高, 后期工作会集中于对类间相似性相对较强较难区分的动作进行分类, 如: 下楼与下坡, 走到下楼 与走到下坡等. 此外, 关节角度是一个可深度挖掘的几何信息, 如: 除膝关节外的髋关节与踝关节对下肢假肢运动意图中的作用有待进一步探究. 最后, 在分类策略如分类器上, 依然有改进的空间.&lt;/p&gt;
&lt;h2 id=&#34;thoughtscomments&#34;&gt;Thoughts/Comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;项目申报相关：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;统计方法不稳定可以作为采用多种方式的依据。&lt;/li&gt;
&lt;li&gt;联想到选题中“特征提取”，对“特征”的理解更清晰了。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;本文特征提取：选定一个phase的时序信号，均值方差；那么可以用其他phase做类似处理得到更多指标，而不仅仅依赖原有数据。&lt;strong&gt;TODO 本文的去噪和特征工程方法可以参考。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;了解了提取关节角的方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210512214045937.png&#34; alt=&#34;image-20210512214045937&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt; 具体公式待后续整理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据行文是通过“实时传输解决滞后性问题解决”，是这样吗，主要矛盾是这里吗，那related work为什么不试试实时？后面可以看一下别人为什么会有滞后性问题&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;仅是识别（分类），没有提到识别后如何基于意图进行控制。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Gait Analysis Systems</title>
        <link>https://K7288.github.io/posts/gait-analysis-systems/</link>
        <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/gait-analysis-systems/</guid>
        <description>&lt;p&gt;&lt;em&gt;&amp;ldquo;Section Four - Gait Analysis Systems&amp;rdquo; from Gait Analysis: Normal and Pathological Function&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Basically, there are 5 measurement systems.&lt;/p&gt;
&lt;p&gt;Three of these focus on the specific events that constitute the act of walking.&lt;/p&gt;
&lt;p&gt;行走各个阶段&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Motion analysis defines the magnitude and timing of individual joint action.&lt;/li&gt;
&lt;li&gt;Dynamic electromyography iden­tifies the period and relative intensity of muscle function.&lt;/li&gt;
&lt;li&gt;Force plate recordings display the functional demands being experienced during the weight-bearing period.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The two remaining gait analysis technics summarize the effects of the person&amp;rsquo;s gait mechanics.&lt;/p&gt;
&lt;p&gt;行走整体效果&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;overall walking capability, one measures the patient&amp;rsquo;s stride char­acteristics&lt;/li&gt;
&lt;li&gt;efficiency revealed by energy cost&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;span-idjumpmotion-analysis-运动分析span&#34;&gt;&lt;span id=&#34;jump&#34;&gt;Motion analysis 运动分析&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Problems: the technical challenge of making the necessary measurements; the effect of out-of-plane movement on the amount of sagittal motion that is perceived.&amp;mdash;&amp;gt;placing a goniometer(测角仪) on the limb and using three-dimensional camera recording&lt;/p&gt;
&lt;p&gt;获取数据$\rightarrow$标注关节&lt;/p&gt;
&lt;p&gt;中立位确定（根据解剖学by the American Academy of Orthopaedic Surgeons）以及关节骨骼旋转方向正负的定义见原书&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;p374&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510113634602.png&#34; alt=&#34;image-20210510113634602&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Reference scales. The direction for graphing each motion of the individual joint is identified. &amp;ldquo;0&amp;rdquo; represents the &lt;strong&gt;neutral position for the motion&lt;/strong&gt;. Vertical axis indicates magnitude of motion. Arrow denotes increasing values for each direction. Horizontal axis represents the gait cycle time scale.&lt;/p&gt;
&lt;h3 id=&#34;motion-data-interpretation&#34;&gt;Motion Data Interpretation&lt;/h3&gt;
&lt;p&gt;The minimum information available from a motion record is the magnitude of the &lt;strong&gt;peak angles (high and low) experienced by the joint&lt;/strong&gt; being studied.&lt;/p&gt;
&lt;p&gt;通过峰值划分motion，和正常状态下相比较（1️⃣magnitudes of joint motion 2️⃣ timing of the action 3️⃣ coordinating the motion patterns of the adjacent joints）&lt;/p&gt;
&lt;h2 id=&#34;dynamic-electromyography-肌肉控制与动态肌电图&#34;&gt;Dynamic Electromyography 肌肉控制与动态肌电图&lt;/h2&gt;
&lt;h3 id=&#34;emg-quantification-肌电图量化&#34;&gt;EMG Quantification 肌电图量化&lt;/h3&gt;
&lt;p&gt;Manual (or descriptive); Electronic summation of the EMG signals; Computer quantification&lt;/p&gt;
&lt;p&gt;采样频率2500Hz 但数据过多，一般取1000或500Hz&lt;/p&gt;
&lt;p&gt;数字化，对信号进行全波整流（避免正负值在后续处理中相互抵消。整流包括将所有的负信号转置到零线的正侧）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510191558532.png&#34; alt=&#34;image-20210510191558532&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;在一个适合的时间间隔进行累加；0.01秒interval(大约1% GC)被发现是最好的;3% interval: less variability in the EMG wave&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510190913473.png&#34; alt=&#34;image-20210510190913473&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;归一化技术：将每个电极的功能数据作为参考值将同一电极产生的值转化为比率(通常以百分比表示)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510193311199.png&#34; alt=&#34;image-20210510193311199&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;adjusting the onset and cessation times of the individual quantified records to match the mean timing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510193906326.png&#34; alt=&#34;image-20210510193906326&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;emg-interpretation&#34;&gt;EMG Interpretation&lt;/h3&gt;
&lt;p&gt;timing与运动相 phases有关 用于判断当前运动状态&lt;/p&gt;
&lt;p&gt;Relative Effort 运动越用力，振幅变大，图形密集&lt;/p&gt;
&lt;p&gt;EMG和force相互推导&lt;/p&gt;
&lt;h2 id=&#34;ground-reaction-force-and-vector-analysis-步态动力学地反力向量力矩功率和压力&#34;&gt;Ground Reaction Force and Vector Analysis 步态动力学——地反力、向量、力矩、功率和压力&lt;/h2&gt;
&lt;p&gt;ground reaction forces (GRF)&lt;/p&gt;
&lt;h3 id=&#34;vertical-load&#34;&gt;Vertical Load&lt;/h3&gt;
&lt;h4 id=&#34;characteristics&#34;&gt;Characteristics&lt;/h4&gt;
&lt;p&gt;Normal stance phase pattern of vertical forces generated by the customary walking speed of &lt;u&gt;82m/ min&lt;/u&gt; has &lt;strong&gt;two peaks separated by a valley&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The force on the force plate changes with changing vertical acceleration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510155906470.png&#34; alt=&#34;image-20210510155906470&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;峰值值约为体重的110%，而谷值力约为体重的80%。第一个峰(F1)发生在MS的开始，此时身体的重心正在迅速下降。在MS后期，谷值(F2)是由身体向前滚过静止的脚时重心上升造成的。第二个峰值(F3)出现在TS后期，再次表明身体重心向前落在TS的前足上时重心下降。&lt;/p&gt;
&lt;h4 id=&#34;vertical-force--speed&#34;&gt;Vertical force &amp;amp; Speed&lt;/h4&gt;
&lt;p&gt;v减小，峰谷更平坦，反之亦然。&lt;/p&gt;
&lt;p&gt;The magnitude of the vertical force changes with variations in gait speed. Walking at slower speeds (&amp;lt;60m/min) reduces the momentum, and therefore the vertical acceleration, with a corresponding decrease in both the peaks and valley deviations from body weight.&lt;/p&gt;
&lt;p&gt;Conversely, fast walking speeds induce higher peaks and lower valleys. Running registers peaks 2.5 times body weight.&lt;/p&gt;
&lt;h3 id=&#34;horizontal-shear&#34;&gt;Horizontal Shear&lt;/h3&gt;
&lt;p&gt;The forces generated parallel to the wa1king surface are called shear.&lt;/p&gt;
&lt;p&gt;Horizontal forces in the anterior-posterior (AP) plane: the ground reaction force vector deviates from the vertical.&lt;/p&gt;
&lt;p&gt;Horizontal medial-lateral (ML  内侧 外侧 ) shear forces: the exchange of body weight from one limb to the&lt;/p&gt;
&lt;p&gt;ML force is least, being less than 10% of body weight. Peak medial shear (5% BW) occurs in mid loading response. Lateral shear reaches a peak (7% BW) in terminal stance.&lt;/p&gt;
&lt;p&gt;The AP shear force (also called fore-aft forces) is equivalent to less than 25%of body weight. At initial contact there often is a momentary aft shear (13% BW).&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Loading&lt;/u&gt; the limb rapidly introduces an &lt;u&gt;anteriorly directed force&lt;/u&gt;, which reaches a peak (13% BW) at the end of the loading response phase. This is not sustained.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Mid stance&lt;/u&gt; is an interval with minimal sagittal shear until just before heel rise, when a &lt;u&gt;posterior shear begins&lt;/u&gt;. There is a rapid rise in the &lt;u&gt;posterior force&lt;/u&gt; throughout &lt;u&gt;terminal stance&lt;/u&gt;, with a final peak equaling 23%BW.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510155411118.png&#34; alt=&#34;image-20210510155411118&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;⬆️ Normal ground reaction force pattern during stance.
(a) Vertical force; (b) Lateral shear (horizontal); (c) Progressional shear (horizontal fore/aft).&lt;/p&gt;
&lt;h3 id=&#34;vectors&#34;&gt;Vectors&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510163811792.png&#34; alt=&#34;image-20210510163811792&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;joint-torques&#34;&gt;Joint Torques&lt;/h3&gt;
&lt;p&gt;Torque is defined as the product of the force and its lever arm T = FxL. The lever (or moment arm) for the joint torque presented by the body&amp;rsquo;s posture is the perpendicular distance between the line of action of the vector and the center of the joint. The vertical ground reaction is the determining force in stance. By combining motion and vector data the torques occurring throughout the stride can be calculated. Sagittal plane data define the flexion and extension torques. Coronal plane measurements identify the abduction and adduction demands. Transverse moments (torques) are calculated by combin­ing the fore-aft and mediolateral values.
Calculation of joint torques from the vector and motion data, as just described, is technically easier, but the effects of gravity and inertia are not included. Studies comparing moment calculations with and without consider­ing the gravitational and inertial factors have shown no difference in the ankle data, but at the hip and knee there were intervals in the gait cycle where the simple vector data registered higher values The investigators have differed on the significance of these findings. Bressler and Frankel noted a brief increase in both the knee and hip values at the beginning loading response of approximately 20% and a similar difference in terminal stance for the hip. Mikosz et al noted the exaggeration of the sagittal knee and hip torques (expressed in units of percent body weight X stature) was 1 % each. These two groups of authors concluded that for most situations, use of the unmodified vector data was adequate. Wells , in contrast, felt the omission of the While very significant for understanding the logic of muscular action, the resulting numbers tend to be too abstract for most clinicians.&lt;/p&gt;
&lt;p&gt;自重会带来影响但部分研究人员认为可以忽略。&lt;/p&gt;
&lt;h3 id=&#34;center-of-pressure-cp&#34;&gt;Center of Pressure C/P&lt;/h3&gt;
&lt;p&gt;base of the GRF vector lies within the foot, as that is the body segment in contact with the floor.&lt;/p&gt;
&lt;p&gt;While the word pressure is in common use, it is not correct, as the area of contact is not considered in the calculation. Center of support would be more accurate.&lt;/p&gt;
&lt;p&gt;Each C/P point represents the &lt;strong&gt;mean of the vertical forces on the four instrumented supporting posts of the force plate&lt;/strong&gt;. By also defining the location of the foot on the force plate, an anatomical correlation can be made. The center of pressure is related to the plantar outline of the foot, but its location &lt;strong&gt;does not necessarily identify that portion of the foot receiving the greatest pressure&lt;/strong&gt;. Only during the period of isolated heel support in loading response or the forefoot support interval in terminal stance will the C/P have any anatomical significance. Even then, the C/ P point represents an average of all the forces on either the heel or forefoot, not the site of maximum pressure.&lt;/p&gt;
&lt;p&gt;The C/P is located in an anatomical area that makes little or no contact with the floor. C/P位于一个解剖区域，很少或没有接触地板。&lt;/p&gt;
&lt;h3 id=&#34;intrinsic-foot-pressure&#34;&gt;Intrinsic Foot Pressure&lt;/h3&gt;
&lt;p&gt;To determine the pressures experienced by the different structures within the foot&lt;/p&gt;
&lt;h2 id=&#34;stride-characteristics-步幅分析&#34;&gt;Stride Characteristics 步幅分析&lt;/h2&gt;
&lt;p&gt;The natural mix of joint mobility, muscle strength, neural control and energy leads to a customary walk­ing speed, stride length and step rate. These time and distance factors, in combination with the swing and stance times, constitute the person&amp;rsquo;s stride characteristics.&lt;/p&gt;
&lt;p&gt;Normal persons, while able to voluntarily modify their gait velocity as needed, also have a 
spontaneous rate that is called either free or customary walking speed (CWS). This free rate of travel designates the optimum functional balance of the person&amp;rsquo;s physical qualities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Velocity = Stride Length x 0.5 Cadence&lt;/strong&gt;    Cadence (step rate)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510184307167.png&#34; alt=&#34;image-20210510184307167&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510184338275.png&#34; alt=&#34;image-20210510184338275&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510185340733.png&#34; alt=&#34;image-20210510185340733&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;normal-variability&#34;&gt;Normal Variability&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Normal adults&lt;/strong&gt; show a &lt;strong&gt;moderate variability&lt;/strong&gt; in their free walking velocity. One group of 60 subjects ages 20 to 65 years showed a 7% standard deviation during indoor testing following pretraining to a common cadence. Another 111 persons ages 20 to 80 tested on an outdoor track displayed a 4% deviation. Two identifiable sources of this variability are age and height (or limb length). 
Age&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A notable difference in velocity (14%) when arthritis and other disabilities are allowed as natural events.&lt;/li&gt;
&lt;li&gt;With healthy subjects the influence of age is less, but increases as years beyond 65 are added.&lt;/li&gt;
&lt;li&gt;The decrease in mean velocity was just 3% for a 60- to 65-year-old group. This increased to 9% when the study group included ages 60 to 80; significant decline in walking ability began after age 70 years.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Limb Length 
儿童中显著；成人腿长与步幅相关性不强($r^2$ = 0.21 ~ 0.28)&lt;/p&gt;
&lt;h3 id=&#34;voluntary-variability&#34;&gt;Voluntary Variability&lt;/h3&gt;
&lt;p&gt;Normal persons have a wide range of safe and relatively comfortable walking speeds.&lt;/p&gt;
&lt;p&gt;the changes in stride length and cadence were about equal. (of similar percentage)&lt;/p&gt;
&lt;p&gt;The standard deviations for normal free walking is approximately 10% of the mean value. The preceding data indicate 4% of this deviation is related to leg length. Age has no significance until the person is past 60 years. Thus, &lt;strong&gt;the larger factor appears to be spontaneous variability&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;energy-cost-能量消耗&#34;&gt;Energy Cost 能量消耗&lt;/h2&gt;
&lt;p&gt;与实验无关，暂略&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Perry, J.M. Burnfield Gait Analysis: Normal and Pathological Function(2nd ed.), SLACK Incorporated (2010)&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Gait Analysis Fundamentals</title>
        <link>https://K7288.github.io/posts/gait-analysis-fundamentals/</link>
        <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
        
        <guid>https://K7288.github.io/posts/gait-analysis-fundamentals/</guid>
        <description>&lt;h2 id=&#34;gait-analysis-步态分析简述1&#34;&gt;Gait analysis 步态分析简述&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;h3 id=&#34;factors-and-parameters-影响步态的因素&#34;&gt;Factors and parameters 影响步态的因素&lt;/h3&gt;
&lt;p&gt;The gait analysis is modulated or modified by many factors, and changes in the normal gait pattern can be transient or permanent. The factors can be of various types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extrinsic: such as terrain, footwear, clothing, cargo&lt;/li&gt;
&lt;li&gt;Intrinsic: sex, weight, height, age, etc.&lt;/li&gt;
&lt;li&gt;Physical: such as weight, height, physique&lt;/li&gt;
&lt;li&gt;Psychological: personality type, emotions&lt;/li&gt;
&lt;li&gt;Physiological: anthropometric characteristics, i.e., measurements and proportions of body&lt;/li&gt;
&lt;li&gt;Pathological: for example trauma, neurological diseases, musculoskeletal anomalies, psychiatric disorders&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;parameters-描述步态的参数&#34;&gt;Parameters 描述步态的参数&lt;/h3&gt;
&lt;p&gt;The parameters taken into account for the gait analysis are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Step length 步长&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stride length 步幅&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cadence 节奏(Step rate; xx steps per minute)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Speed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dynamic base&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Progression line 渐进线&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Foot angle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hip angle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Squat performance&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gait-parameters一种分类2&#34;&gt;gait parameters：一种分类&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
&lt;h4 id=&#34;joint-angles&#34;&gt;Joint angles&lt;/h4&gt;
&lt;h4 id=&#34;gait-eventsgait-phases&#34;&gt;Gait events/Gait phases&lt;/h4&gt;
&lt;p&gt;initial and end contact(most common)
(IC) initial contact; (LR) loading response; (MS) mid stance; (TS) terminal stance; (PS) pre-swing; (EC) end contact; (SW) swing&lt;/p&gt;
&lt;h4 id=&#34;spatiotemporal-parameters&#34;&gt;Spatiotemporal parameters&lt;/h4&gt;
&lt;p&gt;Stride Time , Step time, Stance time, Gait velocity, Cadence, Stride symmetry&lt;/p&gt;
&lt;h2 id=&#34;basic-sciences--anatomy-physiology-and-biomechanics&#34;&gt;Basic sciences – anatomy, physiology and biomechanics&lt;/h2&gt;
&lt;h3 id=&#34;anatomy&#34;&gt;Anatomy&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Term&lt;/th&gt;
&lt;th&gt;Figure&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;directions&lt;br&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;reference planes&lt;/td&gt;
&lt;td&gt;anterior posterior&lt;br&gt;superior inferior(&lt;em&gt;cephalad&lt;/em&gt;: towards the head and &lt;em&gt;caudad&lt;/em&gt;: towards the ‘tail’ )&lt;br/&gt;left right&lt;br/&gt;&lt;br/&gt;Medial 中间的 Lateral 侧向的&lt;br/&gt;Proximal 近端的  Distal 远端的&lt;br/&gt;Superficial  Deep&lt;br&gt;&lt;br/&gt;sagittal plane: &lt;u&gt;any&lt;/u&gt; plane which divides part of the body into right and left portions; the median plane is the midline sagittal plane.&lt;br&gt;frontal plane/coronal plane&lt;br&gt;transverse plane/horizontal plane&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814101819770.png&#34; alt=&#34;image-20210814101819770&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;movements&lt;/td&gt;
&lt;td&gt;Flexion 弯曲/屈曲 extension 伸张 in the sagittal plane&lt;br/&gt;Abduction 外展 and adduction 内收 in the frontal plane &lt;br/&gt;Internal/medial and external/lateral rotation in the transverse plane&lt;br&gt;&lt;br&gt;Ankle&lt;br/&gt;dorsiflexion 背屈 and plantarflexion 跖屈&lt;br/&gt;&lt;br/&gt;Varus 内翻 and valgus 外翻: an angulation of a joint towards or away from the midline(膝内翻 blow legs; 膝外翻 knock knees)&lt;br&gt;Pronation 内转 and supination 外转: rotations about the long axis of the forearm or foot; pronation of both hands brings the thumbs together, supination brings the little fingers together&lt;br&gt;Inversion of the feet brings the soles together; eversion causes the soles to point away from the midline.&lt;br/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814104803567.png&#34; alt=&#34;image-20210814104803567&#34;  /&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814104822712.png&#34; alt=&#34;image-20210814104822712&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;gait-analysis-three-basic-approaches3&#34;&gt;Gait Analysis: three basic approaches&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;p&gt;The simplest system subdivides the cycle accord­ing to the variations in reciprocal floor contact by the two feet. A second method uses the time and distance qualities of the stride. The third approach identifies the functional significance of the events within the gait cycle and designates these intervals as the functional phases of gait.&lt;/p&gt;
&lt;h3 id=&#34;gait-cycle-gc&#34;&gt;Gait cycle (GC)&lt;/h3&gt;
&lt;p&gt;One gait cycle (a single sequence of these functions by one limb) can be divided into two phases, &lt;strong&gt;stance&lt;/strong&gt; (&lt;strong&gt;ST&lt;/strong&gt;) and &lt;strong&gt;swing&lt;/strong&gt; (&lt;strong&gt;SW&lt;/strong&gt;), which can be subdivided into &lt;strong&gt;5 and 3 phases&lt;/strong&gt;, respectively.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stance&lt;/strong&gt; is the term used to designate the entire period during which &lt;strong&gt;the foot is on the ground&lt;/strong&gt;. Stance begins with initial contact.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;IC&lt;/strong&gt; initial contact 对于没有某一类型行走障碍的人来说就是 &lt;strong&gt;HS&lt;/strong&gt; heel strike.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Subdivided into &lt;strong&gt;3 intervals according to the sequence of floor contact by the two feet&lt;/strong&gt;. (根据两腿所在的运动相划分，与phase不同)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both the start and end of stance involve a period of bilateral foot contact with the floor (double stance; &lt;strong&gt;term &amp;ldquo;support&amp;rdquo; is avoided for an unequal sharing of body weight by the two feet&lt;/strong&gt;), while the middle portion of stance has one foot contact.&lt;/li&gt;
&lt;li&gt;Initial double stance/Loading response(10%) begins the gait cycle. It is the time both feet are on the floor after IC.&lt;/li&gt;
&lt;li&gt;Single limb support(40%) begins when the opposite foot is lifted for swing. (&lt;strong&gt;所以Swing和Single limb support占比相同&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Terminal double stance(10%) begins with floor contact by the other foot (contralateral initial contact) and continues until the original stance limb is lifted for swing (ipsilateral toe-off).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510082609418.png&#34; alt=&#34;image-20210510082609418&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210813202051514.png&#34; alt=&#34;image-20210813202051514&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Swing&lt;/strong&gt; applies to the time &lt;strong&gt;the foot is in the air for limb advancement&lt;/strong&gt;. Swing begins as the foot is lifted from the floor (toe-off).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510082507492.png&#34; alt=&#34;image-20210510082507492&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;gait-cycle--speed&#34;&gt;Gait Cycle ＆ Speed&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;total stance and swing times和速度负相关&lt;/strong&gt;；The &lt;strong&gt;change&lt;/strong&gt; in stance and swing times becomes &lt;strong&gt;progressively greater as speed slows&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Subdivisions of stance : &lt;strong&gt;速度与Single stance interval/Swing占比正相关&lt;/strong&gt;；&lt;strong&gt;curvilinear&lt;/strong&gt; pattern of change.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Having an interval when both feet are in contact with the ground for the limbs to exchange their support roles is a basic characteristic of walking. When double stance is omitted, the person has entered the running mode of locomotion.&lt;/p&gt;
&lt;h3 id=&#34;stride-and-step&#34;&gt;Stride and Step&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Stride&lt;/strong&gt; is the equivalent of a gait cycle. It is based on the actions of &lt;strong&gt;one limb&lt;/strong&gt;.The duration of a stride is the interval between two sequential initial floor contacts by the same limb (i.e., right IC and the next right IC).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step&lt;/strong&gt; refers to the &lt;strong&gt;timing between the two limbs&lt;/strong&gt;. There are two steps in each stride (or gait cycle). At the midpoint of one stride the other foot contacts the ground to begin its next stance period. The interval between an initial contact by each foot is a step (i.e., left and then right). The same offset in timing will be repeated in reciprocal fashion throughout the walk.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510085622226.png&#34; alt=&#34;image-20210510085622226&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;gait-phases&#34;&gt;Gait Phases&lt;/h3&gt;
&lt;h4 id=&#34;gait-events&#34;&gt;Gait events&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;IC&lt;/strong&gt; Initial contact 对于没有某一类型行走障碍的人来说就是 &lt;strong&gt;HS&lt;/strong&gt; heel strike.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OT&lt;/strong&gt; Opposite toe off&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HO/HR&lt;/strong&gt; Heel rise/off&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OI&lt;/strong&gt; Opposite initial contact&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TO&lt;/strong&gt; Toe off&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FA&lt;/strong&gt; Feet adjacent&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TV&lt;/strong&gt; Tibia vertical&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&amp;hellip;(FO foot off, FF foot flat)&lt;/p&gt;
&lt;h4 id=&#34;tasks&#34;&gt;Tasks&lt;/h4&gt;
&lt;p&gt;The phases of gait also provide a means for correlating the simultaneous actions of the individual joints into patterns of total limb function.  联系关节模式和运动&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Each of the eight gait phases has a functional objective and a critical pattern of selective synergistic motion to accomplish this goal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Weight acceptance (WA)&lt;/strong&gt; begins the stance period and uses the first two gait phases (&lt;strong&gt;IC&lt;/strong&gt; initial contact and &lt;strong&gt;LR&lt;/strong&gt; loading response).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single limb support  (SLS)&lt;/strong&gt; continues stance with the next two phases of gait (&lt;strong&gt;MSt&lt;/strong&gt; mid stance and &lt;strong&gt;TSt&lt;/strong&gt; terminal stance).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limb advancement(LA)&lt;/strong&gt; begins in the final phase of stance (pre-swing) and then continues through the three phases of swing (&lt;strong&gt;ISw&lt;/strong&gt; initial swing,&lt;strong&gt;MSw&lt;/strong&gt; midswing and &lt;strong&gt;TSw&lt;/strong&gt; terminal swing).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210510090047998.png&#34; alt=&#34;image-20210510090047998&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;7-gait-phases&#34;&gt;7 gait phases&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Stance&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Swing&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Loading response&lt;br&gt;Mid-stance&lt;br/&gt;Terminal stance&lt;br/&gt;Pre-swing&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Initial swing&lt;br/&gt;Mid-swing&lt;br/&gt;Terminal swing&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Phase&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Term&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Interval&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Figure(the reference limb shaded)&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Initial Contact (IC)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0-2%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814100252165.png&#34; alt=&#34;image-20210814100252165&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;hip flexed; knee extended; ankle  dorsiflexed to neutral. &lt;br&gt;The other limb at the end of terminal stance.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Loading response (LR)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0-10%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814095235166.png&#34; alt=&#34;image-20210814095235166&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;knee flexed with the heel as a rocker for shock absorption. Ankle plantar flexion limits the heel rocker by forefoot contact with the floor. &lt;br/&gt;The opposite limb in pre-swing phase.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Mid-stance (MSt)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10-30%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814113204808.png&#34; alt=&#34;image-20210814113204808&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;the first half of &lt;u&gt;single limb support&lt;/u&gt;; the limb advances over the stationary foot by ankle dorsifiexion (ankle rocker) while the knee and hip extend.&lt;br&gt;The opposite Iimb in its mid swing phase.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Terminal stance (TSt)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;30-50%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814113224324.png&#34; alt=&#34;image-20210814113224324&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;&lt;u&gt;the second half of single Iimb support&lt;/u&gt;, the heel rises and the Iimb advances over the forefoot rocker. The knee increases its extension and then just begins to flex slightly.Increased hip extension puts the Iimb in a more trailing position.&lt;br&gt;The other Iimb in terminal swing.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;4&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Pre-swing (PSw)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;50-60%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814113443337.png&#34; alt=&#34;image-20210814113443337&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;Floor contact by the other limb has started &lt;u&gt;terminal double support&lt;/u&gt;. The reference limb responds with increased ankle plantar flexion. greater knee flexion and loss of hip extension.&lt;br&gt;The opposite limb in Loading Response.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Initial swing (ISw)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;60-73%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814113452228.png&#34; alt=&#34;image-20210814113452228&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;The foot is lifted and limb advanced by hip flexion and increased knee flexion. The ankle only partially dorsiflexes.&lt;br&gt;The other limb in early mid-stance.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Mid-swing (MSw)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;73-87%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814113501863.png&#34; alt=&#34;image-20210814113501863&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;Advaneement of the limb anterior to the body weight line is gained by further hip flexion. The knee is allowed to extend in response to gravity while the ankle continues dorsiflexing to neutral.&lt;br&gt;The other limb in late mid-slance.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Terminal swing (TSw)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;87-100%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210814113510052.png&#34; alt=&#34;image-20210814113510052&#34;  /&gt;&lt;/td&gt;
&lt;td&gt;limb advancement is completed by knee extension. The hip maintains its earlier flexion. and the ankle remains dorsiflexed to neutral.&lt;br&gt;The other limb in terminal stance.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/image-20210813201955698.png&#34; alt=&#34;image-20210813201955698&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;stance-st-支撑相&#34;&gt;Stance ST 支撑相&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;首次触地期（initial contact，IC）&lt;/li&gt;
&lt;li&gt;承重反应期（loading response，LR）&lt;/li&gt;
&lt;li&gt;支撑相中期（mid stance, MSt）&lt;/li&gt;
&lt;li&gt;支撑相末期（terminal stance, TSt）&lt;/li&gt;
&lt;li&gt;摆动前期（pre-swing, PSw）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Corresponding to the beginning of the ST phase, the initial contact (IC) describes the moment when one part of the foot, in physiologic gait the heel, touches the ground. The loading response (LR) starts with the IC and ends with the contralateral toe-off. Subsequently, the mid stance (MS) lasts until the heel-off of the reference leg. The MS is followed by the terminal stance (TS), which ends with the contralateral IC. The ST phase terminates with the pre-swing (PS), which ends with the toe-off of the reference leg. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;swing-sw-摆动相&#34;&gt;Swing SW 摆动相&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;摆动相早期（initial swing，ISw）&lt;/li&gt;
&lt;li&gt;摆动相中期（mid swing，MSw）&lt;/li&gt;
&lt;li&gt;摆动相末期（terminal swing，TSw）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Considering the SW phase, the initial swing follows the PS and terminates when the ankle joint of the reference leg crosses the supporting leg. This phase is followed by the mid swing, which ends with the tibia of the reference leg being vertical to the ground. The gait cycle is concluded by the terminal swing, which ends with the initial contact of the reference leg.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://K7288.github.io/assets/1-s2.0-S0966636217302424-gr1.jpg&#34; alt=&#34;img&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;basic-functionslocomotor-functions&#34;&gt;Basic Functions(Locomotor Functions)&lt;/h3&gt;
&lt;p&gt;上身passenger 下面locomotor（涉及11个关节）&lt;/p&gt;
&lt;p&gt;As the locomotor unit carries the body to its desired location each weight-bearing limb accomplishes four distinct functions. (1) A propulsive force is generated. (2) Upright stability is maintained, despite an ever-changing posture. (3) The shock of floor impact at the onset of each stride is minimized. (4) Energy is conserved by these functions being performed in a manner that reduces the amount of muscular effort required (Table 3.1). The accomplish­ment of each function depends on a distinct motion pattern. Each represents a complex series of interactions between the body mass and the two multiseg­mented lower limbs. During walking these blend into a single, three-dimen­sional pattern.&lt;/p&gt;
&lt;p&gt;主要有4个Locomotor Functions: Propulsion, Stance Stability, Shock Absorption, Energy Conservation, 不同的function对应的重心位置和关节角不同，随phase的变化也不同，详见此书&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;p19-p47&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Gait_analysis#Markerless_gait_capture&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gait analysis wikipedia&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S0966636217302424&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Rafael Caldas, Marion Mundt, Wolfgang Potthast, Fernando Buarque de Lima Neto, Bernd Markert,A systematic review of gait analysis methods based on inertial sensors and adaptive algorithms,Gait &amp;amp; Posture,Volume 57,,2017&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Perry, J.M. Burnfield, Gait Analysis: Normal and Pathological Function(2nd ed.), SLACK Incorporated (2010)&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
        </item>
        <item>
        <title>Hugo Guide</title>
        <link>https://K7288.github.io/posts/hugo-guide/</link>
        <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/hugo-guide/</guid>
        <description>&lt;h2 id=&#34;about-contents&#34;&gt;About Contents&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Add Some Content&lt;/strong&gt; &lt;code&gt;hugo new post/**.md&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The newly created content file will start with something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;---
title: &amp;#34;**&amp;#34;
date: 2019-03-26T08:47:11+01:00
draft: true
---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Drafts do not get deployed; once you finish a post, update the header of the post to say &lt;code&gt;draft: false&lt;/code&gt;. More info &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/usage/#draft-future-and-expired-content&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;---
title: &amp;#34;Hugo Guide&amp;#34;
date: 2021-05-01T08:47:11+01:00
categories: [&amp;#34;Manual&amp;#34;]
tags: [&amp;#34;Hugo&amp;#34;, &amp;#34;GitHub&amp;#34;]
draft: false
---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Add pictures&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/post/xxx.jpg&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;is actually &lt;code&gt;baseURL/post/xxx.jpg&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Put the picture as below&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;.
└── static
    └── post
        └── xxx.jpg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;customize-the-theme&#34;&gt;Customize the Theme&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Start the Hugo server&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;▶ hugo server -D

                   | EN
+------------------+----+
  Pages            | 10
  Paginator pages  |  0
  Non-page files   |  0
  Static files     |  3
  Processed images |  0
  Aliases          |  1
  Sitemaps         |  1
  Cleaned          |  0

Total in 11 ms
Watching for changes in /Users/bep/quickstart/{content,data,layouts,static,themes}
Watching for config changes in /Users/bep/quickstart/config.toml
Environment: &amp;#34;development&amp;#34;
Serving pages from memory
Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)
Press Ctrl+C to stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Navigate to your new site at http://localhost:1313/.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Site Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Open up &lt;code&gt;config.toml&lt;/code&gt; in a text editor:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;baseURL = &amp;#34;http://K7288.github.io&amp;#34;
languageCode = &amp;#34;en-us&amp;#34;
title = &amp;#34;K7288&amp;#34;
theme = &amp;#34;stack&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;For further theme customization, see &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/themes/customizing/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Customize a Theme&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;build-static-pages&#34;&gt;Build static pages&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;hugo -D
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Output will be in &lt;code&gt;./public/&lt;/code&gt; directory by default (&lt;code&gt;-d&lt;/code&gt;/&lt;code&gt;--destination&lt;/code&gt; flag to change it, or set &lt;code&gt;publishdir&lt;/code&gt; in the config file).&lt;/p&gt;
&lt;p&gt;See Also&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/external-learning-resources/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;External Learning Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/hugo-modules/use-modules/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Use Hugo Modules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/usage/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Basic Usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/CaiJimmy/hugo-theme-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugo Theme Stack&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Math</title>
        <link>https://K7288.github.io/posts/math/</link>
        <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
        
        <guid>https://K7288.github.io/posts/math/</guid>
        <description>&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
e^{ix}=\text{cos}x+i\text{sin}x
$$&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\left(C_{n+1, t+1}-C_{n, t}\right)-\left(C_{n, t+1}-C_{n-1, t}\right)=\frac{2}{n+1}
$$&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\begin{aligned} 
C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2}
+C_{t+1, t+1}-C_{t, t} \\ 
&amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) 
\end{aligned}
$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Latex&#34; data-lang=&#34;Latex&#34;&gt;&lt;span class=&#34;k&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;aligned&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; 
C&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;n+1, t+1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;-C&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;n, t&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;&amp;amp;&lt;/span&gt;=&lt;span class=&#34;k&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;2&lt;span class=&#34;nb&#34;&gt;}{&lt;/span&gt;n+1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;+&lt;span class=&#34;k&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;2&lt;span class=&#34;nb&#34;&gt;}{&lt;/span&gt;n&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;+&lt;span class=&#34;k&#34;&gt;\cdots&lt;/span&gt;+&lt;span class=&#34;k&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;2&lt;span class=&#34;nb&#34;&gt;}{&lt;/span&gt;t+2&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
+C&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;t+1, t+1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;-C&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;t, t&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;\\\\&lt;/span&gt; 
&lt;span class=&#34;nb&#34;&gt;&amp;amp;&lt;/span&gt;=2&lt;span class=&#34;k&#34;&gt;\left&lt;/span&gt;(H&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;n+1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;-H&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;t+1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\right&lt;/span&gt;)+2-2 /(t+1) 
&lt;span class=&#34;k&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;aligned&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;换行需要使用&lt;code&gt;\\\\&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\begin{aligned}&lt;/code&gt;和&lt;code&gt;\end{aligned}&lt;/code&gt;之间不能有空行&lt;/p&gt;
&lt;p&gt;不支持&lt;code&gt;\left[&lt;/code&gt;，&lt;code&gt;\right)&lt;/code&gt;等&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\begin{cases}\begin{array}{l}
\theta_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} \theta_{i}(t-j),\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\{r h,l h, r k, l k\}\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases}
$$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;k&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;cases&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;array&lt;span class=&#34;nb&#34;&gt;}{&lt;/span&gt;l&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;\theta&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;i&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;(t-j)&lt;span class=&#34;nb&#34;&gt;^{&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\prime&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;=&lt;span class=&#34;k&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;13&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;\Sigma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;1&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;-1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;\theta&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;i&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;(t-j),&lt;span class=&#34;k&#34;&gt;\\\\&lt;/span&gt; a&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;i&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;(t-j)&lt;span class=&#34;nb&#34;&gt;^{&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\prime&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;=&lt;span class=&#34;k&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;1&lt;span class=&#34;nb&#34;&gt;}{&lt;/span&gt;3&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;\sum&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;1&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;-1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; a&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;i&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;(t-j), i=&lt;span class=&#34;k&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;r h,l h, r k, l k&lt;span class=&#34;k&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\\\\&lt;/span&gt;w&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;i&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;(t-j)&lt;span class=&#34;nb&#34;&gt;^{&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\prime&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;=&lt;span class=&#34;k&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;1&lt;span class=&#34;nb&#34;&gt;}{&lt;/span&gt;3&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;\Sigma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;1&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;-1&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; w&lt;span class=&#34;nb&#34;&gt;_{&lt;/span&gt;i&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;(t-j)&lt;span class=&#34;k&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;array&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;cases&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;\begin{array}&lt;/code&gt;和&lt;code&gt;\end{array}&lt;/code&gt;之间不能换行😅&lt;/p&gt;
&lt;p&gt;大括号只能用&lt;code&gt;\begin{cases}&lt;/code&gt; &lt;code&gt;\end{cases}&lt;/code&gt;实现了&lt;/p&gt;
&lt;p&gt;花括号要这样&lt;code&gt;\\}&lt;/code&gt;才能打出来$\}$&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
