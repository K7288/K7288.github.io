<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on K7288</title>
    <link>https://K7288.github.io/posts/</link>
    <description>Recent content in Posts on K7288</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 17 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://K7288.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>å¤–éª¨éª¼ç»¼è¿°</title>
      <link>https://K7288.github.io/posts/%E5%A4%96%E9%AA%A8%E9%AA%BC%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%A4%96%E9%AA%A8%E9%AA%BC%E7%BB%BC%E8%BF%B0/</guid>
      <description>Lower limb exoskeleton systems-overview1    Category Control(mostly) Actuator(mostly) Wearer     Assistive High precision; Predefined trajectories triggered by the userâ€™s moving intention
($\Rightarrow$ Intention Estimation + Trajectories Generating) DC motor patients permanently lose the ability to walk   Rehabilitation Predefined; Impedance control; Adjusting itself based on patient feedback. high-power density rehabilitating patients to regain mobility   Augmentation admittance/impedance control; positive feedback sensitivity amplification control, Inaccurate but high power/weight ratio actuators (series elastic actuators (SEA) and pneumatic actuators) healthy individuals    Assistive Intention Estimation â€‹   Direct</description>
    </item>
    
    <item>
      <title>Origami patterns</title>
      <link>https://K7288.github.io/posts/origami-patterns/</link>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/origami-patterns/</guid>
      <description>Yoshimura
Miura-ori
diagnoal</description>
    </item>
    
    <item>
      <title>(Origami) Pneumatic Exoskeleton</title>
      <link>https://K7288.github.io/posts/origami-pnumatic-exoskeleton/</link>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/origami-pnumatic-exoskeleton/</guid>
      <description>(Origami) Pneumatic Exoskeleton
Summary of previous work    Author Origami pattern Joint Prototype ç ”ç©¶é˜¶æ®µ     Bio-Robotics and Control (BiRC) Laboratoryï¼ŒUNIST, Korea Yoshimura pattern shoulder  1.è®¾è®¡ 2.å»ºæ¨¡ï¼ˆè¾“å‡ºåŠ›å…³äºå¼¯æ›²è§’åº¦ç­‰çš„è¡¨è¾¾å¼ï¼‰3. å®éªŒéªŒè¯å¯¹æ”¯æ’‘èƒ½åŠ›/è¾“å‡ºåŠ›çŸ©çš„ä»¿çœŸç»“æœ   å—æ–¹ç§‘æŠ€å¤§å­¦ åˆ˜æ€èª ç‹å³¥ Variated Yoshimura with trapezoid facets. wrist  1. è®¾è®¡ 2. è¿åŠ¨å­¦å»ºæ¨¡ 3. çº§è”æ§åˆ¶ï¼ˆæœªè¯¦ç»†é˜è¿°ï¼Œä½¿ç”¨ä¹‹å‰åˆä½œçš„å·¥ä½œï¼‰ 4. å®éªŒéªŒè¯æ§åˆ¶æ€§èƒ½ä»¥åŠä¸åŒè´Ÿè½½ä¸‹çš„è¿åŠ¨èŒƒå›´   è¥¿åŒ—å·¥ä¸šå¤§å­¦ Jing Fang*2 #1 #2 / (Accordion/Fan) knee  1. è®¾è®¡ 2. å»ºæ¨¡ï¼ˆè¾“å‡ºåŠ›çŸ©çš„é—­å¼è¡¨è¾¾å¼ï¼‰3. å®éªŒéªŒè¯æœºæ¢°æ€§èƒ½åŠè¾…åŠ©æ•ˆæœ 4. æ§åˆ¶ï¼ˆæ»¡è¶³å¯¹ç‰¹å®šåŠ¨ä½œçš„æ”¯æŒï¼‰   Yang, Hee Doo / (Artificial muscle) elbow</description>
    </item>
    
    <item>
      <title>IPS for Validation</title>
      <link>https://K7288.github.io/posts/ips-for-validation/</link>
      <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/ips-for-validation/</guid>
      <description>Detection of gait events using an F-Scan in-shoe pressure measurement system  å¯¹F-ScanÂ® systemå‡†ç¡®æ€§çš„è®¨è®º Methods &amp;amp; Results   KTçš„é˜ˆå€¼é€‰å– ä¸€äº›éªŒè¯æŒ‡æ ‡  Detection of gait events using an F-Scan in-shoe pressure measurement system æ¯”è¾ƒäº†force-based detection (FDï¼Œè½¯ä»¶è‡ªå¸¦)å’Œarea-based method (AD) ï¼›kinetic detection(KTï¼Œä½¿ç”¨force platformsçš„æ•°æ®)ä½œä¸ºvalidation
å¯¹F-ScanÂ® systemå‡†ç¡®æ€§çš„è®¨è®º Several studies have evaluated the accuracy and reliability of force and pressure measurements using the F-ScanÂ® system and reached different conclusions. While some authors concluded that F-Scan demonstrated good to excellent reliability in measuring plantar pressures [11], others concluded that the system was not entirely suitable for accurate and repeatable absolute pressure measurements [12], [13], [14] or that the system could be used only in a sample large enough as to allow the detection of the real effect of the treatment [15].</description>
    </item>
    
    <item>
      <title>Reviews of Gait Event/Phase Detection Methods</title>
      <link>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</link>
      <pubDate>Mon, 02 Aug 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/reviews-of-gait-eventphase-detection-methods/</guid>
      <description>Strategy1 &amp;amp; Yield  Search Strategy
  Scopus, Google Scholar, and PubMed databases were used to perform a literature search on the topic of gait phase partitioning.
  The electronic search was conducted in September 2015.
  Keywords included: gait events, gait phases, and their combinations with the words: partitioning, detection, classification, and recognition. In addition, wildcard symbols, such as hyphens or inverted commas, were used to consider all possible variations of root words.</description>
    </item>
    
    <item>
      <title>Phase Portraits</title>
      <link>https://K7288.github.io/posts/phase-portrait/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/phase-portrait/</guid>
      <description>Studies using phase portraits    Authors and year Axes Task     Holgate et al. 2009 Tibia angle &amp;amp; tibia scaled angular velocity Continuous gait phase estimation   Villarreal et al.,2017 Thigh angle &amp;amp; its derivative(estimated thigh velocity) Continuous gait phase estimation   Quintero et al.,2017 Thigh angle &amp;amp; its derivative(estimated thigh velocity) Continuous gait phase estimation; gait speed estimation(as a byproduct)   Quintero et al.</description>
    </item>
    
    <item>
      <title>Sensors for Gait Analysis</title>
      <link>https://K7288.github.io/posts/sensors-for-gait-analysis/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/sensors-for-gait-analysis/</guid>
      <description>Sensors for Gait Analysis  Sensors for Gait Analysis  Sensors  Inertial Measurement Units  Sensor placement  Preference in literature (inter- and intra=) Segments to choose   Filter Application   Insole pressure sensors      Sensors    Distribution of studies based on the type of wearable sensors used Distribution of studies based on the type of sensors used for ground-truth validation of IMU-based gait analysis.</description>
    </item>
    
    <item>
      <title>FScan: Before Taking A Recording</title>
      <link>https://K7288.github.io/posts/before-taking-a-recording/</link>
      <pubDate>Fri, 09 Jul 2021 22:00:09 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/before-taking-a-recording/</guid>
      <description>FScan: Before Taking A Recording * means &amp;ldquo;optinal&amp;rdquo;; æ­¤å¤„çš„å®šä¹‰å’Œæ­¥éª¤å‡å‚è€ƒTekscançš„F-Scan User Manual
Preparing the Patient trim the sensor; set up the testing area; set up the system hardware; weigh the patient; outfit the patient.
*Zeroing the Sensor å½“æ•´ä¸ªå®éªŒè¿‡ç¨‹ä¸­é‹å«ä¸Šå§‹ç»ˆæœ‰é¢å¤–å‹åŠ›æ—¶ä½¿ç”¨ï¼›ç±»ä¼¼ç§°é‡çš„å»çš®ï¼›
*Equilibration åœ¨é‹å«ä¸Šæ”¾ç½®å‡åŒ€é‡ç‰©ï¼›
Calibration Point Calibration æ ¡å‡†æ—¶é—´å–å†³äºå®é™…è¡Œèµ°è¿‡ç¨‹ï¼Œå¿«çš„äºº1sï¼Œæ…¢çš„2s
å…ˆæŠ¬èµ·å¾…æ ¡å‡†è„šï¼Œæ”¾ä¸‹åŒæ—¶é‡é‡å…¨éƒ¨é›†ä¸­åœ¨è¯¥è„šä¸Šï¼Œæ”¾ä¸‹åå¾ˆå¿«ï¼ˆé—´éš”1sï¼‰å®éªŒäººå‘˜ç‚¹å‡»æ ¡å‡†ï¼ˆå®æµ‹è¿™æ ·ä¸è¡Œï¼Œè¿˜æ˜¯è¦ç¨å¾®ç¨³å®šä¸€ä¸‹å†å¼€å§‹æ ‡å®šã€‚ï¼‰
å¯ä»¥ç”¨æ‰‹æŒ‡åœ¨ç«–ç›´å¢™é¢ä¸Šè½»ç‚¹è¾…åŠ©ç¨³å®šã€‚ï¼ˆå®æµ‹+å®˜æ–¹æ–‡æ¡£ï¼‰
ç¨³å®šåä¼ æ„Ÿå™¨å‹åŠ›æŒç»­ä¸Šå‡ï¼Œå¯ä»¥åªçœ‹å‰nç§’æ¥åˆ¤æ–­æ ‡å®šæ˜¯å¦æ­£ç¡®ã€‚(n=5~10)
Extended Calibration æ˜¯ç‚¹æ ¡å‡†çš„å»¶ä¼¸ï¼›é»˜è®¤å¼€å¯ï¼›åœ¨ä¸¤ä¸ªå‡é‡‡ç”¨ç‚¹æ ¡å‡†çš„sensoræµ‹é‡å®ŒæˆååŸºäºä½“é‡è°ƒæ•´ä¸¤sensorçš„æ ¡å‡†ï¼ˆby an equal amountï¼‰to correct for the differing &amp;ldquo;drift&amp;rdquo; times that occur between your calibration and the actual test.
è¿›è¡Œæ­¤æ ¡å‡†è¦æ±‚ä¸¤è„šå‡å¿…é¡»æ»¡3steps $\Rightarrow$ ä¸ç„¶ä¼šæç¤ºâ€œæ­¥æ€æ‰©å±•ä¸è¶³â€æ‰“âœ”ï¸å¼€å¯Step Calibration To initiate Step calibration, initially, the subject stands entirely on the foot to be off-loaded.</description>
    </item>
    
    <item>
      <title>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons</title>
      <link>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</link>
      <pubDate>Thu, 08 Jul 2021 14:29:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</guid>
      <description>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons
intentionå®šä¹‰: walk/stride across/stop state
Research question  analysis of gait planning based on a human kinematics model and real-time motion stability based on the zero-moment point (ZMP). a neural interface based on sEMG to achieve motion intention recognition and muscle fatigue estimation. to verify the stability of humanâ€“exoskeleton system and ergonomic effects of the proposed gait switching method by organized experiments.</description>
    </item>
    
    <item>
      <title>A novel motion intention recognition approach for soft exoskeleton via IMU</title>
      <link>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</link>
      <pubDate>Thu, 08 Jul 2021 09:05:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</guid>
      <description>A novel motion intention recognition approach for soft exoskeleton via IMU
intentionå®šä¹‰: the classic five kinds of terrains(including walking on flat ground, going up and downstairs, and up and down slopes) &amp;amp; transformed terrains
   Abbreviation Definition Abbreviation Definition     IMU Inertial measurement unit SA Stair ascent   DDLMI DNN-based deep locomotion mode identification SD Stair decent   ISR Identification success rate RA Ramp ascent   LW Level-ground walking RD Ramp decent    Research question to propose a recognition method with historical information based on neural network to recognize different terrain and add the pattern transformation recognition, trying to predict the next motion mode in advance.</description>
    </item>
    
    <item>
      <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
      <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
      <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
      <description>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach
intentionå®šä¹‰: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).
Research question to propose an automatic, user-independent recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.</description>
    </item>
    
    <item>
      <title>Motion control for a walking companion robot with a novel humanâ€“robot interface</title>
      <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
      <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
      <description>Motion control for a walking companion robot with a novel humanâ€“robot interface
Research question A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.
A new humanâ€“ robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.
mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states</description>
    </item>
    
    <item>
      <title>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study</title>
      <link>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</link>
      <pubDate>Tue, 06 Jul 2021 22:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</guid>
      <description>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study
intentionå®šä¹‰: standing still(stationary), walking or ascending the stairs
Hardware sensors: ADXL345 (an accelerometer; in pelvis unit) and four FSRs (two in each foot for heel and toe respectively)
Algorithm   gait adaptation: detect in which phase of the gait cycle the subject is
  adaptive frequency oscillators (AFO) $\Leftarrow$ Since the human gait cycle is periodic, the acceleration signals obtained from the pelvis unit is also periodic in nature.</description>
    </item>
    
    <item>
      <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
      <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
      <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
      <description>A lower limb exoskeleton based on recognition of lower limb walking intention
intentionå®šä¹‰: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination
Introduction   Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driverâ€™s intention, and humanâ€“robot interface.
  three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.</description>
    </item>
    
    <item>
      <title>Intention Recgonition for Exoskeleton</title>
      <link>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</link>
      <pubDate>Tue, 06 Jul 2021 13:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</guid>
      <description>Intention Recgonition for Exoskeleton
intentionå®šä¹‰: walk/stand
assistance exoskeleton system   æ”¯æŒ4ç§state: L swing, R swing, Double stance(L), Double stance(R)
  control
  Methods online SVM; features: ZMP(Zero Moment Point), IMU
  ZMP
  concept: The distributed floor reaction force can be replaced by a single force R acts on ZMP.
  ZMP can be obtained from ground reaction force (GRF) measurement or inverse dynamics of system.</description>
    </item>
    
    <item>
      <title>é¡µå†…è·³è½¬</title>
      <link>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</link>
      <pubDate>Mon, 05 Jul 2021 16:52:26 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</guid>
      <description>è¿™æ˜¯ä¸€æ®µæ–‡å­—ï¼Œæˆ‘æƒ³è·³è½¬åˆ°è¿™é‡Œã€‚
â¬
â¬
â¬
æˆ‘å®ç°äº†è·³è½¬ã€‚
&amp;lt;a id=&amp;#34;series&amp;#34;&amp;gt;&amp;lt;/a&amp;gt;è¿™æ˜¯ä¸€æ®µæ–‡å­—ï¼Œæˆ‘æƒ³è·³è½¬åˆ°è¿™é‡Œã€‚ â¬ â¬ â¬ &amp;lt;a class=&amp;#34;link&amp;#34; href=&amp;#34;#series&amp;#34;&amp;gt;æˆ‘å®ç°äº†è·³è½¬ã€‚&amp;lt;/a&amp;gt; </description>
    </item>
    
    <item>
      <title>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses</title>
      <link>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</guid>
      <description>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses
intentionå®šä¹‰â€”locomotion modes: level walking, ramp ascent, ramp descent, stair ascent, and stair descent
Research question to develop a user-independent intent recognition system capable of recognizing level-ground walking, slopes, and stairs and to compare this system with a user-dependent intent recognition system.
Introduction  Prior studies in which pattern recognition algorithms: current methods to initiate transitions between modes, such as visual, audio, or compensatory movement commands, are unintuitive and impose a cognitive burden.</description>
    </item>
    
    <item>
      <title>Multi-sensor based human motion intention recognition algorithm for walking-aid robot</title>
      <link>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</guid>
      <description>Multi-sensor based human motion intention recognition algorithm for walking-aid robot
intentionå®šä¹‰ï¼švelocity; è¿™é‡Œè¡¨å¾ä¸ºä¸€ä¸ªè‡ªå®šæ¦‚å¿µIM
Research question A multi-sensor(force sensors and LRF; for both lower and upper limbs) based human motion intention recognition algorithm for walking-aid robot.
Introduction  assistive rehabilitation robots: PAMM, Walking Helper, HAL, Omni RT Walker-II (ORTW-II) ç®€ç•¥è¯´äº†ä¸€äº›human motion estimation methods  Methods  Sensors: push-pull force sensors and LRF(Laser Range Finder)    LRF: Range Segmentation, Identification of Circle, Leg detection, Intention detection</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://K7288.github.io/posts/terms/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/terms/</guid>
      <description>Terms Definition     inertia matrix    damping matrix    stiffness matrix    centripetal and Coriolis matrix    Cartesian coordinate    mass-damper-spring model    impedance control    admittance control å¯¼çº³æ§åˆ¶    push-off impulse time    transition function    adaptive frequency oscillators    one-way ANOVA    two-way ANOVA    a neural interface    linear discriminant analysis    drift(signal/integral/zero/integral/temperature drift)    a rigid body åˆšä½“    time-varying, adaptive compensation term, manifold, coarse/fine-grained level granularity, an inertial frame, oscillator, denominator,</description>
    </item>
    
    <item>
      <title>è¡Œæ–‡å¸¸è§è¯´æ³•</title>
      <link>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</guid>
      <description>prior studies/research
Experimental Protocol
Representative diagram
the integrated design
cognitive effort
methodology
prototype
Sensory Information</description>
    </item>
    
    <item>
      <title>A review of human activity recognition methods</title>
      <link>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</link>
      <pubDate>Thu, 01 Jul 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</guid>
      <description>A review of human activity recognition methods
Recognizing human activities from video sequences or still images
intentionå®šä¹‰: activity; ä¸€ä¸ªæè¿°æ€§è¯
Usually, the terms â€œactivityâ€ and â€œbehaviorâ€ are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term â€œactivityâ€ is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term â€œbehaviorâ€ is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.</description>
    </item>
    
    <item>
      <title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>
      <link>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</link>
      <pubDate>Tue, 29 Jun 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</guid>
      <description>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intentionå®šä¹‰ï¼švelocity+trajectory; åªæ¶‰åŠåˆ°ä¸€ä¸ªæ¥è§¦ç‚¹
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.</description>
    </item>
    
    <item>
      <title>Froude Numbers</title>
      <link>https://K7288.github.io/posts/froude-numbers/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/froude-numbers/</guid>
      <description>The Gaits of Bipedal and Quadrupedal Animals Alexander R. The gaits of bipedal and quadrupedal animals. The International Journal of Robotics Research. 1984;
mammals of different sizes tend to move in dynamically similar fashion whenever their Froude numbers $u^2 /gh$ are equal: here u is speed, g is the acceleration of free fall, and h is the height of the hip joint from the ground.
Research Problem description of the gaits of two- and four-legged animals and some of the important optimization criteria(e.</description>
    </item>
    
    <item>
      <title>F-Scan</title>
      <link>https://K7288.github.io/posts/f-scan/</link>
      <pubDate>Tue, 18 May 2021 14:21:37 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/f-scan/</guid>
      <description>Details é‡‡æ ·é¢‘ç‡ï¼š$50\text{Hz}$
æµ‹åŠ›ç‚¹å°ºå¯¸ï¼š$5.1\times5.1(\text{mm})$
ç¿»è¯‘é—®é¢˜ï¼š
 åŠ›åº¦ $\Rightarrow$ åŠ› å‹åŠ› $\Rightarrow$ å‹å¼º  æµ‹åŠ›ç‰‡æ— æ‰€è°“æ­£å
æµç¨‹ è£å‰ªï¼ˆåªè¦ä¸å‰ªæ–­æ¨ªå‘çº¿è·¯å³å¯ï¼‰
éƒ¨ç½²ï¼ˆä¿¡å·é‡‡é›†/é€šä¿¡è£…ç½®ç”¨é­”åŠ›è´´å›ºå®šåœ¨å°è…¿ï¼Œæ’ä¸Šæµ‹åŠ›ç‰‡ï¼‰
æ ¡å‡†ï¼ˆéœ€è¦è¢«è¯•å•è„šç«™ç«‹å„5sï¼‰
åœ¨fsxçª—å£å³é”®â€œå•ä½â€é€‰æ‹©å•ä½å’Œç²¾åº¦
å½•åˆ¶
æ•°æ®å¯¼å‡º 1.å®Œæ•´æ•°æ®ï¼šé€‰ä¸­ç›¸åº”fsxçª—å£åœ¨â€œæ–‡ä»¶â€ä¸­å¯¼å‡º
æ ¼å¼ï¼šæ¯ä¸€å¸§çš„å…¨éƒ¨æµ‹åŠ›ç‚¹æ‰€æµ‹å‹å¼ºï¼ˆåŒ…æ‹¬ç°è‰²è¾¹ç•Œ&amp;quot;B&amp;quot;å’Œå‰ªå»çš„æµ‹åŠ›ç‚¹ï¼‰
å•ä½ï¼šè‡ªé€‰ï¼Œä¼šåœ¨å¯¼å‡ºçš„csvæ–‡ä»¶å¤´åˆ—å‡º
å†™äº†è®¡ç®—æ¯ä¸€å¸§æ€»å‹åŠ›çš„ä»£ç ï¼Œä¹Ÿå¯ç”¨é‡‡æ ·åŒºé€‰ä¸­æ•´ä¸ªåŒºåŸŸå¾—åˆ°æ€»å‹åŠ›
2.å–æ ·åŒº
æ‰€åœ¨çª—æ ¼å³é”®â€œå¯¹è±¡â€å¯¼å‡º æˆ–è€…ç›´æ¥åœ¨ç”Ÿæˆçš„å›¾çº¿ä¸Šctrl+cç²˜è´´åˆ°excel
æ ¼å¼ï¼šä¸ä¿ç•™æ¯ä¸ªé‡‡æ ·ç‚¹ä¿¡æ¯ï¼Œåªæœ‰æ•´ä½“æ•°æ®ï¼ˆè¿™ä¸€ä¸ªåŒºåŸŸçš„æ€»å‹åŠ›/å‹å¼ºç­‰ï¼‰
åœ¨å³é”®&amp;quot;å±æ€§&amp;quot;ä¸­å¯ä»¥æ›´æ”¹é‡‡æ ·åŒºæ˜¾ç¤ºçš„ä¿¡æ¯</description>
    </item>
    
    <item>
      <title>Hugo HTML Tips</title>
      <link>https://K7288.github.io/posts/hugo-html-tips/</link>
      <pubDate>Tue, 18 May 2021 11:23:29 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/hugo-html-tips/</guid>
      <description>  åŸç”Ÿhtmlæ”¯æŒ
hugoé‡‡ç”¨goldmarkä½œä¸ºé»˜è®¤æ¸²æŸ“å™¨ï¼Œéœ€è¦åœ¨configä¸­å¼€å¯
  markup: goldmark: renderer: unsafe: true html å›¾ç‰‡éœ€è¦ç»å¯¹è·¯å¾„ï¼Œå½¢å¼å¦‚ä¸‹ï¼š  &amp;lt;img src=&amp;#34;/assets/image-20210416142714352.png&amp;#34; alt=&amp;#34;image-20210416142714352&amp;#34; style=&amp;#34;zoom:33%;&amp;#34; /&amp;gt; è€Œä¸èƒ½æ˜¯src=&amp;quot;assets\ æ‰€ä»¥ä¹Ÿä¸å¤ªæ”¯æŒç½‘ç»œå›¾ç‰‡&amp;hellip;&amp;hellip;
****å¥½åƒä¸èƒ½å‡ºç°ã€‚  </description>
    </item>
    
    <item>
      <title>(Draft)Image Processing and Computer Vision</title>
      <link>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</guid>
      <description>å‚è€ƒä¹¦ç›® Digital Image Processing by Rafael C. Gonzalez, Richard E. Woods, 3rd Edition
ç¬¬ä¸€ç«  æ•°å­—å›¾åƒçš„é‡‡é›†æ–¹å¼ä»¥åŠç‰¹æ€§ 1.1 å›¾åƒæ¦‚è¿° å›¾åƒæ˜¯ä¸€ä¸ªäºŒç»´äº®åº¦å‡½æ•°ï¼›
æ¨¡æ‹Ÿå›¾åƒï¼šä¸€å¹…æ´»åŠ¨ã€å½©è‰²ã€ç«‹ä½“çš„å›¾åƒâ€”â€”$I=f(x,y,z,Î»,t)$ï¼Œä¸‰ç»´ç©ºé—´+æ³¢è°±ä¸Š+æ—¶é—´ä¸Šè¿ç»­ï¼Œæƒ³è±¡ä¸­çš„è™šæ‹Ÿå›¾åƒ
æ•°å­—å›¾åƒï¼šæ•°å­—å›¾åƒæ˜¯ç”±æ¨¡æ‹Ÿå›¾è±¡æ•°å­—åŒ–å¾—åˆ°çš„ï¼Œä»¥åƒç´ ä¸ºåŸºæœ¬å…ƒç´ ã€å¯ä»¥ç”¨æ•°å­—è®¡ç®—æœºæˆ–æ•°å­—ç”µè·¯å­˜å‚¨å’Œå¤„ç†çš„å›¾åƒã€‚
æŠŠä¸€å¹…å›¾ç”»åˆ†å‰²æˆå¦‚å›¾æ‰€ç¤ºçš„ä¸€ä¸ªä¸ªå°åŒºåŸŸï¼ˆåƒç´ ï¼‰ï¼Œå¹¶å°†å„å°åŒºåŸŸç°åº¦ç”¨æ•´æ•°æ¥è¡¨ç¤ºï¼Œå½¢æˆä¸€å¹…ç‚¹é˜µå¼çš„æ•°å­—å›¾åƒã€‚å®ƒåŒ…æ‹¬é‡‡æ ·å’Œé‡åŒ–ä¸¤ä¸ªè¿‡ç¨‹ã€‚åƒç´ çš„ä½ç½®å’Œç°åº¦å°±æ˜¯åƒç´ çš„å±æ€§ã€‚
å›¾åƒæ•°å­—åŒ– å›¾åƒæ•°å­—åŒ–:å°†æ¨¡æ‹Ÿå›¾åƒç»è¿‡ç¦»æ•£åŒ–ä¹‹åï¼Œå¾—åˆ°ç”¨æ•°å­—è¡¨ç¤ºçš„å›¾åƒã€‚
ä¸€å¹…æ¨¡æ‹Ÿå›¾åƒçš„åæ ‡åŠå¹…åº¦éƒ½æ˜¯è¿ç»­çš„ï¼Œä¸ºäº†æŠŠå®ƒè½¬æ¢ä¸ºæ•°å­—å½¢å¼ï¼Œå¿…é¡»å¯¹åæ ‡å’Œå¹…åº¦éƒ½ä½œç¦»æ•£åŒ–æ“ä½œã€‚æ•°å­—åŒ–åæ ‡å€¼ç§°ä¸ºé‡‡æ ·ï¼Œå®ƒç¡®å®šäº†å›¾åƒçš„ç©ºé—´åˆ†è¾¨ç‡ï¼›æ•°å­—åŒ–å¹…åº¦å€¼ç§°ä¸ºé‡åŒ–ï¼Œå®ƒç¡®å®šäº†å›¾åƒçš„å¹…åº¦åˆ†è¾¨ç‡ã€‚
1.2.1å›¾åƒæ•°å­—åŒ–â€”â€”é‡‡æ · ï¼ˆ1ï¼‰å›¾åƒçš„é‡‡æ ·ï¼šå°†åœ¨ç©ºé—´ä¸Šè¿ç»­çš„å›¾åƒè½¬æ¢æˆç¦»æ•£çš„é‡‡æ ·ç‚¹ï¼ˆå³åƒç´ ï¼‰é›†çš„æ“ä½œ
z=f(x,y), xâˆˆ[0,a], yâˆˆ[0,b], zâˆˆ[0,c] $\rightarrow$ z=f(x,y), x=0,1,â€¦,N-1,y=0,1,â€¦,M-1, z=0,1,â€¦,L-1
é‡‡æ ·é—´éš”å¤ªå°ï¼Œåˆ™å¢å¤§æ•°æ®é‡ï¼›å¤ªå¤§ï¼Œåˆ™ä¼šå‘ç”Ÿä¿¡æ¯çš„æ··å ï¼Œå¯¼è‡´ç»†èŠ‚æ— æ³•è¾¨è®¤ã€‚
ä¸€ç»´è¿ç»­ä¿¡å·çš„é‡‡æ · åœ¨å·¥ç¨‹ä¸­çš„è®¸å¤šä¿¡å·ï¼Œå®é™…ä¸Šéƒ½æ˜¯è¿ç»­ä¿¡å·ï¼Œæˆ–è€…ç§°ä¸ºè¿ç»­æ—¶é—´å‡½æ•°ï¼Œè®°ä¸ºx(t)ï¼Œtçš„å–å€¼æ˜¯ä»$-\infty$ è¿ç»­å˜åŒ–åˆ°$+ \infty $ ã€‚ä½†æ˜¯ï¼Œç”¨è®¡ç®—æœºå¤„ç†è¿™äº›ä¿¡å·ï¼Œå¿…é¡»é¦–å…ˆå¯¹è¿ç»­ä¿¡å·è¿›è¡Œé‡‡æ ·ï¼Œå³æŒ‰ä¸€å®šçš„æ—¶é—´é—´éš”Tsè¿›è¡Œå–å€¼ï¼š $$ ğ‘¥_ğ‘‘ (ğ‘›)=ğ‘¥(ğ‘›ğ‘‡_ğ‘ ) , ğ‘›=â€¦âˆ’1,0,1â€¦ $$ $T_s$ä¸ºé‡‡æ ·é—´éš”ï¼Œ$ x_d (n)$ä¸ºç¦»æ•£ä¿¡å·æˆ–æ—¶é—´åºåˆ—
è¿ç»­ä¿¡å·x(t)å’Œé¢‘è°±X(f)çš„å…·ä½“å…³ç³»ä¸ºï¼š $$ X(f)=\int _{âˆ’\infty}^\infty x(t)e^{âˆ’j2\pi ft} dt\\\\x(t)=\int _{âˆ’\infty}^\infty X(f)e^{j2\pi ft} df $$
ä¸€ç»´ç©ºé—´é‡‡æ ·çš„Nyquistæ¡ä»¶ï¼š$X(f)$æœ‰æˆªé¢‘$ f_c$ï¼Œå³å½“$|f|â‰¥ f_c$æ—¶, $X(f)=0$ï¼›$T_sâ‰¤\frac{1}{2f_c}$ æˆ–$2f_câ‰¤f_s$
å¦‚æœä¿¡å·ä¸æ˜¯æœ‰é™å¸¦å®½ä¿¡å·ï¼Œé‡‡æ ·é¢‘ç‡æˆ–é‡‡æ ·é—´éš”ä¸æ»¡è¶³Nyquistæ¡ä»¶ï¼Œå°±ä¼šäº§ç”Ÿæ··å ç°è±¡ã€‚
åœ¨æ»¡è¶³Nyquistæ¡ä»¶ä¸‹ï¼Œä»ç¦»æ•£ä¿¡å·$x(nT_s)$å¯æ¢å¤è¿ç»­ä¿¡å·$x(t)$ $$ x(t)=\Sigma_{n=âˆ’\infty}^{+\infty}x(nT_s)sinc(\frac{\pi}{T_s} (t-nT_s)) $$</description>
    </item>
    
    <item>
      <title>The effect of stride length on lower extremity joint kinetics at various gait speeds</title>
      <link>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</link>
      <pubDate>Sun, 16 May 2021 10:44:02 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</guid>
      <description>The effect of stride length on lower extremity joint kinetics at various gait speeds
 Research question Concepts Notations Background Materials and Methods  Data analysis  1. æ•°æ®å¤„ç† 2. Protocol validation 3. Continuum analysis  main effect analysis SL   4. Torque pulse approximation     Results  Protocol validation Continuum analysis Torque pulse approximation   Conclusion Limits/Further Work Thoughts/Comments  Research question In this study, we investigated how sagittal plane joint moments are affected by a factorial modulation of two important gait parameters: gait speed and stride length.</description>
    </item>
    
    <item>
      <title>Menu</title>
      <link>https://K7288.github.io/posts/menu/</link>
      <pubDate>Sun, 16 May 2021 10:35:13 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/menu/</guid>
      <description>å®ç°é¡µå†…è·³è½¬  åŸºæœ¬è¯­æ³• æ³¨æ„äº‹é¡¹ A subtitle just for test æµ‹è¯• a A  æµ‹è¯•â€”â€”æµ‹è¯• æµ‹è¯•:ä¸€ä¸ªæµ‹è¯•   1.æµ‹è¯•   ç›®å½•å®ç°  å®ç°é¡µå†…è·³è½¬ åŸºæœ¬è¯­æ³• [&amp;lt;æç¤ºè¯­&amp;gt;](#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;) æ³¨æ„äº‹é¡¹   è‹¥æ ‡é¢˜æ˜¯è‹±æ–‡ï¼Œåœ¨(#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)ä¸­éœ€è¦å°å†™
ä¾‹å¦‚ [ä¾‹å¦‚](#a-subtitle-just-for-test)
  è‹¥æ ‡é¢˜ä¸­å‡ºç°ç©ºæ ¼ï¼Œéœ€è¦ç”¨-è¿æ¥
ä¾‹å¦‚ [ä¾‹å¦‚](#æµ‹è¯•-a-a)
  (#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)ä¸­ä¸èƒ½å‡ºç°åŠè§’ç‚¹(å³è‹±æ–‡ä¸­çš„å¥å·).ï¼Œä¼¼ä¹ä¹Ÿä¸æ”¯æŒå…¶ä»–æ ‡ç‚¹ï¼Œ(#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)ä¸­éœ€è¦å°†æ ‡ç‚¹åˆ é™¤
æµ‹è¯•:ä¸€ä¸ªæµ‹è¯• [æµ‹è¯•:ä¸€ä¸ªæµ‹è¯•](#æµ‹è¯•ä¸€ä¸ªæµ‹è¯•)
1.æµ‹è¯• [1.æµ‹è¯•](#1æµ‹è¯•)
æµ‹è¯•â€”â€”æµ‹è¯• [æµ‹è¯•â€”â€”æµ‹è¯•](#æµ‹è¯•æµ‹è¯•)
  A subtitle just for test æµ‹è¯• a A æµ‹è¯•â€”â€”æµ‹è¯• æµ‹è¯•:ä¸€ä¸ªæµ‹è¯• 1.æµ‹è¯• ç›®å½•å®ç°  VS codeæ’ä»¶ Markdown All in One  ctrl+shift+p Markdown All in One: Create Table of Contents   TOD0 å®ç°ä¾§è¾¹ç›®å½•   ğŸ˜‚ å·²ç»å‡ºç°äº†å¯¹â€œæµ‹â€çš„å®Œå‹å´©å</description>
    </item>
    
    <item>
      <title>æ­¥é€Ÿä¼°è®¡ç»¼è¿°æ•´ç†</title>
      <link>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</link>
      <pubDate>Wed, 12 May 2021 22:17:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</guid>
      <description>Toward Pervasive Gait Analysis With Wearable Sensors: A Systematic Review Abstract å¯¹å½“å‰çš„å®šé‡æ­¥æ€åˆ†ææŠ€æœ¯è¿›è¡Œç³»ç»Ÿçš„ç»¼è¿°ï¼Œå¹¶æå‡ºå…³é”®æŒ‡æ ‡ï¼Œæ¥è¯„ä¼°ç°æœ‰çš„é€šè¿‡å¯ç©¿æˆ´ä¼ æ„Ÿå™¨æå–æ­¥æ€ç‰¹å¾çš„æ–¹æ³•ã€‚å®ƒæ—¨åœ¨çªå‡ºè¿™ä¸€å¿«é€Ÿå‘å±•çš„ç ”ç©¶é¢†åŸŸä¸­çš„å…³é”®è¿›å±•ï¼Œå¹¶æ¦‚è¿°ç ”ç©¶å’Œä¸´åºŠåº”ç”¨çš„æ½œåœ¨æœªæ¥æ–¹å‘ã€‚
SECTION III. Methods for Extracting Relevant Gait Features From Wearable Sensors A.æ–‡çŒ®æ£€ç´¢
B. Kinematics
Kinematic information is a well-established set of gait measures in biomechanical analysis.
ä»æƒ¯æ€§ä¼ æ„Ÿå™¨è·å–è¿åŠ¨å­¦ä¿¡æ¯ä¼¼ä¹å¾ˆç›´è§‚ï¼Œä½†æ˜¯è¦è·å¾—å…³äºäººä½“è¿åŠ¨å­¦çš„å‡†ç¡®ç©ºé—´ä¿¡æ¯ä»ç„¶å¾ˆå›°éš¾ï¼šå…¨å±€å¤±å‡†å’Œintegration drift
C.æ—¶åºç‰¹å¾
D.åˆ©ç”¨æƒ¯æ€§ä¼ æ„Ÿå™¨çš„æ­¥é€Ÿæå–
Laudanski et al. [104] reviewed the current research (16 papers in total) on gait speed estimation using inertial sensors, classifying the current gait speed estimation model into three categories: abstraction model (i.</description>
    </item>
    
    <item>
      <title>åŸºäºå‡ ä½•ä¸ç‰©ç†ç‰¹å¾èåˆçš„æ™ºèƒ½ä¸‹è‚¢å‡è‚¢è¿åŠ¨æ„å›¾è¯†åˆ«</title>
      <link>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</link>
      <pubDate>Wed, 12 May 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</guid>
      <description>åŸºäºå‡ ä½•ä¸ç‰©ç†ç‰¹å¾èåˆçš„æ™ºèƒ½ä¸‹è‚¢å‡è‚¢è¿åŠ¨æ„å›¾è¯†åˆ«Movement intention recognition of intelligent lower limb prosthesis based on the fusion of geometric and physical features
intentionå®šä¹‰â€”locomotion modes 5ç±»ç¨³æ€æ¨¡å¼: å¹³åœ°è¡Œèµ°ã€ä¸Šæ¥¼ã€ä¸‹æ¥¼ã€ä¸Šå¡å’Œ ä¸‹å¡ï¼Œ8ç±»è½¬æ¢æ¨¡å¼
Research question å°†å…³èŠ‚è§’è¡¨ç¤ºçš„å‡ ä½•ç‰¹å¾ä¸åŠ é€Ÿåº¦ã€è§’é€Ÿåº¦è¡¨ç¤ºçš„ç‰©ç†ç‰¹å¾æœ‰æœºèåˆå¹¶åº”ç”¨äºæ™ºèƒ½ä¸‹è‚¢å‡è‚¢çš„è¿åŠ¨æ„å›¾è¯†åˆ«
Introduction ä¼ ç»Ÿçš„æ„å›¾è¯†åˆ«æ–¹æ³•æ‰€ç”¨ä¼ æ„Ÿå™¨æ•°é‡åŠç§ç±»è¾ƒå¤š, ç‰¹å¾å‘é‡ç»´æ•°åé«˜, ç»Ÿè®¡ç‰¹å¾å¯¹çŸ­æ—¶æ ·æœ¬å…·æœ‰ä¸ç¨³å®šæ€§ï¼ˆåœ¨1.3 ç‰¹å¾é€‰æ‹©ä¸æå–æœ‰å…¬å¼è¯æ˜ï¼‰ã€‚related workæ²¡æœ‰ç»“åˆå‡ ä½•å’Œç‰©ç†ã€‚
Methods   é‡‡æ ·ï¼šå¥ä¾§å¤§è…¿ã€å°è…¿æƒ¯æ€§æµ‹é‡å•å…ƒäºæ‘†åŠ¨ç›¸å‰æœŸæ‰€äº§ç”Ÿçš„è¿åŠ¨æ—¶åºæ•°æ®ä½œä¸ºæ ·æœ¬ï¼›
  æ•°æ®å¤„ç†ï¼šç§»åŠ¨å¹³å‡æ»¤æ³¢å™¨æ»¤æ³¢å»å™ª
  ç‰¹å¾æå–ï¼š
 å‡ ä½•ç‰¹å¾ï¼šæ ¹æ®ä¸¤ä¸ªä¼ æ„Ÿå™¨çš„åŠ é€Ÿåº¦ã€è§’é€Ÿåº¦è®¡ç®—ä¸€ç»´çš„è†å…³èŠ‚è§’ï¼ŒFDAæ–¹æ³•æå–æœ€å€¼æ–œç‡ ç‰©ç†ç‰¹å¾ï¼šåŠ é€Ÿåº¦ã€è§’é€Ÿåº¦çš„å‡å€¼ã€æ–¹å·®  å‡å€¼ã€æ–¹å·®ã€æœ€å€¼æ–œç‡èåˆæ„æˆ25ç»´çš„ç‰¹å¾åŸºæ„å»ºç‰¹å¾å‘é‡
  SVMåˆ†ç±»
  Results 13ç§æ—¥å¸¸è¡Œä¸ºè¿›è¡Œåˆ†ç±»ã€‚å®éªŒç»“æœï¼šå¯¹5ç±»ç¨³æ€æ¨¡å¼: å¹³åœ°è¡Œèµ°ã€ä¸Šæ¥¼ã€ä¸‹æ¥¼ã€ä¸Šå¡å’Œ ä¸‹å¡çš„è¯†åˆ«ç‡è¾¾åˆ°96.9%, å¯¹8ç±»è½¬æ¢æ¨¡å¼çš„è¯†åˆ«ç‡è¾¾åˆ°97.1%, å¯¹13 ç§æ¨¡å¼çš„è¯†åˆ«ç‡ä¸º94.3%ã€‚
Highlights å‡å°‘äº†ä¼ æ„Ÿå™¨çš„æ•°é‡åŠç§ç±», é™ä½ äº†ç‰¹å¾å‘é‡çš„ç»´æ•°é™ä½äº†ç®—æ³•å¤æ‚åº¦ä¸”é¿å…äº†æ»åæ€§é—®é¢˜, ç”¨åŠ é€Ÿåº¦ã€ è§’é€Ÿåº¦åŠè†å…³èŠ‚è§’ä¸‰ä¸ªå‚æ•°å…±åŒå¯¹äººä½“ä¸‹è‚¢è¿åŠ¨çš„è¿åŠ¨å­¦ç‰¹ç‚¹è¿›è¡Œè¡¨å¾ã€‚
åœ¨ç‰¹å¾çš„æå–ä¸Š, å°†FDAæ–¹æ³•ä¸ç»Ÿè®¡æ–¹æ³•ç›¸ç»“åˆ, å¼¥è¡¥äº†ä»…æå–ç»Ÿè®¡ç‰¹å¾çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚
Limits/Further Work å¯¹äº13ç§åŠ¨ä½œçš„è¯†åˆ«ç‡æœ‰å¾…æé«˜, åæœŸå·¥ä½œä¼šé›†ä¸­äºå¯¹ç±»é—´ç›¸ä¼¼æ€§ç›¸å¯¹è¾ƒå¼ºè¾ƒéš¾åŒºåˆ†çš„åŠ¨ä½œè¿›è¡Œåˆ†ç±», å¦‚: ä¸‹æ¥¼ä¸ä¸‹å¡, èµ°åˆ°ä¸‹æ¥¼ ä¸èµ°åˆ°ä¸‹å¡ç­‰.</description>
    </item>
    
    <item>
      <title>Gait Analysis Systems</title>
      <link>https://K7288.github.io/posts/gait-analysis-systems/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/gait-analysis-systems/</guid>
      <description>&amp;ldquo;Section Four - Gait Analysis Systems&amp;rdquo; from Gait Analysis: Normal and Pathological Function1
Basically, there are 5 measurement systems.
Three of these focus on the specific events that constitute the act of walking.
è¡Œèµ°å„ä¸ªé˜¶æ®µ
 Motion analysis defines the magnitude and timing of individual joint action. Dynamic electromyography idenÂ­tifies the period and relative intensity of muscle function. Force plate recordings display the functional demands being experienced during the weight-bearing period.  The two remaining gait analysis technics summarize the effects of the person&amp;rsquo;s gait mechanics.</description>
    </item>
    
    <item>
      <title>Gait Analysis Fundamentals</title>
      <link>https://K7288.github.io/posts/gait-analysis-fundamentals/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/gait-analysis-fundamentals/</guid>
      <description>Gait analysis æ­¥æ€åˆ†æç®€è¿°1 Factors and parameters å½±å“æ­¥æ€çš„å› ç´  The gait analysis is modulated or modified by many factors, and changes in the normal gait pattern can be transient or permanent. The factors can be of various types:
 Extrinsic: such as terrain, footwear, clothing, cargo Intrinsic: sex, weight, height, age, etc. Physical: such as weight, height, physique Psychological: personality type, emotions Physiological: anthropometric characteristics, i.e., measurements and proportions of body Pathological: for example trauma, neurological diseases, musculoskeletal anomalies, psychiatric disorders  Parameters æè¿°æ­¥æ€çš„å‚æ•° The parameters taken into account for the gait analysis are as follows:</description>
    </item>
    
    <item>
      <title>Hugo Guide</title>
      <link>https://K7288.github.io/posts/hugo-guide/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/hugo-guide/</guid>
      <description>About Contents Add Some Content hugo new post/**.md
The newly created content file will start with something like this:
--- title: &amp;#34;**&amp;#34; date: 2019-03-26T08:47:11+01:00 draft: true --- Drafts do not get deployed; once you finish a post, update the header of the post to say draft: false. More info here.
--- title: &amp;#34;Hugo Guide&amp;#34; date: 2021-05-01T08:47:11+01:00 categories: [&amp;#34;Manual&amp;#34;] tags: [&amp;#34;Hugo&amp;#34;, &amp;#34;GitHub&amp;#34;] draft: false --- Add pictures
/post/xxx.jpg
is actually baseURL/post/xxx.jpg</description>
    </item>
    
    <item>
      <title>Math</title>
      <link>https://K7288.github.io/posts/math/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/math/</guid>
      <description>$$ e^{ix}=\text{cos}x+i\text{sin}x $$
  $$ \left(C_{n+1, t+1}-C_{n, t}\right)-\left(C_{n, t+1}-C_{n-1, t}\right)=\frac{2}{n+1} $$
  $$ \begin{aligned} C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2} +C_{t+1, t+1}-C_{t, t} \\ &amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) \end{aligned} $$
\begin{aligned} C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2} +C_{t+1, t+1}-C_{t, t} \\\\ &amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) \end{aligned} æ¢è¡Œéœ€è¦ä½¿ç”¨\\\\
\begin{aligned}å’Œ\end{aligned}ä¹‹é—´ä¸èƒ½æœ‰ç©ºè¡Œ
ä¸æ”¯æŒ\left[ï¼Œ\right)ç­‰
  $$ \begin{cases}\begin{array}{l} \theta_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} \theta_{i}(t-j),\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\{r h,l h, r k, l k\}\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases} $$
\begin{cases}\begin{array}{l} \theta_{i}(t-j)^{\prime}=\frac{13} \Sigma_{1}^{-1} \theta_{i}(t-j),\\\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\\{r h,l h, r k, l k\\}\\\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases} \begin{array}å’Œ\end{array}ä¹‹é—´ä¸èƒ½æ¢è¡ŒğŸ˜…</description>
    </item>
    
  </channel>
</rss>
