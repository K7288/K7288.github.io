<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on K7288</title>
    <link>https://K7288.github.io/posts/</link>
    <description>Recent content in Posts on K7288</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 09 Jul 2021 22:00:09 +0800</lastBuildDate><atom:link href="https://K7288.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Before Taking A Recording</title>
      <link>https://K7288.github.io/posts/before-taking-a-recording/</link>
      <pubDate>Fri, 09 Jul 2021 22:00:09 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/before-taking-a-recording/</guid>
      <description>Before Taking A Recording * means &amp;ldquo;optinal&amp;rdquo;; 此处的定义和步骤均参考Tekscan的F-Scan User Manual
Preparing the Patient trim the sensor; set up the testing area; set up the system hardware; weigh the patient; outfit the patient.
*Zeroing the Sensor 当整个实验过程中鞋垫上始终有额外压力时使用；类似称重的去皮；不过新影片都是白色目前应该还没有出现过需要平衡的情况。
*Equilibration 在鞋垫上放置均匀重物；
Calibration Point Calibration 校准时间取决于实际行走过程，快的人1s，慢的2s
先抬起待校准脚，放下同时重量全部集中在该脚上，放下后很快（间隔1s）实验人员点击校准
Extended Calibration 是点校准的延伸；默认开启；在两个均采用点校准的sensor测量完成后基于体重调整两sensor的校准（by an equal amount）to correct for the differing &amp;ldquo;drift&amp;rdquo; times that occur between your calibration and the actual test.
进行此校准要求两脚均必须满3steps $\Rightarrow$ 不然会提示“步态扩展不足”打✔️开启Step Calibration To initiate Step calibration, initially, the subject stands entirely on the foot to be off-loaded.</description>
    </item>
    
    <item>
      <title>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons</title>
      <link>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</link>
      <pubDate>Thu, 08 Jul 2021 14:29:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</guid>
      <description>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons
intention定义: walk/stride across/stop state
Research question  analysis of gait planning based on a human kinematics model and real-time motion stability based on the zero-moment point (ZMP). a neural interface based on sEMG to achieve motion intention recognition and muscle fatigue estimation. to verify the stability of human–exoskeleton system and ergonomic effects of the proposed gait switching method by organized experiments.</description>
    </item>
    
    <item>
      <title>A novel motion intention recognition approach for soft exoskeleton via IMU</title>
      <link>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</link>
      <pubDate>Thu, 08 Jul 2021 09:05:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</guid>
      <description>A novel motion intention recognition approach for soft exoskeleton via IMU
intention定义: the classic five kinds of terrains(including walking on flat ground, going up and downstairs, and up and down slopes) &amp;amp; transformed terrains
   Abbreviation Definition Abbreviation Definition     IMU Inertial measurement unit SA Stair ascent   DDLMI DNN-based deep locomotion mode identification SD Stair decent   ISR Identification success rate RA Ramp ascent   LW Level-ground walking RD Ramp decent    Research question to propose a recognition method with historical information based on neural network to recognize different terrain and add the pattern transformation recognition, trying to predict the next motion mode in advance.</description>
    </item>
    
    <item>
      <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
      <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
      <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
      <description>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach
intention定义: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).
Research question to propose an automatic, user-independent recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.</description>
    </item>
    
    <item>
      <title>Motion control for a walking companion robot with a novel human–robot interface</title>
      <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
      <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
      <description>Motion control for a walking companion robot with a novel human–robot interface
Research question A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.
A new human– robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.
mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states</description>
    </item>
    
    <item>
      <title>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study</title>
      <link>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</link>
      <pubDate>Tue, 06 Jul 2021 22:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</guid>
      <description>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study
intention定义: standing still(stationary), walking or ascending the stairs
Hardware sensors: ADXL345 (an accelerometer; in pelvis unit) and four FSRs (two in each foot for heel and toe respectively)
Algorithm   gait adaptation: detect in which phase of the gait cycle the subject is
  adaptive frequency oscillators (AFO) $\Leftarrow$ Since the human gait cycle is periodic, the acceleration signals obtained from the pelvis unit is also periodic in nature.</description>
    </item>
    
    <item>
      <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
      <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
      <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
      <description>A lower limb exoskeleton based on recognition of lower limb walking intention
intention定义: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination
Introduction   Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driver’s intention, and human–robot interface.
  three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.</description>
    </item>
    
    <item>
      <title>Intention Recgonition for Exoskeleton</title>
      <link>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</link>
      <pubDate>Tue, 06 Jul 2021 13:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</guid>
      <description>Intention Recgonition for Exoskeleton
intention定义: walk/stand
assistance exoskeleton system   支持4种state: L swing, R swing, Double stance(L), Double stance(R)
  control
  Methods online SVM; features: ZMP(Zero Moment Point), IMU
  ZMP
  concept: The distributed floor reaction force can be replaced by a single force R acts on ZMP.
  ZMP can be obtained from ground reaction force (GRF) measurement or inverse dynamics of system.</description>
    </item>
    
    <item>
      <title>页内跳转</title>
      <link>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</link>
      <pubDate>Mon, 05 Jul 2021 16:52:26 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</guid>
      <description>这是一段文字，我想跳转到这里。
⏬
⏬
⏬
我实现了跳转。
&amp;lt;a id=&amp;#34;series&amp;#34;&amp;gt;&amp;lt;/a&amp;gt;这是一段文字，我想跳转到这里。 ⏬ ⏬ ⏬ &amp;lt;a class=&amp;#34;link&amp;#34; href=&amp;#34;#series&amp;#34;&amp;gt;我实现了跳转。&amp;lt;/a&amp;gt; </description>
    </item>
    
    <item>
      <title>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses</title>
      <link>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</guid>
      <description>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses
intention定义—locomotion modes: level walking, ramp ascent, ramp descent, stair ascent, and stair descent
Research question to develop a user-independent intent recognition system capable of recognizing level-ground walking, slopes, and stairs and to compare this system with a user-dependent intent recognition system.
Introduction  Prior studies in which pattern recognition algorithms: current methods to initiate transitions between modes, such as visual, audio, or compensatory movement commands, are unintuitive and impose a cognitive burden.</description>
    </item>
    
    <item>
      <title>Multi-sensor based human motion intention recognition algorithm for walking-aid robot</title>
      <link>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</guid>
      <description>Multi-sensor based human motion intention recognition algorithm for walking-aid robot
intention定义：velocity; 这里表征为一个自定概念IM
Research question A multi-sensor(force sensors and LRF; for both lower and upper limbs) based human motion intention recognition algorithm for walking-aid robot.
Introduction  assistive rehabilitation robots: PAMM, Walking Helper, HAL, Omni RT Walker-II (ORTW-II) 简略说了一些human motion estimation methods  Methods  Sensors: push-pull force sensors and LRF(Laser Range Finder)    LRF: Range Segmentation, Identification of Circle, Leg detection, Intention detection</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://K7288.github.io/posts/terms/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/terms/</guid>
      <description>Terms Definition     inertia matrix    damping matrix    stiffness matrix    centripetal and Coriolis matrix    Cartesian coordinate    mass-damper-spring model    impedance control    admittance control 导纳控制    push-off impulse time    transition function    adaptive frequency oscillators    one-way ANOVA    two-way ANOVA    a neural interface    linear discriminant analysis    drift(signal/integral/zero/integral/temperature drift)     time-varying, adaptive compensation term, manifold, coarse/fine-grained level granularity, an inertial frame, oscillator, denominator,</description>
    </item>
    
    <item>
      <title>行文常见说法</title>
      <link>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</guid>
      <description>prior studies/research
Experimental Protocol
Representative diagram
the integrated design
cognitive effort
methodology</description>
    </item>
    
    <item>
      <title>A review of human activity recognition methods</title>
      <link>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</link>
      <pubDate>Thu, 01 Jul 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</guid>
      <description>A review of human activity recognition methods
Recognizing human activities from video sequences or still images
intention定义: activity; 一个描述性词
Usually, the terms “activity” and “behavior” are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term “activity” is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term “behavior” is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.</description>
    </item>
    
    <item>
      <title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>
      <link>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</link>
      <pubDate>Tue, 29 Jun 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</guid>
      <description>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intention定义：velocity+trajectory; 只涉及到一个接触点
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.</description>
    </item>
    
    <item>
      <title>Froude Numbers</title>
      <link>https://K7288.github.io/posts/froude-numbers/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/froude-numbers/</guid>
      <description>The Gaits of Bipedal and Quadrupedal Animals Alexander R. The gaits of bipedal and quadrupedal animals. The International Journal of Robotics Research. 1984;
mammals of different sizes tend to move in dynamically similar fashion whenever their Froude numbers $u^2 /gh$ are equal: here u is speed, g is the acceleration of free fall, and h is the height of the hip joint from the ground.
Research Problem description of the gaits of two- and four-legged animals and some of the important optimization criteria(e.</description>
    </item>
    
    <item>
      <title>F-Scan</title>
      <link>https://K7288.github.io/posts/f-scan/</link>
      <pubDate>Tue, 18 May 2021 14:21:37 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/f-scan/</guid>
      <description>Details 采样频率：$50\text{Hz}$
测力点尺寸：$5.1\times5.1(\text{mm})$
翻译问题：
 力度 $\Rightarrow$ 力 压力 $\Rightarrow$ 压强  测力片无所谓正反
流程 裁剪（只要不剪断横向线路即可）
部署（信号采集/通信装置用魔力贴固定在小腿，插上测力片）
校准（需要被试单脚站立各5s）
在fsx窗口右键“单位”选择单位和精度
录制
数据导出 1.完整数据：选中相应fsx窗口在“文件”中导出
格式：每一帧的全部测力点所测压强（包括灰色边界&amp;quot;B&amp;quot;和剪去的测力点）
单位：自选，会在导出的csv文件头列出
写了计算每一帧总压力的代码，也可用采样区选中整个区域得到总压力
2.取样区
所在窗格右键“对象”导出 或者直接在生成的图线上ctrl+c粘贴到excel
格式：不保留每个采样点信息，只有整体数据（这一个区域的总压力/压强等）
在右键&amp;quot;属性&amp;quot;中可以更改采样区显示的信息</description>
    </item>
    
    <item>
      <title>Hugo HTML Tips</title>
      <link>https://K7288.github.io/posts/hugo-html-tips/</link>
      <pubDate>Tue, 18 May 2021 11:23:29 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/hugo-html-tips/</guid>
      <description>  原生html支持
hugo采用goldmark作为默认渲染器，需要在config中开启
   markup:goldmark:renderer:unsafe: truehtml 图片需要绝对路径，形式如下：  &amp;lt;img src=&amp;quot;/assets/image-20210416142714352.png&amp;quot; alt=&amp;quot;image-20210416142714352&amp;quot; style=&amp;quot;zoom:33%;&amp;quot; /&amp;gt;而不能是src=&amp;quot;assets\ 所以也不太支持网络图片&amp;hellip;&amp;hellip;
****好像不能出现。  </description>
    </item>
    
    <item>
      <title>(Draft)Image Processing and Computer Vision</title>
      <link>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</guid>
      <description>参考书目 Digital Image Processing by Rafael C. Gonzalez, Richard E. Woods, 3rd Edition
 第一章 数字图像的采集方式以及特性  1.1 图像概述 1.2 图像数字化  1.2.1图像数字化——采样  一维连续信号的采样 二维连续图像信号的采样  二维Nyquist条件 亚采样     1.2.2图像数字化——量化   1.3 数字图像基本要素  1.3.1基本要素 1.3.2图像质量 1.3.3图像颜色：红、绿、蓝三基色 1.3.4图像的描述：灰度/黑白/彩色图像、链表、拓扑结构、距离 1.3.5图像的矩阵特性：距离、邻域、临接、连通 1.3.6图像文件格式   1.4 数字图像处理意义及内容 1.5 数字图像处理系统及应用  1.5.1数字图像特性：图像/显示分辨率/打印机分辨率 像素深度 位面数量 1.5.2数字图像处理系统     第二章 数字图像预处理方法  2.1 灰度化  2.1.1灰度化主要方法 2.1.2图像二值化  1.全局二值化 2.</description>
    </item>
    
    <item>
      <title>The effect of stride length on lower extremity joint kinetics at various gait speeds</title>
      <link>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</link>
      <pubDate>Sun, 16 May 2021 10:44:02 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</guid>
      <description>The effect of stride length on lower extremity joint kinetics at various gait speeds
 Research question Concepts Notations Background Materials and Methods  Data analysis  1. 数据处理 2. Protocol validation 3. Continuum analysis  main effect analysis SL   4. Torque pulse approximation     Results  Protocol validation Continuum analysis Torque pulse approximation   Conclusion Limits/Further Work Thoughts/Comments  Research question In this study, we investigated how sagittal plane joint moments are affected by a factorial modulation of two important gait parameters: gait speed and stride length.</description>
    </item>
    
    <item>
      <title>Menu</title>
      <link>https://K7288.github.io/posts/menu/</link>
      <pubDate>Sun, 16 May 2021 10:35:13 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/menu/</guid>
      <description>实现页内跳转  基本语法 注意事项 A subtitle just for test 测试 a A  测试——测试 测试:一个测试   1.测试   目录实现  实现页内跳转 基本语法 [&amp;lt;提示语&amp;gt;](#&amp;lt;目标内容&amp;gt;)注意事项   若标题是英文，在(#&amp;lt;目标内容&amp;gt;)中需要小写
例如 [例如](#a-subtitle-just-for-test)
  若标题中出现空格，需要用-连接
例如 [例如](#测试-a-a)
  (#&amp;lt;目标内容&amp;gt;)中不能出现半角点(即英文中的句号).，似乎也不支持其他标点，(#&amp;lt;目标内容&amp;gt;)中需要将标点删除
测试:一个测试 [测试:一个测试](#测试一个测试)
1.测试 [1.测试](#1测试)
测试——测试 [测试——测试](#测试测试)
  A subtitle just for test 测试 a A 测试——测试 测试:一个测试 1.测试 目录实现  VS code插件 Markdown All in One  ctrl+shift+p Markdown All in One: Create Table of Contents   TOD0 实现侧边目录   😂 已经出现了对“测”的完型崩坏</description>
    </item>
    
    <item>
      <title>步速估计综述整理</title>
      <link>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</link>
      <pubDate>Wed, 12 May 2021 22:17:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</guid>
      <description>Toward Pervasive Gait Analysis With Wearable Sensors: A Systematic Review Abstract 对当前的定量步态分析技术进行系统的综述，并提出关键指标，来评估现有的通过可穿戴传感器提取步态特征的方法。它旨在突出这一快速发展的研究领域中的关键进展，并概述研究和临床应用的潜在未来方向。
SECTION III. Methods for Extracting Relevant Gait Features From Wearable Sensors A.文献检索
B. Kinematics
Kinematic information is a well-established set of gait measures in biomechanical analysis.
从惯性传感器获取运动学信息似乎很直观，但是要获得关于人体运动学的准确空间信息仍然很困难：全局失准和integration drift
C.时序特征
D.利用惯性传感器的步速提取
Laudanski et al. [104] reviewed the current research (16 papers in total) on gait speed estimation using inertial sensors, classifying the current gait speed estimation model into three categories: abstraction model (i.</description>
    </item>
    
    <item>
      <title>基于几何与物理特征融合的智能下肢假肢运动意图识别</title>
      <link>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</link>
      <pubDate>Wed, 12 May 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</guid>
      <description>基于几何与物理特征融合的智能下肢假肢运动意图识别Movement intention recognition of intelligent lower limb prosthesis based on the fusion of geometric and physical features
intention定义—locomotion modes 5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡，8类转换模式
Research question 将关节角表示的几何特征与加速度、角速度表示的物理特征有机融合并应用于智能下肢假肢的运动意图识别
Introduction 传统的意图识别方法所用传感器数量及种类较多, 特征向量维数偏高, 统计特征对短时样本具有不稳定性（在1.3 特征选择与提取有公式证明）。related work没有结合几何和物理。
Methods   采样：健侧大腿、小腿惯性测量单元于摆动相前期所产生的运动时序数据作为样本；
  数据处理：移动平均滤波器滤波去噪
  特征提取：
 几何特征：根据两个传感器的加速度、角速度计算一维的膝关节角，FDA方法提取最值斜率 物理特征：加速度、角速度的均值、方差  均值、方差、最值斜率融合构成25维的特征基构建特征向量
  SVM分类
  Results 13种日常行为进行分类。实验结果：对5类稳态模式: 平地行走、上楼、下楼、上坡和 下坡的识别率达到96.9%, 对8类转换模式的识别率达到97.1%, 对13 种模式的识别率为94.3%。
Highlights 减少了传感器的数量及种类, 降低 了特征向量的维数降低了算法复杂度且避免了滞后性问题, 用加速度、 角速度及膝关节角三个参数共同对人体下肢运动的运动学特点进行表征。
在特征的提取上, 将FDA方法与统计方法相结合, 弥补了仅提取统计特征的不稳定性问题。
Limits/Further Work 对于13种动作的识别率有待提高, 后期工作会集中于对类间相似性相对较强较难区分的动作进行分类, 如: 下楼与下坡, 走到下楼 与走到下坡等.</description>
    </item>
    
    <item>
      <title>Gait Analysis Systems</title>
      <link>https://K7288.github.io/posts/gait-analysis-systems/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/gait-analysis-systems/</guid>
      <description>&amp;ldquo;Section Four - Gait Analysis Systems&amp;rdquo; from Gait Analysis: Normal and Pathological Function1
Basically, there are 5 measurement systems.
Three of these focus on the specific events that constitute the act of walking.
行走各个阶段
 Motion analysis defines the magnitude and timing of individual joint action. Dynamic electromyography iden­tifies the period and relative intensity of muscle function. Force plate recordings display the functional demands being experienced during the weight-bearing period.  The two remaining gait analysis technics summarize the effects of the person&amp;rsquo;s gait mechanics.</description>
    </item>
    
    <item>
      <title>Gait Analysis Fundamentals</title>
      <link>https://K7288.github.io/posts/gait-analysis-fundamentals/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/gait-analysis-fundamentals/</guid>
      <description>Gait analysis 步态分析简述1 Factors and parameters 影响步态的因素 The gait analysis is modulated or modified by many factors, and changes in the normal gait pattern can be transient or permanent. The factors can be of various types:
 Extrinsic: such as terrain, footwear, clothing, cargo Intrinsic: sex, weight, height, age, etc. Physical: such as weight, height, physique Psychological: personality type, emotions Physiological: anthropometric characteristics, i.e., measurements and proportions of body Pathological: for example trauma, neurological diseases, musculoskeletal anomalies, psychiatric disorders  Parameters 描述步态的参数 The parameters taken into account for the gait analysis are as follows:</description>
    </item>
    
    <item>
      <title>Hugo Guide</title>
      <link>https://K7288.github.io/posts/hugo-guide/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/hugo-guide/</guid>
      <description>About Contents Add Some Content hugo new post/**.md
The newly created content file will start with something like this:
---title: &amp;quot;**&amp;quot;date: 2019-03-26T08:47:11+01:00draft: true---Drafts do not get deployed; once you finish a post, update the header of the post to say draft: false. More info here.
---title: &amp;quot;Hugo Guide&amp;quot;date: 2021-05-01T08:47:11+01:00categories: [&amp;quot;Manual&amp;quot;]tags: [&amp;quot;Hugo&amp;quot;, &amp;quot;GitHub&amp;quot;]draft: false---Add pictures
/post/xxx.jpg
is actually baseURL/post/xxx.jpg</description>
    </item>
    
    <item>
      <title>Math</title>
      <link>https://K7288.github.io/posts/math/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/math/</guid>
      <description>$$ e^{ix}=\text{cos}x+i\text{sin}x $$
  $$ \left(C_{n+1, t+1}-C_{n, t}\right)-\left(C_{n, t+1}-C_{n-1, t}\right)=\frac{2}{n+1} $$
  $$ \begin{aligned} C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2} +C_{t+1, t+1}-C_{t, t} \\ &amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) \end{aligned} $$
\begin{aligned} C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2} +C_{t+1, t+1}-C_{t, t} \\\\ &amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) \end{aligned} 换行需要使用\\\\
\begin{aligned}和\end{aligned}之间不能有空行
不支持\left[，\right)等
  $$ \begin{cases}\begin{array}{l} \theta_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} \theta_{i}(t-j),\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\{r h,l h, r k, l k\}\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases} $$
\begin{cases}\begin{array}{l} \theta_{i}(t-j)^{\prime}=\frac{13} \Sigma_{1}^{-1} \theta_{i}(t-j),\\\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\\{r h,l h, r k, l k\\}\\\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases} \begin{array}和\end{array}之间不能换行😅</description>
    </item>
    
    <item>
      <title>论文3篇泛读 1-&gt;measurement可靠性(方法比较奇怪或者没有) 2/3-&gt;步态参数拟合</title>
      <link>https://K7288.github.io/posts/measurement%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83%E5%A5%87%E6%80%AA%E6%88%96%E8%80%85%E6%B2%A1%E6%9C%89-%E6%AD%A5%E6%80%81%E5%8F%82%E6%95%B0%E6%8B%9F%E5%90%88/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/measurement%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83%E5%A5%87%E6%80%AA%E6%88%96%E8%80%85%E6%B2%A1%E6%9C%89-%E6%AD%A5%E6%80%81%E5%8F%82%E6%95%B0%E6%8B%9F%E5%90%88/</guid>
      <description>因为不熟悉心相关研究问题，之前做笔记的次数也少，这几篇Literature Notes结构不够清晰，而且过长，下次注意。
三篇文献与选题的关联性差强人意，之后留意/请教一下如何有效查找文献。
1. Reliability of centre of pressure, plantar pressure, and plantar-flexion isometric strength measures: A systematic review COP PP PFisom 三种步态控制measurement 的可靠性
方法：对三个数据库实验进行同行评估 ICC
Background Centre of pressure (COP), plantar pressure (PP), and plantar-flexion isometric strength (PFisom) are often examined in relation to postural control and gait.
Research question Our aim was to systematically review and quality appraise articles addressing the reliability of COP and PP measures in static stance and PFisom measures.</description>
    </item>
    
  </channel>
</rss>
