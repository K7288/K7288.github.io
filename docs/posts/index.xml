<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on K7288</title>
    <link>https://K7288.github.io/posts/</link>
    <description>Recent content in Posts on K7288</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 09 Jul 2021 22:00:09 +0800</lastBuildDate><atom:link href="https://K7288.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Before Taking A Recording</title>
      <link>https://K7288.github.io/posts/before-taking-a-recording/</link>
      <pubDate>Fri, 09 Jul 2021 22:00:09 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/before-taking-a-recording/</guid>
      <description>Before Taking A Recording * means &amp;ldquo;optinal&amp;rdquo;; æ­¤å¤„çš„å®šä¹‰å’Œæ­¥éª¤å‡å‚è€ƒTekscançš„F-Scan User Manual
Preparing the Patient trim the sensor; set up the testing area; set up the system hardware; weigh the patient; outfit the patient.
*Zeroing the Sensor å½“æ•´ä¸ªå®éªŒè¿‡ç¨‹ä¸­é‹å«ä¸Šå§‹ç»ˆæœ‰é¢å¤–å‹åŠ›æ—¶ä½¿ç”¨ï¼›ç±»ä¼¼ç§°é‡çš„å»çš®ï¼›ä¸è¿‡æ–°å½±ç‰‡éƒ½æ˜¯ç™½è‰²ç›®å‰åº”è¯¥è¿˜æ²¡æœ‰å‡ºç°è¿‡éœ€è¦å¹³è¡¡çš„æƒ…å†µã€‚
*Equilibration åœ¨é‹å«ä¸Šæ”¾ç½®å‡åŒ€é‡ç‰©ï¼›
Calibration Point Calibration æ ¡å‡†æ—¶é—´å–å†³äºå®é™…è¡Œèµ°è¿‡ç¨‹ï¼Œå¿«çš„äºº1sï¼Œæ…¢çš„2s
å…ˆæŠ¬èµ·å¾…æ ¡å‡†è„šï¼Œæ”¾ä¸‹åŒæ—¶é‡é‡å…¨éƒ¨é›†ä¸­åœ¨è¯¥è„šä¸Šï¼Œæ”¾ä¸‹åå¾ˆå¿«ï¼ˆé—´éš”1sï¼‰å®éªŒäººå‘˜ç‚¹å‡»æ ¡å‡†
Extended Calibration æ˜¯ç‚¹æ ¡å‡†çš„å»¶ä¼¸ï¼›é»˜è®¤å¼€å¯ï¼›åœ¨ä¸¤ä¸ªå‡é‡‡ç”¨ç‚¹æ ¡å‡†çš„sensoræµ‹é‡å®ŒæˆååŸºäºä½“é‡è°ƒæ•´ä¸¤sensorçš„æ ¡å‡†ï¼ˆby an equal amountï¼‰to correct for the differing &amp;ldquo;drift&amp;rdquo; times that occur between your calibration and the actual test.
è¿›è¡Œæ­¤æ ¡å‡†è¦æ±‚ä¸¤è„šå‡å¿…é¡»æ»¡3steps $\Rightarrow$ ä¸ç„¶ä¼šæç¤ºâ€œæ­¥æ€æ‰©å±•ä¸è¶³â€æ‰“âœ”ï¸å¼€å¯Step Calibration To initiate Step calibration, initially, the subject stands entirely on the foot to be off-loaded.</description>
    </item>
    
    <item>
      <title>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons</title>
      <link>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</link>
      <pubDate>Thu, 08 Jul 2021 14:29:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-real-time-stability-control-method-through-semg-interface-for-lower-extremity-rehabilitation-exoskeletons/</guid>
      <description>A Real-Time Stability Control Method Through sEMG Interface for Lower Extremity Rehabilitation Exoskeletons
intentionå®šä¹‰: walk/stride across/stop state
Research question  analysis of gait planning based on a human kinematics model and real-time motion stability based on the zero-moment point (ZMP). a neural interface based on sEMG to achieve motion intention recognition and muscle fatigue estimation. to verify the stability of humanâ€“exoskeleton system and ergonomic effects of the proposed gait switching method by organized experiments.</description>
    </item>
    
    <item>
      <title>A novel motion intention recognition approach for soft exoskeleton via IMU</title>
      <link>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</link>
      <pubDate>Thu, 08 Jul 2021 09:05:01 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-novel-motion-intention-recognition-approach-for-soft-exoskeleton-via-imu/</guid>
      <description>A novel motion intention recognition approach for soft exoskeleton via IMU
intentionå®šä¹‰: the classic five kinds of terrains(including walking on flat ground, going up and downstairs, and up and down slopes) &amp;amp; transformed terrains
   Abbreviation Definition Abbreviation Definition     IMU Inertial measurement unit SA Stair ascent   DDLMI DNN-based deep locomotion mode identification SD Stair decent   ISR Identification success rate RA Ramp ascent   LW Level-ground walking RD Ramp decent    Research question to propose a recognition method with historical information based on neural network to recognize different terrain and add the pattern transformation recognition, trying to predict the next motion mode in advance.</description>
    </item>
    
    <item>
      <title>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach</title>
      <link>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</link>
      <pubDate>Wed, 07 Jul 2021 17:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/daily-locomotion-recognition-and-prediction-a-kinematic-data-based-machine-learning-approach/</guid>
      <description>Daily Locomotion Recognition and Prediction: A Kinematic Data-Based Machine Learning Approach
intentionå®šä¹‰: locomotion modes (LMs; walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective locomotion mode transitions(LMTs).
Research question to propose an automatic, user-independent recognition and prediction tool using easily wearable kinematic motion sensors for innovatively classifying several LMs (walking direction, level-ground walking, ascend and descend stairs, and ascend and descend ramps) and respective LMTs.</description>
    </item>
    
    <item>
      <title>Motion control for a walking companion robot with a novel humanâ€“robot interface</title>
      <link>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</link>
      <pubDate>Wed, 07 Jul 2021 14:00:00 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/motion-control-for-a-walking-companion-robot-with-a-novel-humanrobot-interface/</guid>
      <description>Motion control for a walking companion robot with a novel humanâ€“robot interface
Research question A walking companion robot is presented for rehabilitation from dyskinesia of lower limbs and its motion control algorithms.
A new humanâ€“ robot interface (HRI) adopts one-axis force sensor and potentiometer connector to detect the motion of the user with the common motions classified into two elemental motion states.
mathematical model-based control method and force control method $\Leftarrow$ distinction of motion states</description>
    </item>
    
    <item>
      <title>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study</title>
      <link>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</link>
      <pubDate>Tue, 06 Jul 2021 22:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-detection-and-gait-recognition_idgr_system-for-gait-assessment-a-pilot-study/</guid>
      <description>Intention Detection and Gait Recognition (IDGR) System for Gait Assessment: A Pilot Study
intentionå®šä¹‰: standing still(stationary), walking or ascending the stairs
Hardware sensors: ADXL345 (an accelerometer; in pelvis unit) and four FSRs (two in each foot for heel and toe respectively)
Algorithm   gait adaptation: detect in which phase of the gait cycle the subject is
  adaptive frequency oscillators (AFO) $\Leftarrow$ Since the human gait cycle is periodic, the acceleration signals obtained from the pelvis unit is also periodic in nature.</description>
    </item>
    
    <item>
      <title>A lower limb exoskeleton based on recognition of lower limb walking intention</title>
      <link>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</link>
      <pubDate>Tue, 06 Jul 2021 16:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-lower-limb-exoskeleton-based-on-recognition-of-lower-limb-walking-intention/</guid>
      <description>A lower limb exoskeleton based on recognition of lower limb walking intention
intentionå®šä¹‰: step initiation $\Leftarrow$ intersection event, continuous walking (normal step velocity $\Leftarrow$ push-off impulse time), acceleration, deceleration, and step termination
Introduction   Key technologies in lower limb exoskeletons are actuator, mechanical design, control, sensor, recognition of the driverâ€™s intention, and humanâ€“robot interface.
  three representative lower limb exoskeletons: Berkeley Lower Extremity Exoskeleton (BLEEX), Hybrid Assistive Leg (HAL), and ReWalk.</description>
    </item>
    
    <item>
      <title>Intention Recgonition for Exoskeleton</title>
      <link>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</link>
      <pubDate>Tue, 06 Jul 2021 13:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-for-exoskeleton/</guid>
      <description>Intention Recgonition for Exoskeleton
intentionå®šä¹‰: walk/stand
assistance exoskeleton system   æ”¯æŒ4ç§state: L swing, R swing, Double stance(L), Double stance(R)
  control
  Methods online SVM; features: ZMP(Zero Moment Point), IMU
  ZMP
  concept: The distributed floor reaction force can be replaced by a single force R acts on ZMP.
  ZMP can be obtained from ground reaction force (GRF) measurement or inverse dynamics of system.</description>
    </item>
    
    <item>
      <title>é¡µå†…è·³è½¬</title>
      <link>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</link>
      <pubDate>Mon, 05 Jul 2021 16:52:26 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E9%A1%B5%E5%86%85%E8%B7%B3%E8%BD%AC/</guid>
      <description>è¿™æ˜¯ä¸€æ®µæ–‡å­—ï¼Œæˆ‘æƒ³è·³è½¬åˆ°è¿™é‡Œã€‚
â¬
â¬
â¬
æˆ‘å®ç°äº†è·³è½¬ã€‚
&amp;lt;a id=&amp;#34;series&amp;#34;&amp;gt;&amp;lt;/a&amp;gt;è¿™æ˜¯ä¸€æ®µæ–‡å­—ï¼Œæˆ‘æƒ³è·³è½¬åˆ°è¿™é‡Œã€‚ â¬ â¬ â¬ &amp;lt;a class=&amp;#34;link&amp;#34; href=&amp;#34;#series&amp;#34;&amp;gt;æˆ‘å®ç°äº†è·³è½¬ã€‚&amp;lt;/a&amp;gt; </description>
    </item>
    
    <item>
      <title>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses</title>
      <link>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/a-classification-method-for-user-independent-intent-recognition-for-transfemoral-amputees-using-powered-lower-limb-prostheses/</guid>
      <description>A Classification Method for User-Independent Intent Recognition for Transfemoral Amputees Using Powered Lower Limb Prostheses
intentionå®šä¹‰â€”locomotion modes: level walking, ramp ascent, ramp descent, stair ascent, and stair descent
Research question to develop a user-independent intent recognition system capable of recognizing level-ground walking, slopes, and stairs and to compare this system with a user-dependent intent recognition system.
Introduction  Prior studies in which pattern recognition algorithms: current methods to initiate transitions between modes, such as visual, audio, or compensatory movement commands, are unintuitive and impose a cognitive burden.</description>
    </item>
    
    <item>
      <title>Multi-sensor based human motion intention recognition algorithm for walking-aid robot</title>
      <link>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/</guid>
      <description>Multi-sensor based human motion intention recognition algorithm for walking-aid robot
intentionå®šä¹‰ï¼švelocity; è¿™é‡Œè¡¨å¾ä¸ºä¸€ä¸ªè‡ªå®šæ¦‚å¿µIM
Research question A multi-sensor(force sensors and LRF; for both lower and upper limbs) based human motion intention recognition algorithm for walking-aid robot.
Introduction  assistive rehabilitation robots: PAMM, Walking Helper, HAL, Omni RT Walker-II (ORTW-II) ç®€ç•¥è¯´äº†ä¸€äº›human motion estimation methods  Methods  Sensors: push-pull force sensors and LRF(Laser Range Finder)    LRF: Range Segmentation, Identification of Circle, Leg detection, Intention detection</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>https://K7288.github.io/posts/terms/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/terms/</guid>
      <description>Terms Definition     inertia matrix    damping matrix    stiffness matrix    centripetal and Coriolis matrix    Cartesian coordinate    mass-damper-spring model    impedance control    admittance control å¯¼çº³æ§åˆ¶    push-off impulse time    transition function    adaptive frequency oscillators    one-way ANOVA    two-way ANOVA    a neural interface    linear discriminant analysis    drift(signal/integral/zero/integral/temperature drift)     time-varying, adaptive compensation term, manifold, coarse/fine-grained level granularity, an inertial frame, oscillator, denominator,</description>
    </item>
    
    <item>
      <title>è¡Œæ–‡å¸¸è§è¯´æ³•</title>
      <link>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/%E8%A1%8C%E6%96%87%E5%B8%B8%E8%A7%81%E8%AF%B4%E6%B3%95/</guid>
      <description>prior studies/research
Experimental Protocol
Representative diagram
the integrated design
cognitive effort
methodology</description>
    </item>
    
    <item>
      <title>A review of human activity recognition methods</title>
      <link>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</link>
      <pubDate>Thu, 01 Jul 2021 00:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/a-review-of-human-activity-recognition-methods/</guid>
      <description>A review of human activity recognition methods
Recognizing human activities from video sequences or still images
intentionå®šä¹‰: activity; ä¸€ä¸ªæè¿°æ€§è¯
Usually, the terms â€œactivityâ€ and â€œbehaviorâ€ are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term â€œactivityâ€ is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term â€œbehaviorâ€ is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.</description>
    </item>
    
    <item>
      <title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>
      <link>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</link>
      <pubDate>Tue, 29 Jun 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/</guid>
      <description>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intentionå®šä¹‰ï¼švelocity+trajectory; åªæ¶‰åŠåˆ°ä¸€ä¸ªæ¥è§¦ç‚¹
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.</description>
    </item>
    
    <item>
      <title>Froude Numbers</title>
      <link>https://K7288.github.io/posts/froude-numbers/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/froude-numbers/</guid>
      <description>The Gaits of Bipedal and Quadrupedal Animals Alexander R. The gaits of bipedal and quadrupedal animals. The International Journal of Robotics Research. 1984;
mammals of different sizes tend to move in dynamically similar fashion whenever their Froude numbers $u^2 /gh$ are equal: here u is speed, g is the acceleration of free fall, and h is the height of the hip joint from the ground.
Research Problem description of the gaits of two- and four-legged animals and some of the important optimization criteria(e.</description>
    </item>
    
    <item>
      <title>F-Scan</title>
      <link>https://K7288.github.io/posts/f-scan/</link>
      <pubDate>Tue, 18 May 2021 14:21:37 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/f-scan/</guid>
      <description>Details é‡‡æ ·é¢‘ç‡ï¼š$50\text{Hz}$
æµ‹åŠ›ç‚¹å°ºå¯¸ï¼š$5.1\times5.1(\text{mm})$
ç¿»è¯‘é—®é¢˜ï¼š
 åŠ›åº¦ $\Rightarrow$ åŠ› å‹åŠ› $\Rightarrow$ å‹å¼º  æµ‹åŠ›ç‰‡æ— æ‰€è°“æ­£å
æµç¨‹ è£å‰ªï¼ˆåªè¦ä¸å‰ªæ–­æ¨ªå‘çº¿è·¯å³å¯ï¼‰
éƒ¨ç½²ï¼ˆä¿¡å·é‡‡é›†/é€šä¿¡è£…ç½®ç”¨é­”åŠ›è´´å›ºå®šåœ¨å°è…¿ï¼Œæ’ä¸Šæµ‹åŠ›ç‰‡ï¼‰
æ ¡å‡†ï¼ˆéœ€è¦è¢«è¯•å•è„šç«™ç«‹å„5sï¼‰
åœ¨fsxçª—å£å³é”®â€œå•ä½â€é€‰æ‹©å•ä½å’Œç²¾åº¦
å½•åˆ¶
æ•°æ®å¯¼å‡º 1.å®Œæ•´æ•°æ®ï¼šé€‰ä¸­ç›¸åº”fsxçª—å£åœ¨â€œæ–‡ä»¶â€ä¸­å¯¼å‡º
æ ¼å¼ï¼šæ¯ä¸€å¸§çš„å…¨éƒ¨æµ‹åŠ›ç‚¹æ‰€æµ‹å‹å¼ºï¼ˆåŒ…æ‹¬ç°è‰²è¾¹ç•Œ&amp;quot;B&amp;quot;å’Œå‰ªå»çš„æµ‹åŠ›ç‚¹ï¼‰
å•ä½ï¼šè‡ªé€‰ï¼Œä¼šåœ¨å¯¼å‡ºçš„csvæ–‡ä»¶å¤´åˆ—å‡º
å†™äº†è®¡ç®—æ¯ä¸€å¸§æ€»å‹åŠ›çš„ä»£ç ï¼Œä¹Ÿå¯ç”¨é‡‡æ ·åŒºé€‰ä¸­æ•´ä¸ªåŒºåŸŸå¾—åˆ°æ€»å‹åŠ›
2.å–æ ·åŒº
æ‰€åœ¨çª—æ ¼å³é”®â€œå¯¹è±¡â€å¯¼å‡º æˆ–è€…ç›´æ¥åœ¨ç”Ÿæˆçš„å›¾çº¿ä¸Šctrl+cç²˜è´´åˆ°excel
æ ¼å¼ï¼šä¸ä¿ç•™æ¯ä¸ªé‡‡æ ·ç‚¹ä¿¡æ¯ï¼Œåªæœ‰æ•´ä½“æ•°æ®ï¼ˆè¿™ä¸€ä¸ªåŒºåŸŸçš„æ€»å‹åŠ›/å‹å¼ºç­‰ï¼‰
åœ¨å³é”®&amp;quot;å±æ€§&amp;quot;ä¸­å¯ä»¥æ›´æ”¹é‡‡æ ·åŒºæ˜¾ç¤ºçš„ä¿¡æ¯</description>
    </item>
    
    <item>
      <title>Hugo HTML Tips</title>
      <link>https://K7288.github.io/posts/hugo-html-tips/</link>
      <pubDate>Tue, 18 May 2021 11:23:29 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/hugo-html-tips/</guid>
      <description>  åŸç”Ÿhtmlæ”¯æŒ
hugoé‡‡ç”¨goldmarkä½œä¸ºé»˜è®¤æ¸²æŸ“å™¨ï¼Œéœ€è¦åœ¨configä¸­å¼€å¯
   markup:goldmark:renderer:unsafe: truehtml å›¾ç‰‡éœ€è¦ç»å¯¹è·¯å¾„ï¼Œå½¢å¼å¦‚ä¸‹ï¼š  &amp;lt;img src=&amp;quot;/assets/image-20210416142714352.png&amp;quot; alt=&amp;quot;image-20210416142714352&amp;quot; style=&amp;quot;zoom:33%;&amp;quot; /&amp;gt;è€Œä¸èƒ½æ˜¯src=&amp;quot;assets\ æ‰€ä»¥ä¹Ÿä¸å¤ªæ”¯æŒç½‘ç»œå›¾ç‰‡&amp;hellip;&amp;hellip;
****å¥½åƒä¸èƒ½å‡ºç°ã€‚  </description>
    </item>
    
    <item>
      <title>(Draft)Image Processing and Computer Vision</title>
      <link>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/draftimage-processing-and-computer-vision/</guid>
      <description>å‚è€ƒä¹¦ç›® Digital Image Processing by Rafael C. Gonzalez, Richard E. Woods, 3rd Edition
 ç¬¬ä¸€ç«  æ•°å­—å›¾åƒçš„é‡‡é›†æ–¹å¼ä»¥åŠç‰¹æ€§  1.1 å›¾åƒæ¦‚è¿° 1.2 å›¾åƒæ•°å­—åŒ–  1.2.1å›¾åƒæ•°å­—åŒ–â€”â€”é‡‡æ ·  ä¸€ç»´è¿ç»­ä¿¡å·çš„é‡‡æ · äºŒç»´è¿ç»­å›¾åƒä¿¡å·çš„é‡‡æ ·  äºŒç»´Nyquistæ¡ä»¶ äºšé‡‡æ ·     1.2.2å›¾åƒæ•°å­—åŒ–â€”â€”é‡åŒ–   1.3 æ•°å­—å›¾åƒåŸºæœ¬è¦ç´   1.3.1åŸºæœ¬è¦ç´  1.3.2å›¾åƒè´¨é‡ 1.3.3å›¾åƒé¢œè‰²ï¼šçº¢ã€ç»¿ã€è“ä¸‰åŸºè‰² 1.3.4å›¾åƒçš„æè¿°ï¼šç°åº¦/é»‘ç™½/å½©è‰²å›¾åƒã€é“¾è¡¨ã€æ‹“æ‰‘ç»“æ„ã€è·ç¦» 1.3.5å›¾åƒçš„çŸ©é˜µç‰¹æ€§ï¼šè·ç¦»ã€é‚»åŸŸã€ä¸´æ¥ã€è¿é€š 1.3.6å›¾åƒæ–‡ä»¶æ ¼å¼   1.4 æ•°å­—å›¾åƒå¤„ç†æ„ä¹‰åŠå†…å®¹ 1.5 æ•°å­—å›¾åƒå¤„ç†ç³»ç»ŸåŠåº”ç”¨  1.5.1æ•°å­—å›¾åƒç‰¹æ€§ï¼šå›¾åƒ/æ˜¾ç¤ºåˆ†è¾¨ç‡/æ‰“å°æœºåˆ†è¾¨ç‡ åƒç´ æ·±åº¦ ä½é¢æ•°é‡ 1.5.2æ•°å­—å›¾åƒå¤„ç†ç³»ç»Ÿ     ç¬¬äºŒç«  æ•°å­—å›¾åƒé¢„å¤„ç†æ–¹æ³•  2.1 ç°åº¦åŒ–  2.1.1ç°åº¦åŒ–ä¸»è¦æ–¹æ³• 2.1.2å›¾åƒäºŒå€¼åŒ–  1.å…¨å±€äºŒå€¼åŒ– 2.</description>
    </item>
    
    <item>
      <title>The effect of stride length on lower extremity joint kinetics at various gait speeds</title>
      <link>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</link>
      <pubDate>Sun, 16 May 2021 10:44:02 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/the-effect-of-stride-length-on-lower-extremity-joint-kinetics-at-various-gait-speeds/</guid>
      <description>The effect of stride length on lower extremity joint kinetics at various gait speeds
 Research question Concepts Notations Background Materials and Methods  Data analysis  1. æ•°æ®å¤„ç† 2. Protocol validation 3. Continuum analysis  main effect analysis SL   4. Torque pulse approximation     Results  Protocol validation Continuum analysis Torque pulse approximation   Conclusion Limits/Further Work Thoughts/Comments  Research question In this study, we investigated how sagittal plane joint moments are affected by a factorial modulation of two important gait parameters: gait speed and stride length.</description>
    </item>
    
    <item>
      <title>Menu</title>
      <link>https://K7288.github.io/posts/menu/</link>
      <pubDate>Sun, 16 May 2021 10:35:13 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/menu/</guid>
      <description>å®ç°é¡µå†…è·³è½¬  åŸºæœ¬è¯­æ³• æ³¨æ„äº‹é¡¹ A subtitle just for test æµ‹è¯• a A  æµ‹è¯•â€”â€”æµ‹è¯• æµ‹è¯•:ä¸€ä¸ªæµ‹è¯•   1.æµ‹è¯•   ç›®å½•å®ç°  å®ç°é¡µå†…è·³è½¬ åŸºæœ¬è¯­æ³• [&amp;lt;æç¤ºè¯­&amp;gt;](#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)æ³¨æ„äº‹é¡¹   è‹¥æ ‡é¢˜æ˜¯è‹±æ–‡ï¼Œåœ¨(#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)ä¸­éœ€è¦å°å†™
ä¾‹å¦‚ [ä¾‹å¦‚](#a-subtitle-just-for-test)
  è‹¥æ ‡é¢˜ä¸­å‡ºç°ç©ºæ ¼ï¼Œéœ€è¦ç”¨-è¿æ¥
ä¾‹å¦‚ [ä¾‹å¦‚](#æµ‹è¯•-a-a)
  (#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)ä¸­ä¸èƒ½å‡ºç°åŠè§’ç‚¹(å³è‹±æ–‡ä¸­çš„å¥å·).ï¼Œä¼¼ä¹ä¹Ÿä¸æ”¯æŒå…¶ä»–æ ‡ç‚¹ï¼Œ(#&amp;lt;ç›®æ ‡å†…å®¹&amp;gt;)ä¸­éœ€è¦å°†æ ‡ç‚¹åˆ é™¤
æµ‹è¯•:ä¸€ä¸ªæµ‹è¯• [æµ‹è¯•:ä¸€ä¸ªæµ‹è¯•](#æµ‹è¯•ä¸€ä¸ªæµ‹è¯•)
1.æµ‹è¯• [1.æµ‹è¯•](#1æµ‹è¯•)
æµ‹è¯•â€”â€”æµ‹è¯• [æµ‹è¯•â€”â€”æµ‹è¯•](#æµ‹è¯•æµ‹è¯•)
  A subtitle just for test æµ‹è¯• a A æµ‹è¯•â€”â€”æµ‹è¯• æµ‹è¯•:ä¸€ä¸ªæµ‹è¯• 1.æµ‹è¯• ç›®å½•å®ç°  VS codeæ’ä»¶ Markdown All in One  ctrl+shift+p Markdown All in One: Create Table of Contents   TOD0 å®ç°ä¾§è¾¹ç›®å½•   ğŸ˜‚ å·²ç»å‡ºç°äº†å¯¹â€œæµ‹â€çš„å®Œå‹å´©å</description>
    </item>
    
    <item>
      <title>æ­¥é€Ÿä¼°è®¡ç»¼è¿°æ•´ç†</title>
      <link>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</link>
      <pubDate>Wed, 12 May 2021 22:17:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E6%AD%A5%E9%80%9F%E4%BC%B0%E8%AE%A1%E7%BB%BC%E8%BF%B0%E6%95%B4%E7%90%86/</guid>
      <description>Toward Pervasive Gait Analysis With Wearable Sensors: A Systematic Review Abstract å¯¹å½“å‰çš„å®šé‡æ­¥æ€åˆ†ææŠ€æœ¯è¿›è¡Œç³»ç»Ÿçš„ç»¼è¿°ï¼Œå¹¶æå‡ºå…³é”®æŒ‡æ ‡ï¼Œæ¥è¯„ä¼°ç°æœ‰çš„é€šè¿‡å¯ç©¿æˆ´ä¼ æ„Ÿå™¨æå–æ­¥æ€ç‰¹å¾çš„æ–¹æ³•ã€‚å®ƒæ—¨åœ¨çªå‡ºè¿™ä¸€å¿«é€Ÿå‘å±•çš„ç ”ç©¶é¢†åŸŸä¸­çš„å…³é”®è¿›å±•ï¼Œå¹¶æ¦‚è¿°ç ”ç©¶å’Œä¸´åºŠåº”ç”¨çš„æ½œåœ¨æœªæ¥æ–¹å‘ã€‚
SECTION III. Methods for Extracting Relevant Gait Features From Wearable Sensors A.æ–‡çŒ®æ£€ç´¢
B. Kinematics
Kinematic information is a well-established set of gait measures in biomechanical analysis.
ä»æƒ¯æ€§ä¼ æ„Ÿå™¨è·å–è¿åŠ¨å­¦ä¿¡æ¯ä¼¼ä¹å¾ˆç›´è§‚ï¼Œä½†æ˜¯è¦è·å¾—å…³äºäººä½“è¿åŠ¨å­¦çš„å‡†ç¡®ç©ºé—´ä¿¡æ¯ä»ç„¶å¾ˆå›°éš¾ï¼šå…¨å±€å¤±å‡†å’Œintegration drift
C.æ—¶åºç‰¹å¾
D.åˆ©ç”¨æƒ¯æ€§ä¼ æ„Ÿå™¨çš„æ­¥é€Ÿæå–
Laudanski et al. [104] reviewed the current research (16 papers in total) on gait speed estimation using inertial sensors, classifying the current gait speed estimation model into three categories: abstraction model (i.</description>
    </item>
    
    <item>
      <title>åŸºäºå‡ ä½•ä¸ç‰©ç†ç‰¹å¾èåˆçš„æ™ºèƒ½ä¸‹è‚¢å‡è‚¢è¿åŠ¨æ„å›¾è¯†åˆ«</title>
      <link>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</link>
      <pubDate>Wed, 12 May 2021 20:52:44 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/</guid>
      <description>åŸºäºå‡ ä½•ä¸ç‰©ç†ç‰¹å¾èåˆçš„æ™ºèƒ½ä¸‹è‚¢å‡è‚¢è¿åŠ¨æ„å›¾è¯†åˆ«Movement intention recognition of intelligent lower limb prosthesis based on the fusion of geometric and physical features
intentionå®šä¹‰â€”locomotion modes 5ç±»ç¨³æ€æ¨¡å¼: å¹³åœ°è¡Œèµ°ã€ä¸Šæ¥¼ã€ä¸‹æ¥¼ã€ä¸Šå¡å’Œ ä¸‹å¡ï¼Œ8ç±»è½¬æ¢æ¨¡å¼
Research question å°†å…³èŠ‚è§’è¡¨ç¤ºçš„å‡ ä½•ç‰¹å¾ä¸åŠ é€Ÿåº¦ã€è§’é€Ÿåº¦è¡¨ç¤ºçš„ç‰©ç†ç‰¹å¾æœ‰æœºèåˆå¹¶åº”ç”¨äºæ™ºèƒ½ä¸‹è‚¢å‡è‚¢çš„è¿åŠ¨æ„å›¾è¯†åˆ«
Introduction ä¼ ç»Ÿçš„æ„å›¾è¯†åˆ«æ–¹æ³•æ‰€ç”¨ä¼ æ„Ÿå™¨æ•°é‡åŠç§ç±»è¾ƒå¤š, ç‰¹å¾å‘é‡ç»´æ•°åé«˜, ç»Ÿè®¡ç‰¹å¾å¯¹çŸ­æ—¶æ ·æœ¬å…·æœ‰ä¸ç¨³å®šæ€§ï¼ˆåœ¨1.3 ç‰¹å¾é€‰æ‹©ä¸æå–æœ‰å…¬å¼è¯æ˜ï¼‰ã€‚related workæ²¡æœ‰ç»“åˆå‡ ä½•å’Œç‰©ç†ã€‚
Methods   é‡‡æ ·ï¼šå¥ä¾§å¤§è…¿ã€å°è…¿æƒ¯æ€§æµ‹é‡å•å…ƒäºæ‘†åŠ¨ç›¸å‰æœŸæ‰€äº§ç”Ÿçš„è¿åŠ¨æ—¶åºæ•°æ®ä½œä¸ºæ ·æœ¬ï¼›
  æ•°æ®å¤„ç†ï¼šç§»åŠ¨å¹³å‡æ»¤æ³¢å™¨æ»¤æ³¢å»å™ª
  ç‰¹å¾æå–ï¼š
 å‡ ä½•ç‰¹å¾ï¼šæ ¹æ®ä¸¤ä¸ªä¼ æ„Ÿå™¨çš„åŠ é€Ÿåº¦ã€è§’é€Ÿåº¦è®¡ç®—ä¸€ç»´çš„è†å…³èŠ‚è§’ï¼ŒFDAæ–¹æ³•æå–æœ€å€¼æ–œç‡ ç‰©ç†ç‰¹å¾ï¼šåŠ é€Ÿåº¦ã€è§’é€Ÿåº¦çš„å‡å€¼ã€æ–¹å·®  å‡å€¼ã€æ–¹å·®ã€æœ€å€¼æ–œç‡èåˆæ„æˆ25ç»´çš„ç‰¹å¾åŸºæ„å»ºç‰¹å¾å‘é‡
  SVMåˆ†ç±»
  Results 13ç§æ—¥å¸¸è¡Œä¸ºè¿›è¡Œåˆ†ç±»ã€‚å®éªŒç»“æœï¼šå¯¹5ç±»ç¨³æ€æ¨¡å¼: å¹³åœ°è¡Œèµ°ã€ä¸Šæ¥¼ã€ä¸‹æ¥¼ã€ä¸Šå¡å’Œ ä¸‹å¡çš„è¯†åˆ«ç‡è¾¾åˆ°96.9%, å¯¹8ç±»è½¬æ¢æ¨¡å¼çš„è¯†åˆ«ç‡è¾¾åˆ°97.1%, å¯¹13 ç§æ¨¡å¼çš„è¯†åˆ«ç‡ä¸º94.3%ã€‚
Highlights å‡å°‘äº†ä¼ æ„Ÿå™¨çš„æ•°é‡åŠç§ç±», é™ä½ äº†ç‰¹å¾å‘é‡çš„ç»´æ•°é™ä½äº†ç®—æ³•å¤æ‚åº¦ä¸”é¿å…äº†æ»åæ€§é—®é¢˜, ç”¨åŠ é€Ÿåº¦ã€ è§’é€Ÿåº¦åŠè†å…³èŠ‚è§’ä¸‰ä¸ªå‚æ•°å…±åŒå¯¹äººä½“ä¸‹è‚¢è¿åŠ¨çš„è¿åŠ¨å­¦ç‰¹ç‚¹è¿›è¡Œè¡¨å¾ã€‚
åœ¨ç‰¹å¾çš„æå–ä¸Š, å°†FDAæ–¹æ³•ä¸ç»Ÿè®¡æ–¹æ³•ç›¸ç»“åˆ, å¼¥è¡¥äº†ä»…æå–ç»Ÿè®¡ç‰¹å¾çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚
Limits/Further Work å¯¹äº13ç§åŠ¨ä½œçš„è¯†åˆ«ç‡æœ‰å¾…æé«˜, åæœŸå·¥ä½œä¼šé›†ä¸­äºå¯¹ç±»é—´ç›¸ä¼¼æ€§ç›¸å¯¹è¾ƒå¼ºè¾ƒéš¾åŒºåˆ†çš„åŠ¨ä½œè¿›è¡Œåˆ†ç±», å¦‚: ä¸‹æ¥¼ä¸ä¸‹å¡, èµ°åˆ°ä¸‹æ¥¼ ä¸èµ°åˆ°ä¸‹å¡ç­‰.</description>
    </item>
    
    <item>
      <title>Gait Analysis Systems</title>
      <link>https://K7288.github.io/posts/gait-analysis-systems/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/gait-analysis-systems/</guid>
      <description>&amp;ldquo;Section Four - Gait Analysis Systems&amp;rdquo; from Gait Analysis: Normal and Pathological Function1
Basically, there are 5 measurement systems.
Three of these focus on the specific events that constitute the act of walking.
è¡Œèµ°å„ä¸ªé˜¶æ®µ
 Motion analysis defines the magnitude and timing of individual joint action. Dynamic electromyography idenÂ­tifies the period and relative intensity of muscle function. Force plate recordings display the functional demands being experienced during the weight-bearing period.  The two remaining gait analysis technics summarize the effects of the person&amp;rsquo;s gait mechanics.</description>
    </item>
    
    <item>
      <title>Gait Analysis Fundamentals</title>
      <link>https://K7288.github.io/posts/gait-analysis-fundamentals/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://K7288.github.io/posts/gait-analysis-fundamentals/</guid>
      <description>Gait analysis æ­¥æ€åˆ†æç®€è¿°1 Factors and parameters å½±å“æ­¥æ€çš„å› ç´  The gait analysis is modulated or modified by many factors, and changes in the normal gait pattern can be transient or permanent. The factors can be of various types:
 Extrinsic: such as terrain, footwear, clothing, cargo Intrinsic: sex, weight, height, age, etc. Physical: such as weight, height, physique Psychological: personality type, emotions Physiological: anthropometric characteristics, i.e., measurements and proportions of body Pathological: for example trauma, neurological diseases, musculoskeletal anomalies, psychiatric disorders  Parameters æè¿°æ­¥æ€çš„å‚æ•° The parameters taken into account for the gait analysis are as follows:</description>
    </item>
    
    <item>
      <title>Hugo Guide</title>
      <link>https://K7288.github.io/posts/hugo-guide/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/hugo-guide/</guid>
      <description>About Contents Add Some Content hugo new post/**.md
The newly created content file will start with something like this:
---title: &amp;quot;**&amp;quot;date: 2019-03-26T08:47:11+01:00draft: true---Drafts do not get deployed; once you finish a post, update the header of the post to say draft: false. More info here.
---title: &amp;quot;Hugo Guide&amp;quot;date: 2021-05-01T08:47:11+01:00categories: [&amp;quot;Manual&amp;quot;]tags: [&amp;quot;Hugo&amp;quot;, &amp;quot;GitHub&amp;quot;]draft: false---Add pictures
/post/xxx.jpg
is actually baseURL/post/xxx.jpg</description>
    </item>
    
    <item>
      <title>Math</title>
      <link>https://K7288.github.io/posts/math/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/math/</guid>
      <description>$$ e^{ix}=\text{cos}x+i\text{sin}x $$
  $$ \left(C_{n+1, t+1}-C_{n, t}\right)-\left(C_{n, t+1}-C_{n-1, t}\right)=\frac{2}{n+1} $$
  $$ \begin{aligned} C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2} +C_{t+1, t+1}-C_{t, t} \\ &amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) \end{aligned} $$
\begin{aligned} C_{n+1, t+1}-C_{n, t} &amp;amp;=\frac{2}{n+1}+\frac{2}{n}+\cdots+\frac{2}{t+2} +C_{t+1, t+1}-C_{t, t} \\\\ &amp;amp;=2\left(H_{n+1}-H_{t+1}\right)+2-2 /(t+1) \end{aligned} æ¢è¡Œéœ€è¦ä½¿ç”¨\\\\
\begin{aligned}å’Œ\end{aligned}ä¹‹é—´ä¸èƒ½æœ‰ç©ºè¡Œ
ä¸æ”¯æŒ\left[ï¼Œ\right)ç­‰
  $$ \begin{cases}\begin{array}{l} \theta_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} \theta_{i}(t-j),\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\{r h,l h, r k, l k\}\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases} $$
\begin{cases}\begin{array}{l} \theta_{i}(t-j)^{\prime}=\frac{13} \Sigma_{1}^{-1} \theta_{i}(t-j),\\\\ a_{i}(t-j)^{\prime}=\frac{1}{3} \sum_{1}^{-1} a_{i}(t-j), i=\\{r h,l h, r k, l k\\}\\\\w_{i}(t-j)^{\prime}=\frac{1}{3} \Sigma_{1}^{-1} w_{i}(t-j)\end{array}\end{cases} \begin{array}å’Œ\end{array}ä¹‹é—´ä¸èƒ½æ¢è¡ŒğŸ˜…</description>
    </item>
    
    <item>
      <title>è®ºæ–‡3ç¯‡æ³›è¯» 1-&gt;measurementå¯é æ€§(æ–¹æ³•æ¯”è¾ƒå¥‡æ€ªæˆ–è€…æ²¡æœ‰) 2/3-&gt;æ­¥æ€å‚æ•°æ‹Ÿåˆ</title>
      <link>https://K7288.github.io/posts/measurement%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83%E5%A5%87%E6%80%AA%E6%88%96%E8%80%85%E6%B2%A1%E6%9C%89-%E6%AD%A5%E6%80%81%E5%8F%82%E6%95%B0%E6%8B%9F%E5%90%88/</link>
      <pubDate>Sat, 01 May 2021 11:37:16 +0800</pubDate>
      
      <guid>https://K7288.github.io/posts/measurement%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83%E5%A5%87%E6%80%AA%E6%88%96%E8%80%85%E6%B2%A1%E6%9C%89-%E6%AD%A5%E6%80%81%E5%8F%82%E6%95%B0%E6%8B%9F%E5%90%88/</guid>
      <description>å› ä¸ºä¸ç†Ÿæ‚‰å¿ƒç›¸å…³ç ”ç©¶é—®é¢˜ï¼Œä¹‹å‰åšç¬”è®°çš„æ¬¡æ•°ä¹Ÿå°‘ï¼Œè¿™å‡ ç¯‡Literature Notesç»“æ„ä¸å¤Ÿæ¸…æ™°ï¼Œè€Œä¸”è¿‡é•¿ï¼Œä¸‹æ¬¡æ³¨æ„ã€‚
ä¸‰ç¯‡æ–‡çŒ®ä¸é€‰é¢˜çš„å…³è”æ€§å·®å¼ºäººæ„ï¼Œä¹‹åç•™æ„/è¯·æ•™ä¸€ä¸‹å¦‚ä½•æœ‰æ•ˆæŸ¥æ‰¾æ–‡çŒ®ã€‚
1. Reliability of centre of pressure, plantar pressure, and plantar-flexion isometric strength measures: A systematic review COP PP PFisom ä¸‰ç§æ­¥æ€æ§åˆ¶measurement çš„å¯é æ€§
æ–¹æ³•ï¼šå¯¹ä¸‰ä¸ªæ•°æ®åº“å®éªŒè¿›è¡ŒåŒè¡Œè¯„ä¼° ICC
Background Centre of pressure (COP), plantar pressure (PP), and plantar-flexion isometric strength (PFisom) are often examined in relation to postural control and gait.
Research question Our aim was to systematically review and quality appraise articles addressing the reliability of COP and PP measures in static stance and PFisom measures.</description>
    </item>
    
  </channel>
</rss>
