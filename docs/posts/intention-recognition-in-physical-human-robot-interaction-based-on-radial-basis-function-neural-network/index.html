<!DOCTYPE html>
<html lang="en">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intention定义：velocity&#43;trajectory; 只涉及到一个接触点
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.'><title>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</title>

<link rel='canonical' href='https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network'>
<meta property='og:description' content='Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intention定义：velocity&#43;trajectory; 只涉及到一个接触点
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.'>
<meta property='og:url' content='https://K7288.github.io/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/'>
<meta property='og:site_name' content='K7288'>
<meta property='og:type' content='article'><meta property='article:section' content='Posts' /><meta property='article:tag' content='Intention Recognition' /><meta property='article:published_time' content='2021-06-29T20:52:44&#43;08:00'/><meta property='article:modified_time' content='2021-06-29T20:52:44&#43;08:00'/>
<meta name="twitter:title" content="Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network">
<meta name="twitter:description" content="Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network
intention定义：velocity&#43;trajectory; 只涉及到一个接触点
Research question a method based on radial basis function neural network (RBFNN) model is presented to identify the motion intention of collaborator.
Here, the human intention is defined as the desired velocity in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.">
    </head>
    <body class="
    article-page has-toc
">
        <script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>
        <script>addBackToTop({
            diameter: 56,
            cornerOffset: 35,
            backgroundColor: 'ddd',
            textColor: '#ddd'
        })</script>
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="https://K7288.github.io" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                <span></span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/robotics/" >
                Robotics
            </a>
        
            <a href="/categories/literature-notes/" >
                Literature Notes
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/posts/intention-recognition-in-physical-human-robot-interaction-based-on-radial-basis-function-neural-network/">Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</a>
    </h2>

    <footer class="article-time">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <time class="article-time--published">2021-06-29</time>
    </footer></div>
</header>

    <section class="article-content">
    <p>Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network</p>
<p>intention定义：velocity+trajectory; 只涉及到一个接触点</p>
<h2 id="research-question">Research question</h2>
<p>a method based on radial basis function neural network (<strong>RBFNN</strong>) model is presented to <strong>identify the motion intention of collaborator</strong>.</p>
<p>Here, the <strong>human intention is defined as the desired velocity</strong> in human limb model, of which the estimation is obtained in real time based on interaction force and the contact point movement characteristics (current position and velocity of the robot) by the trained RBFNN model.</p>
<h2 id="introduction">Introduction</h2>
<ul>
<li>
<p>Kazuhiro Kosuge and Norihide Kazamura proposed several algorithms to generate the motion based on the intentional force and experimentally compare them, including method of force augmentation type, method of position control type, and method of velocity control type [8].</p>
</li>
<li>
<p>Dylan P. Losey et al. provided a unifying view of human and robot sharing task execution. They defined <strong>three key themes that emerge in shared control scenarios</strong>, namely, <strong>intent detection, arbitration, and feedback</strong> [9].</p>
</li>
<li>
<p>Definition of intent in this paper: In many physical human-robot interaction (pHRI) applications, the intent can be defined in a binary way. It is often ascertained from a brain-machine interface (BMI), as seen in[10]. In other applications, user intent is defined in terms of a velocity or position trajectory, the predicted forward path of the user and/or robot.</p>
</li>
<li>
<p>human intention recognition based on myographic signals 肌电信号</p>
<ul>
<li>
<p>pattern recognition</p>
<p>The pattern recognition approach is to map patterns of any number of signal features to desired prosthesis poses, grasps, or functions. The way in which control algorithms learn this mapping varies, but common approaches are LDA, SVMs, and artificial neural networks (ANNs) [11, 12, 15].</p>
</li>
<li>
<p>mapping to continuous effort.</p>
<p>control systems that learn the mapping between EMG signals and user’s desired joint torque, e.g. relationship between the root-mean square (RMS) of measured EMG signals and the estimated user’s desired torques [16].</p>
</li>
</ul>
</li>
<li>
<p>human intention recognition based on interaction force</p>
<ul>
<li>dynamics model
<ul>
<li>Pehlivanet al. use an <strong>inverse dynamics model of the robot</strong> to estimate the user force applied to the robot from the robot encoder measurements [17].</li>
<li>In [20–22], human intentions are predicted by establishing a dynamic model of collaborator. Passenberg C. uses human models and jerk models to recognize human intention with extended Kalman filtering method [23]. These estimation methods based on the <strong>human body model</strong> are very difficult because the impedance parameters of the human body are variable and can be hardly obtained [24].</li>
</ul>
</li>
<li>NN method
<ul>
<li>the motion intention of the human partner is defined as the desired trajectory in the employed human limb model; difficult to obtain in practice.</li>
</ul>
</li>
<li>Hidden Markov Model
<ul>
<li>very complex and difficult to establish a model of intention recognition.</li>
<li>C. Lee uses the Baum-Welch algorithm to train Hidden Markov Model, which predicts
the collaborator&rsquo;s intention by learning the meaning of the collaborators’ gestures. However, this method does not really realize the purpose of identifying partner intention [19].</li>
</ul>
</li>
<li>In addition, the measured interaction force can be used to estimate other forms of motion intention. For example, the interaction forces measured in the handles to predict possible walking modes or the walker’s forward path in [25, 26].</li>
</ul>
</li>
</ul>
<h2 id="methods">Methods</h2>
<p>assumption: the end effector of robot physically interacts with the human hand and there is only one interaction point.</p>
<p>sensor: Six-Dimensional Force Sensor</p>
<ol>
<li>
<p>in order to <strong>obtain training data and test data</strong> of neural network, the adaptive impedance control method is used to collect sample data.</p>
</li>
<li>
<p>basis neural network model is established after mapping sample data.</p>
<ul>
<li>
<p>data matching</p>
</li>
<li>
<p>K-means method used to define the number of the hidden layer nodes. Weighted mean value (Wmv) parameter (as follows) of cluster radius to determine K value.</p>
</li>
<li>
<p><img src="/assets/image-20210703115112299.png" alt="image-20210703115112299" style="zoom:50%;" /></p>
</li>
</ul>
</li>
<li>
<p>the intention of the collaborator is identified through online prediction.</p>
</li>
<li>
<p>In order to verify the validity of the RBFNN method in this paper, the robot’s contact point speed and interaction force are analyzed by comparing with the corresponding experimental parameters values from the adaptive impedance control algorithm. 
<img src="/assets/4141269.fig.002.svg" align="center"></p>
</li>
</ol>
<h2 id="thoughtscomments">Thoughts/Comments</h2>
<ul>
<li>
<p>K-means是怎么用在hidden layer nodes数量的确定上的？？(p5)</p>
<ul>
<li>先有鸡还是现有蛋</li>
</ul>
</li>
<li>
<p>有时间看一下</p>
<ul>
<li>这个自适应方法是怎么得出的</li>
</ul>
<p><img src="/assets/image-20210701181613356.png" alt="image-20210701181613356" style="zoom:50%;" /></p>
<ul>
<li>质量-弹簧-阻尼器系统等（Dr. F毕业论文那里好像有张图）</li>
</ul>
<p><img src="/assets/image-20210701181822246.png" alt="image-20210701181822246" style="zoom:50%;" /></p>
</li>
</ul>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/intention-recognition/">Intention Recognition</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>

    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3&#43;Aro6EYUG4&#43;cU&#43;KJWu/X"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"integrity="sha384-g7c&#43;Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI&#43;sEnkvrMWph2EDg4"crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC&#43;Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"crossorigin="anonymous"
                defer="true"
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>
    
    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">Related contents</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="">
    <a href="/posts/intention-recognition-for-exoskeleton/">
        
        

        <div class="article-details">
            <h2 class="article-title">Intention Recgonition for Exoskeleton</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/posts/multi-sensor-based-human-motion-intention-recognition-algorithm-for-walking-aid-robot/">
        
        

        <div class="article-details">
            <h2 class="article-title">Multi-sensor based human motion intention recognition algorithm for walking-aid robot</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/posts/a-review-of-human-activity-recognition-methods/">
        
        

        <div class="article-details">
            <h2 class="article-title">A review of human activity recognition methods</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/posts/%E5%9F%BA%E4%BA%8E%E5%87%A0%E4%BD%95%E4%B8%8E%E7%89%A9%E7%90%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%B8%8B%E8%82%A2%E5%81%87%E8%82%A2%E8%BF%90%E5%8A%A8%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/">
        
        

        <div class="article-details">
            <h2 class="article-title">基于几何与物理特征融合的智能下肢假肢运动意图识别</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/posts/%E5%A4%96%E9%AA%A8%E9%AA%BC%E7%BB%BC%E8%BF%B0/">
        
        

        <div class="article-details">
            <h2 class="article-title">外骨骼综述</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>

     
     
        
    <link rel="stylesheet" href="https://unpkg.com/vssue/dist/vssue.min.css" />

<div id="vssue"></div>

<script src="https://unpkg.com/vue/dist/vue.runtime.min.js"></script>
<script src="https://unpkg.com/vssue/dist/vssue.github.min.js"></script>

<script>
    new Vue({
        el: "#vssue",
        render: (h) =>
            h("Vssue", {
                props: {
                    title: "Intention Recognition in Physical Human-Robot Interaction Based on Radial Basis Function Neural Network",
                    options: {
                        proxy: (url) => "https://cors-anywhere.azm.workers.dev/" + url,
                        owner: "K7288",
                        repo: "blog-repos",
                        clientId: "ac393ff5fd371a96eda1",
                        clientSecret: "e9c2b32500e90b7d0e374ecf8481b97819b8012c",
                    },
                },
            }),
    });
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 K7288
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="2.3.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>

    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">Table of contents</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#research-question">Research question</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#methods">Methods</a></li>
    <li><a href="#thoughtscomments">Thoughts/Comments</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
